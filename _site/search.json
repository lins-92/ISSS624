[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to my ISSS6224 Geospatial Analytics webpage! :)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_EX01.html",
    "href": "Hands-on_EX01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The purpose of this exercise is to practice the basics of using geospatial data in R.\n\n\nsf is used to manipulate geospatial data and tidyverse for aspatial data. kableExtra makes tables with nicer formating.\n\n\n\n\n\nLet’s load the geospatial data.\n\nmpsz = st_read(dsn = \"Hands-on_EX01/data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath = st_read(dsn = \"Hands-on_EX01/data/geospatial\", \n                      layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool = st_read(\"Hands-on_EX01/data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that each file has a different geometry type to represent different types of features.\nWe can also see that mpsz and cyclingpath both have the same projected CRS of SVY21 but preschools has a geodetic CRS of WGS 84. These refer to the coordinate systems to model geographic location and how to represent this information on a flat surface. Here is a detailed explanation on why coordinate systems are needed and the difference between a geodetic CRS (GCS) and projected CRS (PCS).\n\n\n\nThe st_geometry command displays the geometry information of a spatial dataset.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nWe can use glimpse to get an overview of the different variables in the dataset and head to view the first few entries.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    OBJECTID \n    SUBZONE_NO \n    SUBZONE_N \n    SUBZONE_C \n    CA_IND \n    PLN_AREA_N \n    PLN_AREA_C \n    REGION_N \n    REGION_C \n    INC_CRC \n    FMEL_UPD_D \n    X_ADDR \n    Y_ADDR \n    SHAPE_Leng \n    SHAPE_Area \n    geometry \n  \n \n\n  \n    1 \n    1 \n    MARINA SOUTH \n    MSSZ01 \n    Y \n    MARINA SOUTH \n    MS \n    CENTRAL REGION \n    CR \n    5ED7EB253F99252E \n    2014-12-05 \n    31595.84 \n    29220.19 \n    5267.381 \n    1630379.3 \n    MULTIPOLYGON (((31495.56 30... \n  \n  \n    2 \n    1 \n    PEARL'S HILL \n    OTSZ01 \n    Y \n    OUTRAM \n    OT \n    CENTRAL REGION \n    CR \n    8C7149B9EB32EEFC \n    2014-12-05 \n    28679.06 \n    29782.05 \n    3506.107 \n    559816.2 \n    MULTIPOLYGON (((29092.28 30... \n  \n  \n    3 \n    3 \n    BOAT QUAY \n    SRSZ03 \n    Y \n    SINGAPORE RIVER \n    SR \n    CENTRAL REGION \n    CR \n    C35FEFF02B13E0E5 \n    2014-12-05 \n    29654.96 \n    29974.66 \n    1740.926 \n    160807.5 \n    MULTIPOLYGON (((29932.33 29... \n  \n  \n    4 \n    8 \n    HENDERSON HILL \n    BMSZ08 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    3775D82C5DDBEFBD \n    2014-12-05 \n    26782.83 \n    29933.77 \n    3313.625 \n    595428.9 \n    MULTIPOLYGON (((27131.28 30... \n  \n  \n    5 \n    3 \n    REDHILL \n    BMSZ03 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    85D9ABEF0A40678F \n    2014-12-05 \n    26201.96 \n    30005.70 \n    2825.594 \n    387429.4 \n    MULTIPOLYGON (((26451.03 30... \n  \n\n\n\n\n\nWe can also create simple plots of spatial data using the base R plot function. We can use indexing to indicate the variable to group by.\n\nplot(mpsz[\"CA_IND\"])\n\n\n\n\n\n\n\nThe st_crs displays the details of a spatial dataset’s projection. In this example, the EPSG code has been wrongly specified and needs to be corrected. The st_set_crs command only changes the code but does not actually change the coordinate system. It is only used to correcting wrongly specified projection information.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo change the coordinate system (called transformation or projection), we use the the st_transform function. We will use this function to transform the preschool dataset to the same projection system as the other 2 layers (SVY21).\n\npreschool <- st_transform(preschool,\n                          crs=3414)\n\n\n\n\nSometimes we have datasets that have spatial information (e.g. latitude and longitude) that are not already in geospatal file formats (shp, gpkg, kml). We will need to import them as aspatial data first then specify which variables contain the geometries and how to represent these data spatially (ie. the coordinate system).\n\nlistings <- read_csv(\"Hands-on_EX01/data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(listings)\n\nRows: 4,252\nColumns: 16\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.34531, 1.2…\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596, 103.9610,…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n\n\nFrom the glimpse, we can see that the latitude and longitude variables contain the spatial information we need. The units used are decimal degrees.\nNow let’s use the st_as_sf function to transform the listings dataset into geospatial data. Use the coords argument to specify the x and y coordinates (longitude then latitude) respectively. We assume that the original coordinate system was WGS84 (EPSG 4326) and reproject it to SVY21 (EPSG 3414).\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %>%\n  st_transform(crs=3414)\n\n\n\n\n\n\n\nBuffers create a zone around a feature. It is used in geospatial analyses in conjunction with other functions to measure access to amenities (e.g. how many households are within 500m proximity to an MRT station?). The function is st_buffer.\nIn this example, we want to calculate the area of land that needs to be set aside for to 5m wide cycling paths.. The original cycling path layer is a polyline dataset which has no width so we need to use create a buffer first then calculate area using the st_area function.\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                            dist=5, nQuadSegs = 30)\n\nbuffer_cycling$area = st_area(buffer_cycling)\n\nsum(buffer_cycling$area)\n\n773143.9 [m^2]\n\n\n\n\n\nCounting the number of points (features) in a polygon is another common geoprocessing tool. We use the st_intersects function to relate the point and polygon layers spatially. It will output a list of points located within each polygon (by their respective indices). The lengths function from base R is used to find the number of elements (ie pre-schools) in each polygon.\nIn this example, we will count the number of pre-schools in each subzone.\n\nmpsz <- mpsz %>%\n  mutate(preschools = lengths(st_intersects(x=mpsz,y=preschool)))\n\nplot(mpsz[\"preschools\"])"
  },
  {
    "objectID": "Hands-on_EX01.html#importing-and-preparing-data-1",
    "href": "Hands-on_EX01.html#importing-and-preparing-data-1",
    "title": "Hands-on Exercise 1",
    "section": "Importing and Preparing Data",
    "text": "Importing and Preparing Data\n\nLoading and Manipulating Data\nThis exercise uses the mpsz dataset from Part 1 and a new attribute dataset containing population data by subzone.\n\npopdata <- read_csv(\"Hands-on_EX01/data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   <chr> \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   <chr> \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   <chr> \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  <chr> \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  <chr> \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  <dbl> 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\nhead(popdata, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    PA \n    SZ \n    AG \n    Sex \n    TOD \n    Pop \n    Time \n  \n \n\n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 1- and 2-Room Flats \n    0 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 3-Room Flats \n    10 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 4-Room Flats \n    30 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 5-Room and Executive Flats \n    50 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HUDC Flats (excluding those privatised) \n    0 \n    2011 \n  \n\n\n\n\n\nFor this exercise, we will only be using the 2020 data. We need to relate the attribute data to the mpsz dataset. First, we need to manipulate the attribute data to create the following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMYACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npop2020 <- popdata %>%\n  filter(Time==2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(POP = sum(Pop)) %>%\n  ungroup() %>%\n  pivot_wider(names_from = AG, \n              values_from = POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])+ rowSums(.[12])) %>%\n  mutate(ECONOMYACTIVE = rowSums(.[7:11]) + rowSums(.[13:15])) %>%\n  mutate(AGED=rowSums(.[16:21])) %>%\n  mutate(TOTAL=rowSums(.[3:21])) %>%  \n  mutate(DEPENDENCY = (YOUNG + AGED)/ ECONOMYACTIVE) %>%\n  select(PA, SZ, YOUNG, ECONOMYACTIVE, AGED, TOTAL, DEPENDENCY) %>%\n  mutate(across(PA:SZ, toupper))\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nJoin the attribute data to the mpsz data by SZ. In the previous step, we manipulated this variable to be uppercase to match with the mpsz file.\n\nmpsz_pop2020 <- left_join(x=mpsz,\n                          y=pop2020,\n                          by= c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_EX01.html#choropleth-maps",
    "href": "Hands-on_EX01.html#choropleth-maps",
    "title": "Hands-on Exercise 1",
    "section": "Choropleth Maps",
    "text": "Choropleth Maps\n\nBasic Map\nA basic choropleth map with no customisations can be created using the qtm function. It uses a number of defaults which may not always be useful depending on the dataset. In the example below, the pretty breaks result in a map which is not informative because of the distribution of dependency ratio.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nMore Customisations\ntmap also allows us to customise each aspect of the map more finely. The code chunk below uses the same dependency ratio data as the above map but splits by quantiles instead to show the distribution more clearly. Other customisations create map elements like title, map scale, map grid and compass.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_EX01/Hands-on_EX01.html",
    "href": "Hands-on_EX01/Hands-on_EX01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The purpose of this exercise is to practice the basics of using geospatial data in R.\n\n\nsf is used to manipulate geospatial data and tidyverse for aspatial data. kableExtra makes tables with nicer formating.\n\n\n\n\n\nLet’s load the geospatial data.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                      layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that each file has a different geometry type to represent different types of features.\nWe can also see that mpsz and cyclingpath both have the same projected CRS of SVY21 but preschools has a geodetic CRS of WGS 84. These refer to the coordinate systems to model geographic location and how to represent this information on a flat surface. Here is a detailed explanation on why coordinate systems are needed and the difference between a geodetic CRS (GCS) and projected CRS (PCS).\n\n\n\nThe st_geometry command displays the geometry information of a spatial dataset.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nWe can use glimpse to get an overview of the different variables in the dataset and head to view the first few entries.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    OBJECTID \n    SUBZONE_NO \n    SUBZONE_N \n    SUBZONE_C \n    CA_IND \n    PLN_AREA_N \n    PLN_AREA_C \n    REGION_N \n    REGION_C \n    INC_CRC \n    FMEL_UPD_D \n    X_ADDR \n    Y_ADDR \n    SHAPE_Leng \n    SHAPE_Area \n    geometry \n  \n \n\n  \n    1 \n    1 \n    MARINA SOUTH \n    MSSZ01 \n    Y \n    MARINA SOUTH \n    MS \n    CENTRAL REGION \n    CR \n    5ED7EB253F99252E \n    2014-12-05 \n    31595.84 \n    29220.19 \n    5267.381 \n    1630379.3 \n    MULTIPOLYGON (((31495.56 30... \n  \n  \n    2 \n    1 \n    PEARL'S HILL \n    OTSZ01 \n    Y \n    OUTRAM \n    OT \n    CENTRAL REGION \n    CR \n    8C7149B9EB32EEFC \n    2014-12-05 \n    28679.06 \n    29782.05 \n    3506.107 \n    559816.2 \n    MULTIPOLYGON (((29092.28 30... \n  \n  \n    3 \n    3 \n    BOAT QUAY \n    SRSZ03 \n    Y \n    SINGAPORE RIVER \n    SR \n    CENTRAL REGION \n    CR \n    C35FEFF02B13E0E5 \n    2014-12-05 \n    29654.96 \n    29974.66 \n    1740.926 \n    160807.5 \n    MULTIPOLYGON (((29932.33 29... \n  \n  \n    4 \n    8 \n    HENDERSON HILL \n    BMSZ08 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    3775D82C5DDBEFBD \n    2014-12-05 \n    26782.83 \n    29933.77 \n    3313.625 \n    595428.9 \n    MULTIPOLYGON (((27131.28 30... \n  \n  \n    5 \n    3 \n    REDHILL \n    BMSZ03 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    85D9ABEF0A40678F \n    2014-12-05 \n    26201.96 \n    30005.70 \n    2825.594 \n    387429.4 \n    MULTIPOLYGON (((26451.03 30... \n  \n\n\n\n\n\nWe can also create simple plots of spatial data using the base R plot function. We can use indexing to indicate the variable to group by.\n\nplot(mpsz[\"CA_IND\"])\n\n\n\n\n\nplot(cyclingpath[\"CYL_PATH_C\"])\n\n\n\n\n\nplot(preschool)\n\n\n\n\n\n\n\nThe st_crs displays the details of a spatial dataset’s projection. In this example, the EPSG code has been wrongly specified and needs to be corrected. The st_set_crs command only changes the code but does not actually change the coordinate system. It is only used to correcting wrongly specified projection information.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo change the coordinate system (called transformation or projection), we use the the st_transform function. We will use this function to transform the preschool dataset to the same projection system as the other 2 layers (SVY21).\n\npreschool <- st_transform(preschool,\n                          crs=3414)\n\n\n\n\nSometimes we have datasets that have spatial information (e.g. latitude and longitude) that are not already in geospatal file formats (shp, gpkg, kml). We will need to import them as aspatial data first then specify which variables contain the geometries and how to represent these data spatially (ie. the coordinate system).\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(listings)\n\nRows: 4,252\nColumns: 16\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.34531, 1.2…\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596, 103.9610,…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n\n\nFrom the glimpse, we can see that the latitude and longitude variables contain the spatial information we need. The units used are decimal degrees.\nNow let’s use the st_as_sf function to transform the listings dataset into geospatial data. Use the coords argument to specify the x and y coordinates (longitude then latitude) respectively. We assume that the original coordinate system was WGS84 (EPSG 4326) and reproject it to SVY21 (EPSG 3414).\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %>%\n  st_transform(crs=3414)\n\n\n\n\n\n\n\nBuffers create a zone around a feature. It is used in geospatial analyses in conjunction with other functions to measure access to amenities (e.g. how many households are within 500m proximity to an MRT station?). The function is st_buffer.\nIn this example, we want to calculate the area of land that needs to be set aside for to 5m wide cycling paths.. The original cycling path layer is a polyline dataset which has no width so we need to use create a buffer first then calculate area using the st_area function.\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                            dist=5, nQuadSegs = 30)\n\nbuffer_cycling$area = st_area(buffer_cycling)\n\nsum(buffer_cycling$area)\n\n773143.9 [m^2]\n\n\n\n\n\nCounting the number of points (features) in a polygon is another common geoprocessing tool. We use the st_intersects function to relate the point and polygon layers spatially. It will output a list of points located within each polygon (by their respective indices). The lengths function from base R is used to find the number of elements (ie pre-schools) in each polygon.\nIn this example, we will count the number of pre-schools in each subzone.\n\nmpsz <- mpsz %>%\n  mutate(preschools = lengths(st_intersects(x=mpsz,y=preschool)))\n\nplot(mpsz[\"preschools\"])"
  },
  {
    "objectID": "Hands-on_EX01/Hands-on_EX01.html#importing-and-preparing-data-1",
    "href": "Hands-on_EX01/Hands-on_EX01.html#importing-and-preparing-data-1",
    "title": "Hands-on Exercise 1",
    "section": "Importing and Preparing Data",
    "text": "Importing and Preparing Data\n\nLoading and Manipulating Data\nThis exercise uses the mpsz dataset from Part 1 and a new attribute dataset containing population data by subzone.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   <chr> \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   <chr> \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   <chr> \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  <chr> \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  <chr> \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  <dbl> 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\nhead(popdata, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    PA \n    SZ \n    AG \n    Sex \n    TOD \n    Pop \n    Time \n  \n \n\n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 1- and 2-Room Flats \n    0 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 3-Room Flats \n    10 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 4-Room Flats \n    30 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 5-Room and Executive Flats \n    50 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HUDC Flats (excluding those privatised) \n    0 \n    2011 \n  \n\n\n\n\n\nFor this exercise, we will only be using the 2020 data. We need to relate the attribute data to the mpsz dataset. First, we need to manipulate the attribute data to create the following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMYACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npop2020 <- popdata %>%\n  filter(Time==2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(POP = sum(Pop)) %>%\n  ungroup() %>%\n  pivot_wider(names_from = AG, \n              values_from = POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])+ rowSums(.[12])) %>%\n  mutate(ECONOMYACTIVE = rowSums(.[7:11]) + rowSums(.[13:15])) %>%\n  mutate(AGED=rowSums(.[16:21])) %>%\n  mutate(TOTAL=rowSums(.[3:21])) %>%  \n  mutate(DEPENDENCY = (YOUNG + AGED)/ ECONOMYACTIVE) %>%\n  select(PA, SZ, YOUNG, ECONOMYACTIVE, AGED, TOTAL, DEPENDENCY) %>%\n  mutate(across(PA:SZ, toupper))\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nJoin the attribute data to the mpsz data by SZ. In the previous step, we manipulated this variable to be uppercase to match with the mpsz file.\n\nmpsz_pop2020 <- left_join(x=mpsz,\n                          y=pop2020,\n                          by= c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_EX01/Hands-on_EX01.html#choropleth-maps",
    "href": "Hands-on_EX01/Hands-on_EX01.html#choropleth-maps",
    "title": "Hands-on Exercise 1",
    "section": "Choropleth Maps",
    "text": "Choropleth Maps\n\nBasic Map\nA basic choropleth map with no customisations can be created using the qtm function. It uses a number of defaults which may not always be useful depending on the dataset. In the example below, the pretty breaks result in a map which is not informative because of the outlier.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nMore Customisations\ntmap also allows us to customise each aspect of the map more finely. The code chunk below uses the same dependency ratio data as the above map but splits by quantiles instead to show the distribution more clearly. Other customisations create map elements like title, map scale, map grid and compass.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThere are also other styles to create breaks. The map below uses the hclust method to create breaks and the number of breaks is increased to 10. Although the number of breaks is increased, the map is not necessarily more informative than the previous map using 5 quantile breaks.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          n=10,\n          style = \"hclust\", \n          palette = \"Reds\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In-class_EX01/In-class_EX01.html",
    "href": "In-class_EX01/In-class_EX01.html",
    "title": "In-Class Exercise 01",
    "section": "",
    "text": "We will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\n\nThis dataset contains the administrative boundaries of the Hunan province in China.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\lins-92\\ISSS624\\In-class_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNext, we import the aspatial data containing some economic indicators of the counties within Hunan.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLastly, we join the aspatial data to the spatial data.\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\nJoining, by = \"County\"\n\n\nWe can now visual GDP per capita for each county.\n\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nThe poly2nb() function of the spdep package cna be used to compute contiguity weight matrices.\n\n\nBy setting queen=TRUE, the poly2nb() function will output the matrix using the queen method.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nWe can view the complete weight matrix using str(). It displays the indices of neighbours.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\nIf we want to retrieve the GDP per capita of all neighbours of polygon 1, we can use the following code chunk. The first line store the indices of all neighbours of 1 by retrieving it from the nested list. The next line uses these indices to retrieve the values from the Hunan GDPPC variable by index.\n\nnb1 <- wm_q[[1]]\nhunan$GDPPC[nb1]\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\nBy changing queen=FALSE, the rook method will be used.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nCompared to the queen method, the rook method produces fewer nonzero links because the rook method is more restrictive than queen method.\n\n\n\nRow standardisation is applied to adjust the weights of each neighbour by the size of the neighbourhood. There are a few ways to perform row standardisation (see below). In the code chunk below, we use “W” where each neighbour is assigned the weight of 1/(#no of neighbours).\nThe function used is the nb2listw(). The options for style are :\n\n“W” row standardised (each row sums to 1)\n“B” binary\n“C” globally standardised (weight = total no of areas/total links)\n“U” unequal (all weights sum to 1)\n“minmax” standardised by minimum and maximum of row\n\n“S” variance standardised\n\nrswm_q <- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\nSpatial weights can be visualised using connectivity graphs. Since the Hunan dataset is in polygons, we need to extract their centroids to do visualisation.\nThe following code chunk uses st_centroid() to generate the latitude and longitude of each polygon centroid and store in vectors. Lastly, the vectors are combined into a single object.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude, latitude)\n\nNow we can plot the connectivity graph. The first line plots the polygons and the second line plots the connectivity matrix by from the connections in weight matrix and the location of the points in coords.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\ntitle(main=\"Connectivity Graph (Queen)\")\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\ntitle(main=\"Connectivity Graph (Rook)\")\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\ntitle(main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\ntitle(main=\"Rook Contiguity\")\n\n\n\n\n\n\n\n\nFor distance weight matrices, the dnearneigh() function of the spdep package is used.\nThe function identifies neighbours of points by Euclidean distance within a specified distance band.\n\n\nA fixed distance weight matrix considers any points within a certain fixed distance as a neighbour. To find this, we first need to set the upper limit for the distance band. We do this using the knearneigh() function by setting k=1 to generate a knn object. It is passed to the knn2nb() function to create a list of indices of the nearest neighbour to each centroid. We then use the nbdists() to compute the distance between each centroid and nearest neighbour.\n\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the summary, we see that the maximum distance between a centroid and its nearest neighbour centroid is 61.79km. If we set the maximum distance at 62km, all centroids will have at least one neighbour. The code chunk below creates a spatial matrix using 62km as the maximum distance.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAt maximum distance of 62km, the average number of neighbours is 3.68.\nNow we can plot the connectivty graph:\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\ntitle(main=\"1st nearest neighbours\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\ntitle(main=\"Distance link (62km)\")\n\n\n\n\n\n\n\nThe adaptive distance weight matrix is another way to build a distance weight matrix. Instead of using a fixed distance to find neighbours, it uses a fixed number of neighbours.\nWe use the knearneigh() function again but set the value of k at a larger number.\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe do not need the additional step of find the distance between neighbours since we have already fixed the number of neighbours. Nonetheless, we can use the following code to understand how the distance considered has changed between methods. Because some areas are more sparse or polygons are larger, the distance considered has naturally increased. The maximum distance considered is now 125km compared to 62km in the fixed distance method.\n\nk6dists <- unlist(nbdists(knn6, coords, longlat = TRUE))\nsummary(k6dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   45.30   57.56   57.89   67.73  124.88 \n\n\nWe can plot the adaptive distance weight matrix connectivity graph:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\ntitle(main=\"Adaptive distnace (k=6)\")\n\n\n\n\n\n\n\nThe inverse distance matrix uses actual distance not just binary weights. It is inversed because weightage should decrease with distance.\nWe can compute distance between points using the nbdists() function. Note that we use the queen contiguity matrix here. Although distance is considered, the neighbourhood is still based on queen contiguity.\n\ndist <- nbdists(wm_q, coords, longlat = TRUE)\nids <- lapply(dist, function(x) 1/(x))\nhead(ids, 5)\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n\n\n\n\nWe can also apply row standardisation to the inverse distance weight matrix.\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nThe code below displays the weights that will be applied to the neighbours of polygon 1.\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n\n\n\n\n\nSpatial weight matrices are typically used in computing spatially lagged values. Spatially lagged values can be used in spatial lag regression as an independent variable to account for the effect of a location’s neighbours.\nIn the following code chunk, we use the row-standardised queen contiguity matrix to compute the average GDP per capita for each polygon’s neighbours.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nhead(GDPPC.lag,5)\n\n[1] 24847.20 22724.80 24143.25 27737.50 27270.25\n\n\nWe join the spatially lagged mean GDP per capita values to the Hunan dataset below:\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nNow we can plot the lagged GDP per capita.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nThe spatially lagged sum is just the sum of the neighbours values. This means that each neighbour has a weight of 1.\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWe can then add compute the spatially lagged sum and join it to the Hunan dataset for plotting.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"NAME_3\"\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nThe spatial window average and sum basically include the area itself, not only its neighbours. To do that, we need to change the diagonal values of the matrix to 1 using the include_self() function.\n\nwm_q1 <- nb2listw(include.self(wm_q))\nwm_q1\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\n\nlag_w_avg_gpdpc <- lag.listw(wm_q1, \n                             hunan$GDPPC)\nhead(lag_w_avg_gpdpc)\n\n[1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17\n\n\nJoin the spatial window mean to the Hunan dataset and plot it.\n\nlag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan <- left_join(hunan, lag_wm_q1.res)\n\nJoining, by = \"NAME_3\"\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\nWe can repeat the process to get spatial window sum.\n\nb_weights <- lapply(include.self(wm_q), \n                    function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nb_weights2 <- nb2listw(include.self(wm_q), \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"NAME_3\"\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_EX02/Hands-on_EX02.html",
    "href": "Hands-on_EX02/Hands-on_EX02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Spatial autocorrelation measures the degree to which one object is similar to other nearby objects. Spatial autocorrelation is an important consideration in geospatial analysis because it means that observations are not independent of each other.\nOne of the common measures of spatial autocorrelation is Moran’s I. It takes a value between -1 and 1. The closer the value is to 1, the more clustered the dependent variable is spatially; the closer the value is to 01, the more dispersed the dependent variable is.\n\n\n\nAdapted from https://www.statology.org/morans-i/\n\n\nThis exercise is to practice how to computing spatiial autocorrelation.\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\n\n\n\n\nThis dataset contains the administrative boundaries of the Hunan province in China.\n\nhunan <- st_read(dsn=\"data/geospatial\",\n                 layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX02\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(hunan)\n\nRows: 88\nColumns: 8\n$ NAME_2     <chr> \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       <int> 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     <chr> \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  <chr> \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng <dbl> 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area <dbl> 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     <chr> \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   <POLYGON [°]> POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\nhead(hunan, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    NAME_2 \n    ID_3 \n    NAME_3 \n    ENGTYPE_3 \n    Shape_Leng \n    Shape_Area \n    County \n    geometry \n  \n \n\n  \n    Changde \n    21098 \n    Anxiang \n    County \n    1.869074 \n    0.1005619 \n    Anxiang \n    POLYGON ((112.0625 29.75523... \n  \n  \n    Changde \n    21100 \n    Hanshou \n    County \n    2.360691 \n    0.1997875 \n    Hanshou \n    POLYGON ((112.2288 29.11684... \n  \n  \n    Changde \n    21101 \n    Jinshi \n    County City \n    1.425620 \n    0.0530241 \n    Jinshi \n    POLYGON ((111.8927 29.6013,... \n  \n  \n    Changde \n    21102 \n    Li \n    County \n    3.474324 \n    0.1890812 \n    Li \n    POLYGON ((111.3731 29.94649... \n  \n  \n    Changde \n    21103 \n    Linli \n    County \n    2.289506 \n    0.1145036 \n    Linli \n    POLYGON ((111.6324 29.76288... \n  \n\n\n\n\n\n\ntm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"County\", size=0.5)\n\n\n\n\nNow let’s load the attribute data. This dataset contains some economic indicators of counties in the Hunan province.\n\necon <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(econ)\n\nRows: 88\nColumns: 29\n$ County      <chr> \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        <chr> \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    <dbl> 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    <dbl> 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         <dbl> 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     <dbl> 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     <dbl> 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         <dbl> 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       <dbl> 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         <dbl> 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        <dbl> 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       <dbl> 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         <dbl> 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         <dbl> 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        <dbl> 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       <dbl> 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     <dbl> 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     <dbl> 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   <dbl> 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R <dbl> 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        <dbl> 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       <dbl> 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        <dbl> 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       <dbl> 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        <dbl> 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     <dbl> 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    <dbl> 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        <dbl> 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      <dbl> 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\nhead(econ, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    County \n    City \n    avg_wage \n    deposite \n    FAI \n    Gov_Rev \n    Gov_Exp \n    GDP \n    GDPPC \n    GIO \n    Loan \n    NIPCR \n    Bed \n    Emp \n    EmpR \n    EmpRT \n    Pri_Stu \n    Sec_Stu \n    Household \n    Household_R \n    NOIP \n    Pop_R \n    RSCG \n    Pop_T \n    Agri \n    Service \n    Disp_Inc \n    RORP \n    ROREmp \n  \n \n\n  \n    Anhua \n    Yiyang \n    30544 \n    10967.0 \n    6831.7 \n    456.72 \n    2703.0 \n    13225.0 \n    14567 \n    9276.9 \n    3954.9 \n    3528.3 \n    2718 \n    494.31 \n    441.4 \n    338.0 \n    54.175 \n    32.830 \n    290.4 \n    234.5 \n    101 \n    670.3 \n    5760.60 \n    910.8 \n    4942.253 \n    5414.5 \n    12373 \n    0.7359464 \n    0.8929619 \n  \n  \n    Anren \n    Chenzhou \n    28058 \n    4598.9 \n    6386.1 \n    220.57 \n    1454.7 \n    4941.2 \n    12761 \n    4189.2 \n    2555.3 \n    3271.8 \n    970 \n    290.82 \n    255.4 \n    99.4 \n    33.171 \n    17.505 \n    104.6 \n    121.9 \n    34 \n    243.2 \n    2386.40 \n    388.7 \n    2357.764 \n    3814.1 \n    16072 \n    0.6256753 \n    0.8782065 \n  \n  \n    Anxiang \n    Changde \n    31935 \n    5517.2 \n    3541.0 \n    243.64 \n    1779.5 \n    12482.0 \n    23667 \n    5108.9 \n    2806.9 \n    7693.7 \n    1931 \n    336.39 \n    270.5 \n    205.9 \n    19.584 \n    17.819 \n    148.1 \n    135.4 \n    53 \n    346.0 \n    3957.90 \n    528.3 \n    4524.410 \n    14100.0 \n    16610 \n    0.6549309 \n    0.8041262 \n  \n  \n    Baojing \n    Hunan West \n    30843 \n    2250.0 \n    1005.4 \n    192.59 \n    1379.1 \n    4087.9 \n    14563 \n    3623.5 \n    1253.7 \n    4191.3 \n    927 \n    195.17 \n    145.6 \n    116.4 \n    19.249 \n    11.831 \n    73.2 \n    69.9 \n    18 \n    184.1 \n    768.04 \n    281.3 \n    1118.561 \n    541.8 \n    13455 \n    0.6544614 \n    0.7460163 \n  \n  \n    Chaling \n    Zhuzhou \n    31251 \n    8241.4 \n    6508.4 \n    620.19 \n    1947.0 \n    11585.0 \n    20078 \n    9157.7 \n    4287.4 \n    3887.7 \n    1449 \n    330.29 \n    299.0 \n    154.0 \n    33.906 \n    20.548 \n    148.7 \n    139.4 \n    106 \n    301.6 \n    4009.50 \n    578.4 \n    3793.550 \n    5444.0 \n    20461 \n    0.5214385 \n    0.9052651 \n  \n\n\n\n\n\nJoin the attribute data to the geospatial data using left_join.\n\nhunan <- left_join(x=hunan,\n                   y=econ,\n                   by=\"County\")\n\n\n\n\nFirst, let’s visualise GDP per capita of the different counties in Hunan province using a choropleth map.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n=5,\n          style=\"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n=5,\n          style=\"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Quantile\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\nTo compute global spatial autocorrelation, we first need to compute a spatial weight matrix. The poly2nb() function from the spdep package is used to compute a contiguity matrix using the queen’s method. This gives a basic weight matrix to indicate if areas are contiguous with each other.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nContiguity matrices are typically not used in raw form. The matrix is often row standardised by dividing each value by the sum of neighbours in a row such that each neighbour of an area applies an equal weightage. Each row will sum up to 1 (all rows are equal).\nThe function used is the nb2listw(). The options for style are :\n\n“W” row standardised (each row sums to 1)\n“B” binary\n“C” globally standardised (weight = total no of areas/total links)\n“U” unequal (all weights sum to 1)\n“minmax” standardised by minimum and maximum of row\n“S” variance standardised\n\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nNow we can finally conduct the Moran’s I test with the moran.test() function from spdep.\n\nmoran.test(hunan$GDPPC,\n           rswm_q,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThe null hypothesis of the Moran’s I test is that the data is randomly distributed (ie Moran’s I=0). In the above example, the null hypothesis is that the data is clustered (ie Moran’s I>0). At 5% significance level, we reject the null hypothesis and accept the alternative hypothesis that there is spatial clustering of GDP per capita. The computed Moran’s I is 0.3, indicating that there is some degree of spatially clustering.\n\n\n\nThe Moran’s I test assumes that the variable follows a normal distribution and is a random sample. When we are unsure of the underlying assumption of the variable, we can use Monte Carlo Moran’s I test instead. This test involves repeated random sampling from the dataset to estimate the distribution of Moran’s I if the variable were a random distributed across space, then compares the computed Moran’s I from the full dataset to this distribution.\n\nset.seed=1234\n\nbperm <- moran.mc(hunan$GDPPC,\n                  rswm_q,\n                  nsim=999,\n                  zero.policy=TRUE,\n                  na.action=na.omit)\n\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe null hypothesis of the Moran’s I test is that the data is randomly distributed or perfectly dispersed (ie Moran’s I<=0). In the above example, the null hypothesis is that the data is clustered (ie Moran’s I>0). At 5% significance level, we reject the null hypothesis and accept the alternative hypothesis that there is spatial clustering of GDP per capita. The computed Moran’s I is 0.3, indicating that there is some degree of spatially clustering.\nWe can use the simulated data to plot the probability distribution of Moran’s I.\n\nmcdata <- as_tibble(bperm$res)\n\nggplot(data=mcdata) +\n  geom_histogram(aes(x=value), \n                 colour=\"black\",\n                 fill=\"light blue\", bins=30) +\n  geom_vline(xintercept=0,\n             colour=\"black\",\n             linetype=\"dashed\") +\n  geom_vline(xintercept=mean(mcdata$value),\n             colour=\"red\") +\n  annotate(geom = \"text\",\n           label=paste0(\"mean =\\n\",\n                        signif(mean(mcdata$value), 3)),\n           x=-0.043,\n           y=139) +\n  ylim(0, 150) +\n  labs(title=\"Simulated Moran's I\",\n       x=\"Simulated Moran's I\", \n       y=\"Frequency\") +\n  theme_bw()\n\n\n\n\nThis is the sampling distribution of Moran’s I, which is approximately a normal distribution. The null hypothesis is the Moran’s I <=0 (although the sample mean is actually slightly less than 0). If the null hypothesis is true, it is unlikely to get values more than 0. From the distribution, we can see that it is unlikely to get the computed Moran’s I of 0.3 if the null hypothesis hold true. As such, we can reject the null hypothesis and conclude that there is clustering observed in the GDP per capita in Hunan.\n\n\n\nGeary’s C test is another method to measure spatial autocorrelation. The geary.test() function from the spdep package is used to perform this test. The Geary C test statistic lies between 0 and 3 with 0 meaning perfect clustering, 1 meaning random distribution and 3 meaning perfect dispersion.\n\ngeary.test(hunan$GDPPC, \n           listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nThe null hypothesis is that Geary’s C >=1 (randomly distributed or perfected dispersed). At 5% significance level, we can reject the null hypothesis and conclude that C <1. The value of 0.69 indicates that GDP per capita is spatially clustered.\n\n\n\nA spatial correlogram can be used to visualise patterns of spatial autocorrelation with increasing lags (distance). Logically, correlation should decrease with more lags. Increasing lags means that we are testing if further locations are correlated with an area. The y-axis is usually Moran’s I or Geary’s C.\nThe code chunk below generates a spatial correlogram using Moran’s I. As the order of contiguity increases, GDP per capita is less correlated, which is to be expected.\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nWe can also view the detail test statistics to check significance of results.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe code chunk below generates a spatial correlogram using Geary’s C. As the order of contiguity increases, GDP per capita is less correlated.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nLocal indicators spatial autocorrelation (LISA) are used to evaluate the existence of clusters and outliers in the spatial arrangement of a variable. The difference between global and local indicators of spatial autocorrelation is that local indicators are computed for each observation. Each value measures the extent of significant spatial clustering of similar values around that observation.\n\n\nLocal Moran’s I can be computed using the localmoran() function. The first line of the code creates a list of the indices by alphabetical order of county name. It will be used later to order the local Moran’s I test output.\n\nfips <- order(hunan$County)\n\nlocalMI <- localmoran(hunan$GDPPC,\n                      rswm_q)\n\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() outputs the following:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local Moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local Moran statistic under the randomisation hypothesis\nZ.Ii: the standard deviation of local Moran statistic\nPr(): the p-value of local Moran statistic\n\nIn this case, the null hypotheses are that GDP per capita are randomly distributed around each area. The default is the two-sided test shown, but this can be adjusted in the arguments of the localmoran() function.\nThe following code chunk prints all the local Moran’s I statistics:\n\nprintCoefmat(data.frame(localMI[fips,], \n                        row.names=hunan$County[fips]), \n             check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n\nTo map the local Moran’s I, first we need to join it to the spatial data.\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nNow, we can create the map.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style=\"pretty\",\n          palette =\"RdBu\",\n          title=\"Local Moran Statistics\") +\n  tm_borders(alpha=0.5)\n\nlocalMI.map\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nThe map seems to indicate that there is a high degree of clustering in some of the north-eastern counties. Some counties have low local Moran’s I, indicating that GDP per capita in surrounding counties are dispersed.\nHowever, this map alone is not enough to conclude if there is not is no clustering of values. We need the p-values as well to evaluate whether the local Moran’s I statistic for each area is significant.\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette =\"-Blues\",\n          title=\"Local Moran's I p-values\") +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(localMI.map, pvalue.map,\n             asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nUsing these 2 maps, we can conclude that there is indeed clustering in some of the north eastern counties. However, the Moran’s I statistic of counties with high degree dispersion indicated in the first map were not significant and hence we cannot reject the null hypothesis that values were randomly.\n\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations. We can plot this using the moran.plot() function.\n\nmoran.plot(hunan$GDPPC,\n           rswm_q,\n           labels=as.character(hunan$County),\n           xlab=\"GDP per capita\",\n           ylab=\"Spatially lagged GDP per capita\")\n\n\n\n\nThe scatterplot is split into 4 quadrants. The x-axis is the actual GDP per capita and the y-axis is the spatially lagged GDP per capita. A higher spatially lagged GDP per capita means the surrounding neighbours have high GDP per capita.\nUpper right: Contains observations with high spatially lagged and actual GDP per capita, indicating positive autocorrelation and clustering of high values.\nLower left: Contains low spatially lagged and actual GDP per capita, indicating positive autocorrelation and clustering of low values.\nUpper left: High spatially lagged GDP per capita and low actual GDP per capita, indicating negative autocorrelation. These observations are outliers with low GDP per capita among neighbours with high GDP per capita.\nLower right: Low spatially lagged GDP per capita and high actual GDP per capita, indicating negative autocorrelation. These observations are outliers with high GDP per capita among neighbours with low GDP per capita.\n This scatterplot still does not take into account whether the values are statistically significant so we still need to refine this further.\n\n\n\nFirst, we center GDP per capita and local Moran’s I around their means. We can then assign each observation to a quadrant depending on whether it is above or below mean GDP per capita and above or below the mean Moran’s I. We also create a quadrant 0 for observations that are not statistically significant. Note that the logical statement for quadrant 0 must be the first as we want it to be prioritised over the other criteria.\n\nhunan.localMI <- hunan.localMI %>%\n  mutate(C_mI = Ii - mean(Ii)) %>%\n  mutate(DV = GDPPC- mean(GDPPC)) %>%\n  mutate(quadrant = case_when(\n    Pr.Ii >0.05 ~0,\n    DV>0 & C_mI>0 ~4, #high-high cluster\n    DV<0 & C_mI<0 ~2, #low-high outlier\n    DV<0 & C_mI>0 ~1, #low-low cluster\n    DV>0 & C_mI<0 ~3)) #high-low outlier\n\nWe can now build the LISA map:\n\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col=\"quadrant\",\n          style=\"cat\",\n          palette = colors,\n          label = clusters,\n          popup.vars=c(\"\")) +\n  tm_view(set.zoom.limits=c(11,17))+\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = \"LISA Clustering\")\n\nLISAmap\n\n\n\n\nFor proper analysis, we should actual GDp per capita next to the LISA map.\n\ntmap_arrange(quantile, LISAmap,\n             asp=1, ncol=2)\n\n\n\n\nFrom the maps, we can see that there is a cluster of high GDP per capita counties in the northeast. There are 2 outlier counties in the with low GDP per capita near this the high cluster. In the southeast, there is a cluster of low GDP per capita.\n\n\n\nLocal spatial statistics can also be used to detect hot spots and cold spots. One such measure is Getis and Ord’s G-statistics. It examines neighbours within a defined proximity to identify where either high or low values clutser spatially.\nInstead of contiguous neighbours, it uses neighbours with a specified distance. As such, we need to find the centroids of each county to develop a distance spatial weight matrix. The following code chunk creates an object with longitude and latitudes extracted using the st_centroid() function.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude, latitude)\n\nNext, we need to determine the maximum distance to consider counties as neighbours in the spatial matrix. The following code chunk uses knearneigh() to find the k nearest neighbours to each centroid (k=1 by default) and stores the indices of the nearest neighbours as list k1. The second line of code uses nbdists() to find the distance between each pair of neighbours . unlist() is needed to extract the distances from the list object. Lastly, we get some summary statistics on distance to nearest neighbours.\n\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe furtherest nearest neighbour is 61.79km away, so using this as the maximum distance will ensure that each county will have at least one neighbour.\nThe following code chunk creates a distance weight matrix (list of the the indices of neighbours within 62km radius of each centroid).\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThen, we convert the matrix to binary format with the nb2listw() function.\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nThe localG() function is used to compute the G statistic of each county with respect to GDP per capita.\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nIt outputs a list of the G statistic for each county (in terms of a z-value). High positive values indicate the posibility of a local cluster of high values of the variable being analysed, very low relative values a similar cluster of low values.\nWe then join the G statistics to the base dataset.\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nWe can see that there is a hotspot of high GDP per capita in the northeast of Hunan province.\n\n\n\nThe previous section computed Gi using a fixed weighting scheme where the distance is fixed and the number of neighbours considered depends on density of neighbours. Another method to compute Gi is to use an adaptive weighting scheme that considers a fixed number of nearest neighbours. The size of the neighbourhood considered will depend on the density of points.\n\nk8 <- knn2nb(knearneigh(coords,\n                        k=8))\nk8\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nk8_lw <- nb2listw(k8, style = 'B')\nsummary(k8_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\nNow to recompute Gi using the new weights matrix and generate the new map.\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, k8_lw)\n\nhunan.gi <- cbind(hunan.gi, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap1 <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi (Fixed)\") + \n  tm_borders(alpha = 0.5)\n\nGimap2 <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi (Adaptive)\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap1,\n             Gimap2,\n             asp=1, \n             ncol=3)\n\nSome legend labels were too wide. These labels have been resized to 0.47, 0.47, 0.47, 0.43. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nUnder the adaptive weightage scheme, there are more non-zero links. We can infer that in general a larger neighbourhood is considered for each county. This is likely especially so for counties on the border. This could explain the additional hotspot on the northeastern border. There are also fewer coldspots compared to the fixed scheme.\n\n\n\n\nhttps://gisgeography.com/spatial-autocorrelation-moran-i-gis/\nhttps://medium.com/locale-ai/spatial-autocorrelation-how-spatial-objects-affect-other-nearby-spatial-objects-e05fa7d43de8\nhttps://www.statology.org/morans-i/\nhttps://storymaps.arcgis.com/stories/5b26f25bb81a437b89003423505e2f71"
  },
  {
    "objectID": "Take-home_EX01/Take-home_EX01.html",
    "href": "Take-home_EX01/Take-home_EX01.html",
    "title": "Take-Home Exercise 01",
    "section": "",
    "text": "The purpose of this study is to understand the spatial patterns of functional and non-functional water points in Nigeria.\n\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\nfunModeling: quick exploratory data analysis\n\n\npackages = c('sf', 'tidyverse', 'spdep', 'tmap', 'funModeling', 'kableExtra')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p,character.only = T)\n}\n\n\n\n\nThe water point data is collected by the Water Point Data Exchange (WPdx) whose goal is to improve water access to rural communities by providing data to enable data-driven decision making. The dataset can be found here and the data dictionary here. The data is in csv format with latitude and longitude information.\n\nwp <- read_csv(\"data/WPdx_plus_Nigeria.csv\")\n\nRows: 95008 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): #status_clean\ndbl (2): #lat_deg, #lon_deg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nDue to the size of the dataset, it has already been pre-processed to keep only entries in Nigeria and some unused variables have been removed. The following code was used to pre-process the raw data file “WPdx_plus_full.csv” from the website but is not run on this page (raw data file is also not found on GitHub).\n\nwp <- read_csv(\"data/WPdx_plus_full.csv\") %>%\n  filter(`#clean_country_name`==\"Nigeria\") %>%\n  select(c(3:4, 22)) %>%\n  write_csv(\"data/WPdx_plus_Nigeria.csv\")\n\n\nglimpse(wp)\n\nRows: 95,008\nColumns: 3\n$ `#lat_deg`      <dbl> 7.980000, 6.964532, 6.486940, 6.727570, 6.779900, 6.95…\n$ `#lon_deg`      <dbl> 5.120000, 3.597668, 7.929720, 7.648670, 7.664850, 7.77…\n$ `#status_clean` <chr> NA, \"Functional\", NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nWe can see that the variable names have some special characters which is not ideal. There are also a lot of NA values in the variable of interest (#status_clean). The following code chunk cleans the variable names and replaces the NA values with “Unknown”.\n\nwp <- wp %>%\n  rename_with(~str_replace(.x, \"#\", \"\")) %>%\n  mutate(status_clean=replace_na(status_clean, \"Unknown\"))\n\nLet’s check the values of status_clean.\n\nwp %>%\n  group_by(status_clean) %>%\n  summarise(n=n()) %>%\n  ungroup() %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    status_clean \n    n \n  \n \n\n  \n    Abandoned \n    175 \n  \n  \n    Abandoned/Decommissioned \n    234 \n  \n  \n    Functional \n    45883 \n  \n  \n    Functional but needs repair \n    4579 \n  \n  \n    Functional but not in use \n    1686 \n  \n  \n    Non-Functional \n    29385 \n  \n  \n    Non-Functional due to dry season \n    2403 \n  \n  \n    Non functional due to dry season \n    7 \n  \n  \n    Unknown \n    10656 \n  \n\n\n\n\n\nThe categories are more detailed than we need to study the proportion of functional and non-functional waterpoints. The following code chunk collapses the categories into 3 categories: “Functional”, “Nonfunctional” and “Unknown”.\n\nwp <- wp %>%\n  mutate(status = case_when(\n    status_clean %in% c(\"Abandoned/Decommissioned\", \n                        \"Abandoned\",\n                        \"Non-Functional\",\n                        \"Non functional due to dry season\",\n                        \"Non-Functional due to dry season\") ~ \"Nonfunctional\",\n    status_clean == \"Unknown\" ~ \"Unknown\",\n    status_clean %in% c(\"Functional\", \n                        \"Functional but not in use\",\n                        \"Functional but needs repair\") ~ \"Functional\"\n  ))\n\nLet’s visualise the proportions of functionality of the waterpoints. On the whole, only 55% of waterpoints are functional.\n\nfreq(wp, input=\"status\")\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n         status frequency percentage cumulative_perc\n1    Functional     52148      54.89           54.89\n2 Nonfunctional     32204      33.90           88.79\n3       Unknown     10656      11.22          100.00\n\n\nNow, I convert the aspatial data into geospatial point data from the latitude and longitude variables using the st_as_sf() function. The GCS of the data is WGS1984 (EPSG:4326) as stated in the data dictionary.\n\nwp_sf <- st_as_sf(wp, \n                  coords = c(\"lon_deg\", \"lat_deg\"),\n                  crs=4326) \n\n\n\n\nI will also use the Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon dataset from geoBoundaries.\n\nadm_bound <- st_read(dsn=\"data\",\n               layer=\"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\lins-92\\ISSS624\\Take-home_EX01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(adm_bound)\n\nRows: 774\nColumns: 6\n$ shapeName  <chr> \"Aba North\", \"Aba South\", \"Abadam\", \"Abaji\", \"Abak\", \"Abaka…\n$ Level      <chr> \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"AD…\n$ shapeID    <chr> \"NGA-ADM2-72505758B79815894\", \"NGA-ADM2-72505758B67905963\",…\n$ shapeGroup <chr> \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NG…\n$ shapeType  <chr> \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"AD…\n$ geometry   <MULTIPOLYGON [°]> MULTIPOLYGON (((7.401109 5...., MULTIPOLYGON (…\n\n\nLet’s check what the Nigeria Level-2 Administrative Boundary and water points data looks like.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(adm_bound) +\n  tm_polygons() +\n  tm_text(\"shapeName\", size=0.2) +\ntm_shape(wp_sf) +\n  tm_symbols(size=0.1)\n\n\n\n\n\n\n\n\nNow I have 2 geospatial datasets: a point dataset with waterpoint locations and a polygon data with administrative boundaries. I still need to count the number of points by status for each administrative area.\nI will use the st_join() function to do a spatial join to relate the polygon IDs to each waterpoint by its location (note that the shapeName variable contains duplicates and should not be used for this step). The join=st_intersects() argument tells R the type of spatial join to use. Note that both datasets must have the same projection (WGS1984), which is why we have not transformed either dataset yet.\n\nwp_named <- st_join(x = wp_sf,\n                    y = adm_bound,\n                    join = st_intersects,\n                    left = TRUE)\n\nNext, we need check if there are any missing values.\n\nsum(is.na(wp_named$shapeID))\n\n[1] 29\n\n\nWe can plot the points to visually check why these points are missing polygon IDs. Most likely it is because they fall outside any administrative area. If so, we can safely ignore these points.\nSetting tmap_mode(\"view\") creates an interactive plot so we can zoom in to check the points. In addition, tm_dots() is used instead of tm_shape() this time so that the size of each point scales dynamically when zooming in on the interactive map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(adm_bound) +\n  tm_polygons() +\ntm_shape(filter(wp_named, is.na(shapeID))) +\n  tm_dots(size=0.1,\n          col=\"red\")\n\n\n\n\n\n\nWe can see that these 29 points fall outside the boundary of Nigeria so we can exclude them.\nNow let’s extract the number of waterpoints by status in each administrative boundary and join it to the administrative boundary polygon layer. First, I need to remove the geometry data using the st_drop_geometry() function to manipulate it like a regular dataframe using tidyr and dplyr functions.\nThe next step is to group by administrative area name and status to generate the count. Lastly, we pivot from long to wide format for joining with the administrative boundary dataset such. The values_fill=0 argument replaces any na values in the values_from variable with 0.\n\nprop <- wp_named %>%\n  st_drop_geometry() %>%\n  group_by(shapeID, status) %>%\n  summarise(n=n()) %>%\n  ungroup() %>%\n  pivot_wider(id_cols=shapeID,\n              names_from=status,\n              values_from=n, \n              values_fill=0)\n\n`summarise()` has grouped output by 'shapeID'. You can override using the\n`.groups` argument.\n\nhead(prop, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    shapeID \n    Functional \n    Nonfunctional \n    Unknown \n  \n \n\n  \n    NGA-ADM2-72505758B10049836 \n    31 \n    39 \n    0 \n  \n  \n    NGA-ADM2-72505758B10063467 \n    50 \n    38 \n    30 \n  \n  \n    NGA-ADM2-72505758B10065661 \n    104 \n    51 \n    23 \n  \n  \n    NGA-ADM2-72505758B10302610 \n    64 \n    53 \n    84 \n  \n  \n    NGA-ADM2-72505758B11317593 \n    51 \n    49 \n    0 \n  \n\n\n\n\n\nNow, we use left_join() to join the counts to the administrative boundary geospatial data. As this is the final dataset we will be working on, we can transform the projection to EPSG:26391. We also need to replace any na counts with 0. There are still na counts in this step because some polygons may not have any waterpoints and would not have been addressed in the previous step. Lastly, we add a new variable for total number of waterpoints.\n\nadm_wp <- left_join(x=adm_bound,\n                    y=prop,\n                    by=\"shapeID\") %>%\n  mutate(across(c(6:8), ~replace_na(.x, 0))) %>%\n  mutate(Total = Functional + Nonfunctional + Unknown) %>%\n  st_transform(crs = 26391)\n\n\n\nFinally, we can plot the number of waterpoints by status in each administrative area.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntotal <- qtm(adm_wp, \"Total\")\nfunc <- qtm(adm_wp, \"Functional\")\nnonfunc <- qtm(adm_wp, \"Nonfunctional\")\nunknown <- qtm(adm_wp, \"Unknown\")\n\ntmap_arrange(total, func, nonfunc, unknown,\n             asp=1, ncol=2, nrow=2)\n\n\n\n\nThe distribution of waterpoints across Nigeria does not appear to be evenly distributed. There are some small administrative areas with many waterpoints in the central north. Based on the distribution of waterpoints of unknown status, we can infer that the north of Nigeria is likely more developed because there are fewer waterpoints of unknown status; likewise, central Nigeria may not be as developed because there is a higher number of waterpoints of unknown or non-functional status.\nThe next 3 code chunks plot waterpoints using quantile breaks. We can also add a histogram to view the distribution of total waterpoints.\n\ntm_shape(adm_wp)+\n  tm_polygons(\"Total\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              legend.hist=TRUE) +\n  tm_layout(main.title=\"Total Waterpoints in Nigeria\",\n            main.title.size=1.1,\n            title.snap.to.legend=FALSE,\n            legend.outside=TRUE,\n            legend.hist.width = 1.1)\n\n\n\n\nFrom this map, we can see that the north-east and south of Nigeria tend to have fewer waterpoints. More than 60% of administrative areas have less than 200 waterpoints. As we do not know the population or water demand of each administrative area, it is difficult to say which areas are water stressed or need additional water infrastructure.\n\ntm_shape(adm_wp)+\n  tm_polygons(\"Functional\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              legend.hist=TRUE) +\n  tm_layout(main.title=\"Functional Waterpoints in Nigeria\",\n            main.title.size=1.1,\n            title.snap.to.legend=FALSE,\n            legend.outside=TRUE,\n            legend.hist.width = 1.1)\n\n\n\n\n\ntm_shape(adm_wp)+\n  tm_polygons(\"Nonfunctional\",\n              style=\"quantile\",\n              palette=\"-RdBu\",\n              legend.hist=TRUE) +\n  tm_layout(main.title=\"Non-Functional Waterpoints in Nigeria\",\n            main.title.size=1.1,\n            title.snap.to.legend=FALSE,\n            legend.outside=TRUE,\n            legend.hist.width = 1.1)\n\n\n\n\nFrom the maps above, it would seem that areas with many waterpoints tend to have many functional and non-functional waterpoints as well. As such, to assess the state of maintenance of waterpoints in each administrative area, it would be better to map the proportion of functional and non-functional waterpoints out of the total number of waterpoints.\n\n\n\nFirst, we need to generate new variables for proportions. There are some administrative areas without any waterpoints which will result is na values for the proportions. We do not replace these na values with 0 because it will affect the subsequent analysis. We will need to be careful to exclude na values in the subsequent steps. We also should not remove these values because it will affect the neighbourhood structure when conducting spatial analysis.\nThere are 2 problems with replacing them with 0:\n\n0 values represent a low proportion of functional/non-functional waterpoints. This is inaccurate since there were no waterpoints at all. Using 0 may skew the spatial distribution and clustering analysis.\nThese areas will appear to have low proportions for both functional and non-functional waterpoints. The relationship between should be negative.\n\n\nadm_wp <-adm_wp %>%\n  mutate(pFunctional = Functional/Total,\n         pNonfunctional = Nonfunctional/Total,\n         pUnknown = Unknown/Total) \n\nThe following plot shows the number of non-functional waterpoints out of total waterpoints by administrative area. It is sorted by descending order of proportion of non-functional waterpoints using the reorder() function.\nWe can see that there are some administrative areas on the left side of the plot with some few waterpoints and most of them are non-functional. Repairs should be focused on such areas with fewer waterpoints and high percentage that are non-functional.\n\nggplot(adm_wp) +\n  geom_bar(aes(x=reorder(shapeID, pNonfunctional, decreasing=TRUE), \n               y=Total,\n               fill=\"Total\"),\n           stat=\"identity\") +\n    geom_bar(aes(x=reorder(shapeID, pNonfunctional, decreasing=TRUE), \n               y=Nonfunctional,\n               fill=\"Non-functional\"),\n           stat=\"identity\",\n           alpha=0.8) +\n  scale_fill_manual(name=\"\",\n                    values=c(\"red\", \"gray30\")) +\n  labs(title=\"Number of Water by Administrative Area\",\n       subtitle=\"(sorted by proportion of non-functional)\",\n       y=\"Number of waterpoints\",\n       x=\"Administrative Areas\")+\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        axis.line.y=element_line(colour=\"grey50\"))\n\n\n\n\nNow let’s plot the proportions spatially.\n\ntotal <- tm_shape(adm_wp)+\n  tm_polygons(\"Total\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Total waterpoints\")\n\nfunc <- tm_shape(adm_wp)+\n  tm_polygons(\"pFunctional\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Proportion functional\")\n\nnonfunc <- tm_shape(adm_wp)+\n  tm_polygons(\"pNonfunctional\",\n              style=\"quantile\",\n              palette=\"-RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Proportion non-functional\")\n\nunknown <- tm_shape(adm_wp)+\n  tm_polygons(\"pUnknown\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Proportion unknown\")\n\ntmap_arrange(total, func, nonfunc, unknown,\n             asp=1, ncol=2, nrow=2)\n\n\n\n\nWe can see that many administrative areas in the north have more waterpoints and a higher proportion of functional waterpoints. Many states in the south part of Nigeria have few waterpoints a high proportion of non-functional waterpoints.\nThe spatial distribution of waterpoints could be influenced by climate and population distribution (see maps below). The south of Nigeria has a tropical climate (and thus higher rainfall) which could mean less reliance on man-made waterpoints and thus there are fewer waterpoints. On the other hand, many regions in the north of Nigeria have a high proportion of functional waterpoints, possibly because of the high reliance on them due to the arid climate.\nAreas with higher population also tend to have more waterpoints.\n\n\n\n\n\n\nKoppen-Geiger climate classification map for Nigeria. Source: Beck, H. E., et al. (2018)\n\n\n\n\n\n\n\nPopulation density in Nigeria. Source: Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFrom plotting the total number of waterpoints and the proportion of functional waterpoints, we can visually see that waterpoints may not be evenly distributed across space in Nigeria. To confirm our intuition from visual inspection, we can test it statistically using global and local spatial autocorrelation statistics.\n\n\nFirst, we must define the neighbourhood to be considered for each administrative area. There are a number of methods to do this (see In-Class Exercise 1). Contiguity matrices only consider polygons that are immediately adjacent while distance matrices use distance to determine the neighbour. The choice of weight matrix can affect the results of the analysis. For this exercise, I will try 2 methods: inverse-distance contiguity weight matrix and adaptive distance weight matrix.\nContiguity Weight Matrix\nFirst, I create an nb object listing the neighbours of each administrative area. Queen method will be used to identify the adjacent neighbours. From the summary below, we can see that on average each administrative area is contiguous with about 6 other polygons. However, there is 1 administrative area which does not have any contiguous neighbours. It is likely an island. This means that a contiguity matrix is not suitable for this analysis.\n\nwm_q <- poly2nb(adm_wp, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 4440 \nPercentage nonzero weights: 0.7411414 \nAverage number of links: 5.736434 \n1 region with no links:\n86\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  14 \n  1   2  14  57 125 182 140 122  72  41  12   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nAdaptive Distance Weight Matrix\nAn adaptive distance weight matrix sets the fixed number of neighbours for each study area. It is usually used if there is large variation in polygon sizes but we need to set a consistent scale of analysis by considering the same number of neighbours for each area.\nFirst, we need to find the centroids of each polygon. These will be used to determine the distances between polygons to set the neighbourhood.\n\nlongitude <- map_dbl(adm_wp$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(adm_wp$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude/1000, latitude/1000)\n\nIn this exercise, I will fix the number of neighbours at 8 [1]. The knearneigh() function takes the coordinates and finds the 8 nearest neighbours of each polygon. We then convert it to an nb object using knn2nb() function. lastly, nb2listw() generates the spatial weight matrix from the nb object.\n\nk8 <- knn2nb(knearneigh(coords, k=8))\nk8\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 6192 \nPercentage nonzero weights: 1.033592 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nk8_lw <- nb2listw(k8, style=\"B\",\n                  zero.policy=TRUE)\n\n\n\n\nThe global Moran’s I test is intended to test if the independent variable (total waterpoints, proportion of functional and non-functional waterpoints) is evenly distributed, randomly distributed or clustered. Since we do not know the underlying distribution of waterpoints, we use Monte Carlo simulations (n=1000) to simulate randomly distribution of proportions spatially.\nNote that that we must set na.action=na.exclude because there are na values in pFunctional and pNonfunctional. Because we omit these values, some areas may have less than 8 neighbours.\n\nset.seed=123\n\nmoran.mc(adm_wp$Total, \n         listw=k8_lw, \n         nsim=999,\n         zero.policy = TRUE, \n         na.action=na.exclude)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  adm_wp$Total \nweights: k8_lw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.49306, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe above test shows that there is spatial clustering of waterpoints in Nigeria. The Moran’s I statistic of 0.49 is significant at the 5% significance level. We can reject the null hypothesis (that total waterpoints is randomly distributed spatially) and conclude that there isspatial clustering of waterpoints in Nigeria.\n\nset.seed=123\n\nmoran.mc(adm_wp$pFunctional, \n         listw=k8_lw, \n         nsim=999,\n         zero.policy = TRUE, \n         na.action=na.exclude)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  adm_wp$pFunctional \nweights: k8_lw \nomitted: 3, 86, 241, 250, 252, 261, 400, 406, 447, 473, 492, 507, 526 \nnumber of simulations + 1: 1000 \n\nstatistic = 0.52454, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nset.seed=123\n\nmoran.mc(adm_wp$pNonfunctional, \n         listw=k8_lw, \n         nsim=999,\n         zero.policy = TRUE, \n         na.action=na.exclude)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  adm_wp$pNonfunctional \nweights: k8_lw \nomitted: 3, 86, 241, 250, 252, 261, 400, 406, 447, 473, 492, 507, 526 \nnumber of simulations + 1: 1000 \n\nstatistic = 0.44023, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe computed Moran’s I of 0.52 (p-value=0.001) and 0.44 (p-value=0.001) for the proportions of functional and non-functional waterpoints respectively are significant at the 5% significance level. This indicates that there is some degree of clustering of proportions of functional and non-functional waterpoints.\n\n\n\n\nHotspots and coldspots can be detected using the local Moran’s I statistics. Unlike the global Moran’s I test, the local Moran’s I test calculates the test statistics for each observation. Each value measures the extent of significant spatial clustering of similar values around that observation.\nThe following code chunk conducts the local MI test and saves the result to a dataframe for both proportion of functional and non-functional waterpoints. The Moran’s I statistics and p-values are then joined to the polygon data to plot in a map.\n\nlocalMI.func <- localmoran(adm_wp$pFunctional,\n                           k8_lw, \n                           na.action=na.exclude,\n                           zero.policy=TRUE)\nlocalMI.func <- data.frame(localMI.func)%>%\n  select(c(1,5)) %>%\n  rename(func.Ii = Ii,\n         func.Pr = Pr.z....E.Ii..)\n\nlocalMI.nonfunc <- localmoran(adm_wp$pNonfunctional,\n                              k8_lw,\n                              na.action=na.exclude,\n                              zero.policy=TRUE)\nlocalMI.nonfunc <- data.frame(localMI.nonfunc)%>%\n  select(c(1,5)) %>%\n  rename(nonfunc.Ii = Ii,\n         nonfunc.Pr = Pr.z....E.Ii..)\n\nadm_wp.localMI <- cbind(adm_wp, localMI.func, localMI.nonfunc) \n\nThe local Moran’s score alone is not enough to show spatial clustering because it does not tell us whether the value of the variable being tested (proportion of functional/non-functional waterpoints) is high or low and whether the test result was significant. As such, we assign each observation to a quadrant depending on the value of the variable on the y-axis (centred around the mean) and Moran’s I on the x-axis. Quadrant 1 contains coldspots and quadrant contains hotspots. The following table explains the the quadrants:\n\nThe following code create 2 new variables each for proportion of functional and non-functional waterpoints. One for the centered proportion (around the mean) and the quadrant that the observation belong to. Note that we must include the na.rm=TRUE argument when computing mean because our data has na values. We also create a quadrant zero if the test statistic is not significant and the null hypothesis of random distribution cannot be rejected.\n\nadm_wp.localMI <- adm_wp.localMI %>%\n  mutate(DV.func = pFunctional- mean(pFunctional, na.rm=TRUE)) %>%\n  mutate(func.quadrant = case_when(\n    func.Pr >0.05 ~0,\n    DV.func<0 & func.Ii>0 ~1, \n    DV.func<0 & func.Ii<0 ~2,\n    DV.func>0 & func.Ii<0 ~3,\n    DV.func>0 & func.Ii>0 ~4)) %>% \n  mutate(DV.nonfunc = pNonfunctional- mean(pNonfunctional, na.rm=TRUE)) %>%\n  mutate(nonfunc.quadrant = case_when(\n    nonfunc.Pr >0.05 ~0,\n    DV.nonfunc<0 & nonfunc.Ii>0 ~1, \n    DV.nonfunc<0 & nonfunc.Ii<0 ~2, \n    DV.nonfunc>0 & nonfunc.Ii<0 ~3,\n    DV.nonfunc>0 & nonfunc.Ii>0 ~4)) \n\nPlot LISA cluster map:\n\npfunc.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"pFunctional\", \n          style=\"quantile\",\n          title=\"Proportion\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"Proportion Functional\")\n\npnonfunc.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"pNonfunctional\", \n          style=\"quantile\",\n          title=\"Proportion\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"Proportion Non-functional\")\n\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nlocalMI.func.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"func.quadrant\", \n          style=\"cat\",\n          palette =colors,\n          label=clusters,\n          title=\"Quadrant\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"LISA Cluster (Functional)\")\n\nlocalMI.nonfunc.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"nonfunc.quadrant\", \n          style=\"cat\",\n          palette =colors,\n          label=clusters,\n          title=\"Quadrant\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"LISA Cluster (Non-Functional)\")\n\ntmap_arrange(pfunc.map, localMI.func.map, \n             pnonfunc.map, localMI.nonfunc.map,\n             asp=1, ncol=2, nrow=2)\n\n\n\n\nThe LISA cluster maps clearly show that there is clustering in the proportion of functional/non-functional waterpoints. There is a hotspot for functional waterpoints in the central north of Nigeria. There is also a coldspot in the southeast where a custer of regions have low proportion of functional waterpints. This area is an area of concern for maintenance efforts. There are not many outliers.\nThere is a coldspot of non-functional waterpoints in the central north of Nigeria that overlaps with the hotspot of functional waterpoints. This is logical as the proportions have an negative relationship. If the proportion of functional waterpoints is high, the proportion of non-functional waterpoints should be low.\nHowever, we see a different story in the south where there is a hotspot of non-functional waterpoint areas and no corresponding hotspot for functional waterpoint. This could be due to a difference in the centring of the proportions. From the code chunk below, we see that the mean proportion of non-functioning waterpoints is much lower than that of functional waterpoints (because there are unknowns as well). The threshold to be classified as a high non-functional area is lower than the threshold to be classified as a low functional area.\n\nmean(adm_wp$pFunctional, na.rm=TRUE)\n\n[1] 0.5069513\n\nmean(adm_wp$pNonfunctional, na.rm=TRUE)\n\n[1] 0.3653858\n\n\nThe 3 hotspot of high proportion of non-functional waterpoints in the south and west of Nigeria are a cause for concern for maintenance efforts.\n\n\n\nThe analysis showed there is clearly uneven distribution of waterpoints in Nigeria, and there is uneven distribution of available (functional) waterpoints. There were significant hotspots with high proportion of non-functional waterpoints which could be indicative of underlying problems in the maintenance regimes. Nonetheless, further analysis should be conducted considering population or water demand to determine water stress and decide on high priority areas to add waterpoints or step up maintenance.\n\n\n\n[1] https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/generate-spatial-weights-matrix.htm"
  },
  {
    "objectID": "In-class_EX02/In-class_EX02.html",
    "href": "In-class_EX02/In-class_EX02.html",
    "title": "In-Class Exercise 2",
    "section": "",
    "text": "This exercise is to prepare the datasets for take-home exercise 1 on analysing availability of waterpoints in Nigeria. The details of the exercise can be found here.\n\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\nfunModeling: quick EDA\n\n\npacman::p_load(sf, tidyverse, tmap, spdep, funModeling)\n\n\n\n\nThe waterpoint dataset is downloaded from here and the data dictionary here. The file has been saved as “Wdx_plus_full.csv”. In this exercise, I will use the csv format. Although the shp file format would be preferable, I was unable to complete the download without the file getting corrupted. Nonetheless, we can simply use the longitude and latitude data provided to convert it to an sf object.\nThe following code imports the waterpoint dataset and keeps only the datapoints from Nigeria.\n\nwp_csv <- read_csv(\"data/WPdx_plus_full.csv\") %>%\n  filter(`#clean_country_name`==\"Nigeria\")\n\n\nglimpse(wp_csv)\n\nWe can see that we do not need most of the variables to analyse the status of waterpoints. The following code chunk keeps only the relevant variables and removes the special characters from the variable names.\n\nwp_csv <- wp_csv %>%\n  select(c(3:4, 22))%>%\n  rename_with(~str_replace(.x, \"#\", \"\"))\n\nNow we can convert it to sf format. From the data dictionary, we know that the original GCS of the data is WGS1984 (EPSG:4326) from the data dictionary. We need to project it to the EPSG:26391 CRS later. However, as we will be using the st_intersects() function later, we will keep retain the EPSG:4326 GCS first.\n\nwp <- st_as_sf(wp_csv, \n               coords = c(\"lon_deg\", \"lat_deg\"),\n               crs=4326)\n\nNow we save the smaller version of the file.\n\nwrite_rds(wp, \"data/wp_nga.rds\")\n\n\n\n\nThis exercise also usess the Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon dataset from geoBoundaries.\n\nnga <- st_read(dsn = \"data\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\lins-92\\ISSS624\\In-class_EX02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\nThe following code chunk imports the reduced waterpoint data file which was saved with geometries. We perform some further cleaning by replacing the na values in the status_clean variable as “Unknown”.\n\nwp_nga <- read_rds(\"data/wp_nga.rds\") %>%\n  mutate(status_clean = replace_na(status_clean, \"Unknown\"))\n\nWe can use the freq() function of the funModeling package to plot the distribution of status of waterpoints.\n\nfreq(data=wp_nga, \n     input = 'status_clean')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                          Unknown     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nThere are types of status but we only really need to know whether the water point is functional or not. Those that were na values will continue to be categorised as unknown status.\n\n\n\nwpt_functional <- wp_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\", \n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nfreq(data=wpt_functional, \n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\n\n\n\nwpt_nonfunctional <- wp_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\n\nfreq(data=wpt_nonfunctional, \n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00\n\n\n\n\n\n\nwpt_unknown <- wp_nga %>%\n  filter(status_clean == \"Unknown\")\n\n\n\n\nThe following code chunk counts the number of points (functional, non-functional and unknown separately) in each polygon of the administrative boundary data and saves type each as a variable in the administrative data attribute table.\n\nnga_wp <- nga %>% \n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown)))\n\nNext, we compute the proportions of functional and non-functional waterpoints for each area. We can also perform the transformation now since we have done the st_intersects() already. Save the file.\n\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%\n  st_transform(crs = 26391) %>%\n  write_rds(\"data/nga_wp.rds\")\n\n\n\n\n\n\nnga_wp <- read_rds(\"data/nga_wp.rds\")\ntotal <- qtm(nga_wp, \"total wpt\")\nwp_functional <- qtm(nga_wp, \"wpt functional\")\nwp_nonfunctional <- qtm(nga_wp, \"wpt non-functional\")\nunknown <- qtm(nga_wp, \"wpt unknown\")\n\ntmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_EX03/Hands-on_EX03.html",
    "href": "Hands-on_EX03/Hands-on_EX03.html",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. This exercise is to practice geographical segmentation techniques. Geographical segmentation delineates a homogeneous region by using geographically referenced multivariate data. We will also conduct aspatial hierarchical clustering on the dataset for comparison.\nIn this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\nThere are the packages that will be used:\n\nsf, rgdal and spdep: spatial data handling and spatial weights\ntidyverse: manipulation of attribute data and plotting visualisations (aspatial)\ntmap: creating map visualisations\ncoorplot, ggpubr, heatmaply and GGally: multivariate data analysis and visualisation\ncluster, factoextra, dendextend, nbclust and clustGeo: cluster analysis\n\n\npacman::p_load(rgdal, spdep, tmap, sf, \n               ggpubr, ClustGeo, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse,\n               dendextend, GGally)\n\n\n\n\nThe dataset used in this exercise is Myanmar Township Boundary GIS data and some infocomm data from the 2014 Myanmar Population and Housing Census Myanmar. For this exercise, we are only using townships from the state of Shan (comprised of Shan (East), Shan (North) and Shan (South)).\nThe following code chunk imports the geospatial data.\n\nshan_sf <- st_read(dsn=\"data/geospatial\",\n                   layer=\"myanmar_township_boundaries\") %>%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\"))\n\nReading layer `myanmar_township_boundaries' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX03\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 15\n$ OBJECTID   <dbl> 163, 203, 240, 106, 72, 40, 194, 159, 61, 124, 71, 155, 101…\n$ ST         <chr> \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (Sout…\n$ ST_PCODE   <chr> \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\",…\n$ DT         <chr> \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"…\n$ DT_PCODE   <chr> \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MM…\n$ TS         <chr> \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kal…\n$ TS_PCODE   <chr> \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR015…\n$ ST_2       <chr> \"Shan State (North)\", \"Shan State (South)\", \"Shan State (So…\n$ LABEL2     <chr> \"Mongmit\\n61072\", \"Pindaya\\n77769\", \"Ywangan\\n76933\", \"Pinl…\n$ SELF_ADMIN <chr> NA, \"Danu\", \"Danu\", \"Pa-O\", NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ST_RG      <chr> \"State\", \"State\", \"State\", \"State\", \"State\", \"State\", \"Stat…\n$ T_NAME_WIN <chr> \"rdk;rdwf\", \"yif;w,\", \"&GmiH\", \"yifavmif;\", \"rbdrf;\", \"uavm…\n$ T_NAME_M3  <chr> \"မိုးမိတ်\", \"ပင်းတယ\", \"ရွာငံ\", \"ပင်လောင်း\", \"မဘိမ်း\", \"ကလော\", \"ဖယ်ခုံ\", \"…\n$ AREA       <dbl> 2703.611, 629.025, 2984.377, 3396.963, 5034.413, 1456.624, …\n$ geometry   <MULTIPOLYGON [°]> MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (…\n\n\n\ntm_shape(shan_sf) +\n  tm_polygons() +\n  tm_text(\"TS\", size =0.5)\n\n\n\n\nNow for the attribute data:\n\nict <- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(ict)\n\nRows: 55\nColumns: 11\n$ `District Pcode`   <chr> \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR014D0…\n$ `District Name`    <chr> \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Ta…\n$ `Township Pcode`   <chr> \"MMR014001\", \"MMR014002\", \"MMR014003\", \"MMR014004\",…\n$ `Township Name`    <chr> \"Taunggyi\", \"Nyaungshwe\", \"Hopong\", \"Hsihseng\", \"Ka…\n$ `Total households` <dbl> 82604, 42634, 24728, 32771, 41341, 17544, 18348, 25…\n$ Radio              <dbl> 30176, 13801, 5083, 8087, 11607, 7324, 8890, 10048,…\n$ Television         <dbl> 62388, 23640, 11272, 16568, 25285, 8862, 4781, 1635…\n$ `Land line phone`  <dbl> 6736, 810, 799, 1042, 1739, 348, 219, 818, 728, 800…\n$ `Mobile phone`     <dbl> 48461, 14973, 5192, 4755, 16900, 2849, 2207, 8321, …\n$ Computer           <dbl> 6705, 669, 358, 325, 1225, 226, 81, 565, 351, 381, …\n$ `Internet at home` <dbl> 9746, 1604, 631, 580, 1741, 136, 152, 556, 737, 316…\n\n\nThe variables Radio, Television, Land line phone, Mobile phone, Computer and Internet at home are the absolute number of households within that township that have access that infocomm technology. For a meaningful comparision between townships, we need to convert these into proportions out of total household in the township. The following code chunk also changes some of the variable names so that the variable names match with the geospatial dataset.\n\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*100) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*100) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*100) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*100) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*100) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*100) %>%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nJoin the aspatial data to the geospatial data.\n\nshan_sf <- left_join(shan_sf, \n                     ict_derived, \n                     by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n\n\n\n\n\nWe can plot the distribution of technology penetration for each type of infocomm technology. The follow code chunk creates a histogram of the absolute number of households that have adopted each technology type and then we use ggarrange() to combine these plots together.\n\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  theme_bw()\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")+\n  theme_bw()\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")+\n  theme_bw()\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")+\n  theme_bw()\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")+\n  theme_bw()\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")+\n  theme_bw()\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, nrow = 2)\n\n\n\n\nWe should also visualise the distribution of % technology penetration. Instead of creating multiple plots and combining them, we can also make use of the facet_wrap() function of ggplot2 to automatically generate the 6 graphs. First, we need to use pivot_longer() to pivot the data from wide to long format such that each observation corresponds to one technology type in a township.\nOne of the benefits of this method is that it automatically sets the x-axis to the same scale so it is easier to compare between each type of technology.\n\nict_prop <- ict_derived %>%\n  pivot_longer(cols= ends_with(\"_PR\"),\n               names_to = \"tech\",\n               values_to=\"PR\") %>%\n  mutate(tech = str_replace(tech, \"_PR\", \"\"))\n\n\nggplot(data = ict_prop,\n       aes(x=PR)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") + \n  facet_wrap(vars(tech)) +\n  theme_bw()\n\n\n\n\nWe can see that computers clearly have the lowest penetration rate with almost all townships having less than 10% of households with this technology. TV is the technology with the highest penetration rate.\nWe should also plot these spatially. We can plot all the penetration rates at the same time using the tm_facets() function.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\",\n                  \"COMPUTER_PR\", \"INTERNET_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 3) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\nWe can see that technology penetration is not equal in the Shan state. Some townships have much higher technology penetration rates for all types of technology. Nonetheless, although a township may have very high penetration of one type of technology, it does not necessarily translate into high penetration rate of other technologies.\n\n\n\nBefore conducting cluster analysis, we need to check for multicollinearity. Multicollinearity occurs when independent variables are linearly correlated. It is important to check for multicollinearity because it makes statistical inferences unreliable.\nThe cor() function computes the correlation coefficients of each pair of variables. We can then use the corrplot.mix() function from the corrplot function to plot a correlogram showing the pairwise correlation values.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nWe typically consider any correlation coefficient more than 0.85 or less than -0.85 as highly correlated. As such, we should only use one of the COMPUTER_PR or INTERNET_PR for the subsequent analysis.\n\n\n\nFirst, we create a new dataframe with only the variables of interest. Note that we did not include INTERNET_PR because of the multicollinearity issue. Next, we assign the row names using the township names.\n\ncluster_vars <- data.frame(ict_derived) %>%\n  select(\"TS\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nrow.names(cluster_vars) <- cluster_vars$\"TS\"\nhead(cluster_vars,10)\n\n                   TS RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nTaunggyi     Taunggyi 36.53092 75.52661   8.154569  58.66665   8.1170403\nNyaungshwe Nyaungshwe 32.37088 55.44870   1.899892  35.11986   1.5691701\nHopong         Hopong 20.55565 45.58395   3.231155  20.99644   1.4477515\nHsihseng     Hsihseng 24.67731 50.55689   3.179641  14.50978   0.9917305\nKalaw           Kalaw 28.07624 61.16204   4.206478  40.87951   2.9631601\nPindaya       Pindaya 41.74647 50.51300   1.983584  16.23917   1.2881897\nYwangan       Ywangan 48.45215 26.05734   1.193591  12.02856   0.4414650\nLawksawk     Lawksawk 38.71017 63.00035   3.151366  32.05686   2.1766768\nPinlaung     Pinlaung 23.16499 54.17189   2.854454  24.94903   1.3762547\nPekon           Pekon 31.86118 53.58494   3.983270  21.48476   1.8970325\n\n\nWe no longer need the TS column.\n\nshan_ict <- cluster_vars %>%\n  select(!1)\n\n\n\nData standardisation is performed such that variables belong to approximately the same range. This is important in hierarchical clustering because it uses distance measures. A variable which has a larger magnitude will have a larger effect on the computed distance than other variables. Standardisation does not change the distribution of the data.\nThe following chunck applies min-max normalisation. It standardised values to a range of 0-1 with 0 being min value and 1 being the max value.\n\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nThe following chunk applies z-score normalisation which assumes that the underlying distribution of the data is a normal distribution. Normality should be checked before using this standardisation method.\n\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nThe following code chunk plots the kernel density original and standardised versions of RADIO_PR. The underlying distribution has not changed.\n\nr <- ggplot(data=ict_derived, \n            aes(x= RADIO_PR)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Original Data\")\n\ns <- ggplot(data=shan_ict.std, \n            aes(x=RADIO_PR)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nz <- ggplot(data=as.data.frame(shan_ict.z), \n            aes(x=RADIO_PR)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\nStandardisation is usually used if the variables have very different ranges. In this case, since all the variables are proportions, they are within the range of 0-100 and do not need to be standardised.\n\n\n\nHierarchical clustering uses distance measures to measure similarity within clusters and dissimilarity between clusters. As such, we first need to calculate the proximity matrix of distances between each observation. The method tells the algorithm what type of distance to compute.\n\nproxmat <- dist(shan_ict, method = 'euclidean')\n\nThere are many different agglomeration methods when performing hierarchical clustering (ie. how to measure similarity/dissimilarity between clusters). We can use the agnes() function of the cluster package to compute the agglomerative coefficient for each method to find the best method. Values closer to 1 suggest a strong clustering structure.\nThe following code chunk creates a function to extract the agglomerative coefficient for each method and applies it to the 4 different methods.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWe can then use the hclust() to conduct the clustering using the specified method and plot the tree.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\nplot(hclust_ward)\n\n\n\n\nHowever, this still does not tell us the optimal number of clusters. There are 3 methods that we can use:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution (distribution with no obvious clustering) of the data. The estimated optimal clusters (k) will be value that maximises the gap statistic, indicating that there is greatest difference between the clustering of the data and the clustering of a random dataset at that number of k.\nclusGap() is used to compute the gap statistic. We can specify the clustering method and maximum number of clusters to consider. If performing k-means clustering, the nstart argument can be used to specify the number of sets of initial centroids. The firstmax method tells the algorithm to report the first local maximum. Because the null reference distribution is formed through Monte Carlo simulations, we need to specify the number of simulations (B=50 here).\n\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 6.104544 6.378209 0.2736651 0.04460994\n [2,] 5.827444 6.048127 0.2206824 0.03880130\n [3,] 5.689680 5.899965 0.2102844 0.03362652\n [4,] 5.559639 5.778070 0.2184311 0.03784781\n [5,] 5.453876 5.675437 0.2215615 0.03897071\n [6,] 5.363009 5.585192 0.2221833 0.03973087\n [7,] 5.288334 5.503748 0.2154145 0.04054939\n [8,] 5.224095 5.429034 0.2049390 0.04198644\n [9,] 5.155439 5.358210 0.2027705 0.04421874\n[10,] 5.074827 5.291273 0.2164465 0.04540947\n\n\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nAlthough the algorithm recommends 1 cluster as the optimum, this is not meaningful. We can instead use the next local maximum (k=6).\n\n\n\nThe elbow plots the total within sum of squares (measure of the variability of the observations within each cluster) by each clustering over a range of k. At the elbow of the curve, dimishing marginal returns sets in, meaning that each subsequent increase in k results in less and less decrease in variability within each cluster (ie. clusters are getting more cohesive but at a slower rate). To prevent overfitting, we choose the k at the elbow of the curve.\n\nfviz_nbclust(shan_ict, hcut, method = \"wss\")\n\n\n\n\nThe elbow appears to occur at 2 or 4.\n\n\n\nThe silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. The average silhouette width is the average of the silhouette values of all the clusters. Maximising this value would give the number of clusters with the best intra-cluster cohesion and intra-cluster separation.\nThe fviz_nbclust() function of the factoextra package can use the average silhouette method. In the code chunk below, the find_k() function of the dendextend package uses average silhouette to recommend the optimal number of clusters.\n\nnum_k <- find_k(hclust_ward)\nplot(num_k)\n\n\n\n\n\n\n\n\nAlthough all 3 methods have recommended different optimal number of clusters, let’s just use k=6 from the gap statistic method.\nThe follow code chunk creates borders around the clusters so we can see which townships are clustered together.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\nThe heatmaply package can be used to build an interactive cluster heatmap to study the distribution of cluster variables at the same time. As the heatmaply() function takes a numeric matrix as input, we must convert the shan_ict object first.\n\nshan_ict_mat <- data.matrix(shan_ict)\n\nThe following code chunk creates the interactive heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\nIf we are happy with the 6 clusters formed, we can save the cluster assignments to the dataset and map them out. cutree() function extracts the cluster assignments\n\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\nThe following code chunk combines the cluster assignments to shan_sf dataset.\n\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNow we can plot it.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nThe clusters are fragmented spatially. This is one of the motivations for spatially constrained clustering.\n\n\n\n\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because the skater() function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp <- as_Spatial(shan_sf)\n\n\n\nAs always, we must define the neighbourhood (neighbour list). We will be using a queen contiguity matrix.\n\nshan.nb <- poly2nb(shan_sp, queen=TRUE)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\nA spanning tree of an undirected graph (such as the connectivity network above) with V vertices (nodes) refers to a subgraph with V-1 edges such that all vertices are still connected to each other. The minimum spanning tree refers to a spanning tree with the lowest total cost if the edges are weighted.\nTo compute the minimum spanning tree, we must first weigh the edges with a cost. The code chunk below computes the “cost” of an edge which is pairwise dissimilarity between neighbours’ values on the five variables.\n\nlcosts <- nbcosts(shan.nb, shan_ict)\n\nWe can assign the costs to the neighbour list to create the spatial weight matrix.\n\nshan.w <- nb2listw(shan.nb,\n                   glist=lcosts,\n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1      S2\nB 55 3025 8208.527 672291.1 6039513\n\n\nWe can now calculate the minimum spanning tree using the mstree() function of the spdep package. As the minimum spanning tree only has v-1 edges, the dimension of the shan.mst object is only 54, not 55 which is the total number of townships in Shan state.\n\nshan.mst <- mstree(shan.w)\ndim(shan.mst)\n\n[1] 54  3\n\n\nWe can plot the minimum spanning tree using the code chunk below.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\nThe code chunk below computes the spatially constrained clusters using the SKATER method. It takes the edges from the minimum spanning tree (not the costs!) and the actual data containing the variable considered. It performs n cuts to get n+1 number of clusters.\n\nclust6 <- skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\n\nclust6\n\n$groups\n [1] 6 6 6 6 6 6 4 6 6 6 1 6 6 6 1 3 6 6 6 3 6 2 6 5 6 2 6 6 6 6 1 5 1 6 6 4 6 2\n[39] 1 6 6 1 5 6 6 6 6 6 6 1 5 6 2 6 6\n\n$edges.groups\n$edges.groups[[1]]\n$edges.groups[[1]]$node\n[1] 31 50 11 15 39 42 33\n\n$edges.groups[[1]]$edge\n     [,1] [,2]      [,3]\n[1,]   11   42 34.387764\n[2,]   50   39 29.755406\n[3,]   15   33 17.106583\n[4,]   15   11 13.743768\n[5,]   31   50  7.396972\n[6,]   50   15  2.147665\n\n$edges.groups[[1]]$ssw\n[1] 118.5374\n\n\n$edges.groups[[2]]\n$edges.groups[[2]]$node\n[1] 22 53 26 38\n\n$edges.groups[[2]]$edge\n     [,1] [,2]      [,3]\n[1,]   53   38 18.917358\n[2,]   22   26 11.786692\n[3,]   22   53  4.064893\n\n$edges.groups[[2]]$ssw\n[1] 67.88651\n\n\n$edges.groups[[3]]\n$edges.groups[[3]]$node\n[1] 20 16\n\n$edges.groups[[3]]$edge\n     [,1] [,2]     [,3]\n[1,]   20   16 13.32999\n\n$edges.groups[[3]]$ssw\n[1] 13.32999\n\n\n$edges.groups[[4]]\n$edges.groups[[4]]$node\n[1] 36  7\n\n$edges.groups[[4]]$edge\n     [,1] [,2]     [,3]\n[1,]   36    7 30.61638\n\n$edges.groups[[4]]$ssw\n[1] 30.61638\n\n\n$edges.groups[[5]]\n$edges.groups[[5]]$node\n[1] 24 43 51 32\n\n$edges.groups[[5]]$edge\n     [,1] [,2]      [,3]\n[1,]   43   32 30.912416\n[2,]   24   43  9.778470\n[3,]   24   51  8.255919\n\n$edges.groups[[5]]$ssw\n[1] 57.98259\n\n\n$edges.groups[[6]]\n$edges.groups[[6]]$node\n [1] 10 25 52 23 14  8 28 55 17 19 18 41 30  6 34  1 13  2 21 12 45 27 47 49 35\n[26] 48 46 40 54 37 44  4  5  3 29  9\n\n$edges.groups[[6]]$edge\n      [,1] [,2]      [,3]\n [1,]   52   45 38.112866\n [2,]   23   47 35.957910\n [3,]   28   52 34.681180\n [4,]   23   27 30.824975\n [5,]   14   49 30.447476\n [6,]    8    6 29.038187\n [7,]   10   55 28.833161\n [8,]    8   35 27.842807\n [9,]   55    1 23.082290\n[10,]   18   48 22.447653\n[11,]   19   41 20.867009\n[12,]   14   37 20.236457\n[13,]    6    4 19.765479\n[14,]   41   40 19.225948\n[15,]   30   54 18.961970\n[16,]   14   44 18.676071\n[17,]    8   46 18.650776\n[18,]    8   18 16.488288\n[19,]    2    3 16.131465\n[20,]   19   17 13.285066\n[21,]    1    5 11.242824\n[22,]   18   12 10.682115\n[23,]   12   28 10.614852\n[24,]   34   21 10.168055\n[25,]   10    9  9.180481\n[26,]   25   10  8.169645\n[27,]   17   25  7.871804\n[28,]   13   34  7.083237\n[29,]   41   29  7.065738\n[30,]   28   14  6.552019\n[31,]    8    2  5.384161\n[32,]   21   30  4.928689\n[33,]   30   23  3.847340\n[34,]   14   13  3.693718\n[35,]   10    8  1.195515\n\n$edges.groups[[6]]$ssw\n[1] 638.2814\n\n\n\n$not.prune\nNULL\n\n$candidates\n[1] 1 2 3 4 5 6\n\n$ssto\n[1] 1261.252\n\n$ssw\n[1] 1261.2515 1139.7426 1067.6608 1016.9978  965.8793  926.6342\n\n$crit\n[1]   1 Inf\n\n$vec.crit\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nattr(,\"class\")\n[1] \"skater\"\n\n\nWe can find the number of townships within each cluster using the following code:\n\ntable(clust6$groups)\n\n\n 1  2  3  4  5  6 \n 7  4  2  2  4 36 \n\n\nOf course, we should also plot the clusters spatially to see the result:\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\", \"green\" ,\"blue\", \"brown\", \"pink\", \"orange\"),\n     cex.circles=0.005,\n     add=TRUE)\n\n\n\n\n\ngroups_mat <- as.matrix(clust6$groups)\n\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, \n                                as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nWe can also use the ggparcoord function from the GGally package to plot a parallel coordinates plot to examine the distribution of the variables in each cluster.\n\nggparcoord(data= shan_sf_spatialcluster,\n           columns=c(25:29),\n           mapping = aes(color = as.factor(`SP_CLUSTER`)),\n           alphaLines = 0.5,\n           scale=\"uniminmax\",\n           boxplot=TRUE) +\n  labs(title = \"Parallel Coordinates Plots of Technology Penetration by Spatial Clusters\",\n       subtitle = \"Standardised using Min-Max Normalisation\",\n       xlab = \"% Household Penetration\") +\n  scale_colour_brewer(name=\"Cluster\",\n                      labels = levels(shan_sf_spatialcluster$`SP_CLUSTER`),\n                      palette = \"Dark2\") +\n  theme(axis.text.x = element_text(angle = 45, size=8),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(~ SP_CLUSTER)\n\n\n\n\n\n\n\nWhen only one similarity matrix is input, the hclustgeo() function of the GeoClust package conducts hierarchical clustering using the ward method similar to the hclust() function of base R.\n\nnongeo_cluster <- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nOf course, since there is no spatial consideration, the clusters are fragmented as with the hclust() function previously.\n\ngroups <- as.factor(cutree(nongeo_cluster, k=6))\nshan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\nThe ClustGeo method can “mix” both the attribute cost matrix and the spatial constraint matrix by varying a parameter alpha (ranged 0-1) to adjust the relative “weight” of each matrix.\nFirst, we need to compute the spatial distance matrix. In the SKATER method, edges were weighted only by attribute cost and did not consider distance. In the following code chunk, the st_distance() function is used to compute the pairwise distances between centroids of each polygon.\n\ndist <- st_distance(shan_sf, shan_sf)\ndistmat <- as.dist(dist)\n\nNext, the choicealpha() function helps to find the optimum weight of each of each matrix for the clustering. It takes 2 matrices d0 and d1 as input: d0 is the attribute space matrix (ie. cost) and d1 is the geographical weight matrix. The code chunk outputs 2 graphs, one using absolute values and one using normalised values. Qnorm on is a measure of homogenity within clusters in each of the dimensions of attribute space (black line) and geographic space (red line). As alpha increases, the homogeneity of clusters in terms of attributes decreases whereas the spatial homogeniety increases. The optimum mixing parameter with minimum compromise in the cohesion of clusters in terms of attribute space and geographical space.\n\ncr <- choicealpha(proxmat, \n                  distmat, \n                  range.alpha = seq(0, 1, 0.1), \n                  K=6, \n                  graph = TRUE)\n\n\n\n\n\n\n\nSince our values are in the same units and approximately thre same magnitude, we can take the first graph using absolute values. The lines cross between 0.3-0.4 so alpha=0.3 or 0.4 would likely be the optimum mix.\nWe can then use hclustgeo() to perform the clustering. This time, we provide two distance matrices as input and specify the alpha.\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.3)\ngroups <- as.factor(cutree(clustG, k=6))\nshan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nSpatial distribution of new clusters:\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")\n\n\n\n\nWe can see that although the clusters are not necessarily contiguous with each other like in the SKATER method, they are still more cohesive than pure aspatial hierarchical clustering because of the mixing parameter alpha.\nWe should also plot the attributes by cluster:\n\nggparcoord(data= shan_sf_Gcluster,\n           columns=c(25:29),\n           mapping = aes(color = as.factor(`CLUSTER`)),\n           alphaLines = 0.5,\n           scale=\"uniminmax\",\n           boxplot=TRUE) +\n  labs(title = \"Parallel Coordinates Plots of Technology Penetration by Spatial Clusters\",\n       subtitle = \"Standardised using Min-Max Normalisation\",\n       xlab = \"% Household Penetration\") +\n  scale_colour_brewer(name=\"Cluster\",\n                      labels = levels(shan_sf_Gcluster$`CLUSTER`),\n                      palette = \"Dark2\") +\n  theme(axis.text.x = element_text(angle = 45, size=8),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(~ CLUSTER)\n\n\n\n\nCharacterisation of clusters\nCluster 1: Mid-high radio, low landline, low computer\nCluster 2: Mid radio, high TV (south-east)\nCluster 3: Mid radio, high TV (north)\nCluster 4: Low landline, low computer\nCluster 5: Low radio\nCluster 6: High TV, high mobile phone, high computer\nFor comparison, let’s plot a few maps with different alpha values.\n\nalphavals <- c(seq(0, 1, 0.2))\n\ntestalpha <- function(x){\n  clustG <- hclustgeo(proxmat, distmat, alpha = x)\n  groups <- as.factor(cutree(clustG, k=6))\n}\n\nresults <- map(alphavals, testalpha)\n\nConvert the results to a dataframe to bind to the polygon data.\n\nalphatest <- as.data.frame(do.call(cbind, results)) %>%\n   mutate(across(.cols = everything(), as.factor))\n\nnames(alphatest) <- paste0(\"alpha\", seq(0, 1, 0.2))\nshan_sf_alphatest <- cbind(shan_sf, alphatest)\n\nCreate a function to plot the results.\n\nautoplot <- function(x){\n  qtm(shan_sf_alphatest, x)\n}\n\nnames <- names(alphatest)\nmaps <- map(names, autoplot)\n\ntmap_arrange(maps[1:6], asp=1, ncols=3)\n\n\n\n\nAs alpha increases, the clusters become more cohesive in geographical space."
  },
  {
    "objectID": "Take-home_EX02/Take-home_EX02.html",
    "href": "Take-home_EX02/Take-home_EX02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "In the last take-home exercise (link), I analysed the spatial distribution of proportion of non-functional waterpoints in Nigeria. I found that there is uneven distribution in the proportion of functional and non-functional waterpoints in each administrative area, which has implications of availability of water supply and maintenance.\nIn this exercise, I will segment Nigeria into different regions based on the availability of waterpoints, type of waterpoints and usage capacity to identify regions to give recommendations to improve water supply or maintenance.\nThe following variables will be used (from exercise write-up):\n\nTotal number of functional water points\nTotal number of nonfunctional water points\nPercentage of functional water points\nPercentage of non-functional water points\nPercentage of main water point technology (i.e. Hand Pump)\nPercentage of usage capacity (i.e. < 1000, >=1000)\nPercentage of rural water points\n\n\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\nfunModeling: quick exploratory data analysis\n\n\npacman::p_load(rgdal, spdep, tmap, sf, kableExtra,\n               ggpubr, cluster, ClustGeo, factoextra, NbClust,\n               heatmaply, corrplot, tidyverse,\n               dendextend, GGally, funModeling, RColorBrewer)\n\n\n\n\nThe following code chunk was used to pre-process the dataset downloaded from Water Point Data Exchange (WPdx) to keep only waterpoints in Nigeria and some relevant variables. It is not run on this page due to the size of the ddataset. The dataset can be found here and the data dictionary here. The data is in csv format with latitude and longitude information.\n\n#not run\n\nraw <- read_csv(\"data/WPdx_plus_full.csv\") %>%\n  filter(`#clean_country_name`==\"Nigeria\") %>%\n  select(c(3:4, 9, 22, 46:47)) %>%\n  write_rds(\"data/WPdx_plus_Nigeria.rds\")\n\nLet’s load the pre-processed dataset and view the dataset.\n\nwp <- read_rds(\"data/WPdx_plus_Nigeria.rds\")\n\nglimpse(wp)\n\nRows: 95,008\nColumns: 6\n$ `#lat_deg`          <dbl> 7.980000, 6.964532, 6.486940, 6.727570, 6.779900, …\n$ `#lon_deg`          <dbl> 5.120000, 3.597668, 7.929720, 7.648670, 7.664850, …\n$ `#water_tech_clean` <chr> \"Tapstand\", \"Mechanized Pump\", \"Hand Pump\", NA, \"H…\n$ `#status_clean`     <chr> NA, \"Functional\", NA, NA, NA, NA, NA, NA, NA, NA, …\n$ usage_capacity      <dbl> 250, 1000, 300, 300, 300, 300, 300, 1000, 300, 300…\n$ is_urban            <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TR…\n\n\nThe following code chunk cleans variables names that contain the special character “#” and recategorises the well status into 3 broad categories (functional, non-functional and unknown).\n\nwp <- read_rds(\"data/WPdx_plus_Nigeria.rds\") %>%\n  rename_with(~str_replace(.x, \"#\", \"\")) %>%\n  mutate(status_clean=replace_na(status_clean, \"Unknown\")) %>%\n  mutate(nonfunctional=ifelse(\n    status_clean %in% c(\"Abandoned/Decommissioned\", \n                        \"Abandoned\",\n                        \"Non-Functional\",\n                        \"Non functional due to dry season\",\n                        \"Non-Functional due to dry season\"),\n    1, 0))%>%\n  mutate(functional=ifelse(\n    status_clean %in% c(\"Functional\", \n                        \"Functional but not in use\",\n                        \"Functional but needs repair\"),\n    1, 0)) %>%\n  mutate(unknown=ifelse(status_clean==\"Unknown\",\n                        1, 0)) %>%\n  select(!status_clean)\n\nLet’s visualise the other variables of interest as well.\n\nfreq(wp, input=\"is_urban\")\n\n\n\n\n  is_urban frequency percentage cumulative_perc\n1    FALSE     75444      79.41           79.41\n2     TRUE     19564      20.59          100.00\n\n\n\nfreq(wp, input=\"water_tech_clean\")\n\n\n\n\n             water_tech_clean frequency percentage cumulative_perc\n1                   Hand Pump     58720      61.81           61.81\n2             Mechanized Pump     25240      26.57           88.38\n3                        <NA>     10055      10.58           98.96\n4                    Tapstand       553       0.58           99.54\n5     Mechanized Pump - Solar       401       0.42           99.96\n6  Hand Pump - India Mark III        19       0.02           99.98\n7         Hand Pump - Afridev         7       0.01           99.99\n8   Hand Pump - India Mark II         7       0.01          100.00\n9    Mechanized Pump - Diesel         3       0.00          100.00\n10           Hand Pump - Mono         1       0.00          100.00\n11      Hand Pump - Rope Pump         1       0.00          100.00\n12            Rope and Bucket         1       0.00          100.00\n\n\n\nggplot(wp) +\n  geom_histogram(aes(x=usage_capacity),\n                 colour=\"black\",\n                 fill=\"light blue\") +\n  theme_bw()\n\n\n\n\n\nsum(is.na(wp$usage_capacity))\n\n[1] 0\n\n\nWe need to recategorise water tech and usage capacity as well. The following code chunk creates new dummy variable for handpumps vs others and waterpumpts of low capacity (<1000) vs high capacity (>=1000). We only need one dummy variable each because there are only 2 categories each so the proportions would be collinear.\n\nwp_clean <- wp %>%\n  mutate(handpump = case_when(\n    water_tech_clean %in% \n      c(\"Tapstand\", \"Rope and Bucket\", \"Mechanized Pump\", \n        \"Mechanized Pump - Solar\", \"Mechanized Pump - Diesel\")~0,\n    is.na(water_tech_clean)~0,\n    TRUE ~ 1)) %>%\n  mutate(capacity_less1000 = case_when(\n    usage_capacity<1000~ 1,\n    usage_capacity>=1000~0\n  )) %>%\n  mutate(rural=ifelse(is_urban==TRUE, 0 , 1)) %>%\n  select(!c(3:5))\n\nWe can then convert the wp tibble dataframe to an sf dataframe. The GCS of the data is WGS1984 (EPSG:4326) as stated in the data dictionary.\n\nwp_sf <- st_as_sf(wp_clean, \n                  coords = c(\"lon_deg\", \"lat_deg\"),\n                  crs=4326) \n\nNext, let’s import the administrative boundary dataset and plot both the administrative boundary and waterpoints.\n\nadm_bound <- st_read(dsn=\"data\",\n               layer=\"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\lins-92\\ISSS624\\Take-home_EX02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\ntm_shape(adm_bound) +\n  tm_polygons() +\ntm_shape(wp_sf) +\n  tm_symbols(size=0.1)\n\n\n\n\n\n\n\n\nThe next step is to associate the location (ie. administrative area) to each waterpoint. I will use st_join() to perform a spatial join to relate polygon IDs to each waterpoint in the wp_st dataset by its location (note that the shapeName variable contains duplicates and should not be used for this step). The join=st_intersects() argument tells R the type of spatial join to use. Note that both datasets must have the same projection (WGS1984), which is why we have not transformed either dataset yet.\n\nwp_sf <- st_join(x = wp_sf,\n                 y = adm_bound,\n                 join = st_intersects,\n                 left = TRUE)\n\nAs found in take-home exercise 1, there should be 29 missing values in polygon IDs where the waterpoings actually fall outside of the boundary of Nigeria.\n\nsum(is.na(wp_sf$shapeID))\n\n[1] 29\n\n\nThe next step is to collapse the dataset by administrative area to get the proportion and number of waterpoints by the relevant variables. First, we need to strip the geometry from the dataset in order to manipulate it.\n\njoinvars <- wp_sf %>%\n  st_set_geometry(NULL) %>%\n  filter(!is.na(shapeID)) %>%\n  group_by(shapeID) %>%\n  summarise(total = n(),\n            functional=sum(functional),\n            nonfunctional=sum(nonfunctional),\n            unknown=sum(unknown),\n            handpump=sum(handpump),\n            capacity_less1000=sum(capacity_less1000),\n            rural = sum(rural)) %>%\n  ungroup()\n\nLet’s check the data. The dataset now contains counts of waterpumps that meet the respective criteria.\n\nhead(joinvars, 5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    shapeID \n    total \n    functional \n    nonfunctional \n    unknown \n    handpump \n    capacity_less1000 \n    rural \n  \n \n\n  \n    NGA-ADM2-72505758B10049836 \n    70 \n    31 \n    39 \n    0 \n    34 \n    34 \n    0 \n  \n  \n    NGA-ADM2-72505758B10063467 \n    118 \n    50 \n    38 \n    30 \n    43 \n    73 \n    29 \n  \n  \n    NGA-ADM2-72505758B10065661 \n    178 \n    104 \n    51 \n    23 \n    122 \n    146 \n    178 \n  \n  \n    NGA-ADM2-72505758B10302610 \n    201 \n    64 \n    53 \n    84 \n    94 \n    179 \n    201 \n  \n  \n    NGA-ADM2-72505758B11317593 \n    100 \n    51 \n    49 \n    0 \n    19 \n    20 \n    0 \n  \n\n\n\n\n\nWe still need to transform some of the variables into proportions out of total waterpoints in the area. We do not need to keep the absolute numbers except for the number of functional and non-functional waterpoints.\n\njoinvars <- joinvars %>%\n  mutate(func_pr = functional/total,\n         nonfunc_pr = nonfunctional/total,\n         handpump_pr = handpump/total,\n         capacity_less1000_pr = capacity_less1000/total,\n         rural_pr = rural/total)  %>%\n  select(c(1, 3:4, 9:13))\n\nNow that we have all the required cluster variables, we can join it back to the administrative boundary dataset using left_join() for mapping later. We can also transform the CRS to EPSG:26391 since we have completed the joining step.\n\nadm_wp <- left_join(x=adm_bound,\n                    y=joinvars,\n                    by=\"shapeID\") %>%\n  st_transform(crs = 26391)\n\n\n\n\nWe can examine the distribution of the cluster variables. The plot_num() function of funModeling can automatically plot the histograms of all numeric variables in a dataset.\n\nplot_num(joinvars)\n\n\n\n\nThe distribution of absolute number of functional and non-functional waterpoints is right skewed. The proportion of rural waterpoints is also left skewed but not as much as handpump proportion. Nonetheless, the hierarchical clustering technique is not as sensitive to outliers so there is no need to address outliers.\nThe following code chunk plots the cluster variables spatially by creating a function. The function is looped over the names of variables of interest using the map() function.\n\nautoplot <- function(x){\n  tm_shape(adm_wp) +\n    tm_fill(col=x,\n            style=\"pretty\") +\n    tm_borders(alpha=0.5)\n}\n\neda_maps <- map(names(joinvars)[2:8], autoplot)\ntmap_arrange(eda_maps, asp=1, ncols=3)\n\n\n\n\nThere are a few observations we can draw from the maps:\n\nThere are regions with missing data. These regions will need to be dropped.\n\n\nadm_wp <- adm_wp %>%\n  filter(!is.na(functional))\n\n\nThere are some regions with high absolute number of functional and non-functional waterpoints.\nMost regions have high proportion of rural waterpoints.\nRegions in the north tend to have higher proportion of handpumps.\nIn general, regions in the north have a higher proportion of functional waterpoints and regions in the south have a higher proportion of non-functional waterpoints.\n\nSince most of the variables are proportions, their range is from 0-1. 2 variables (functional and nonfunctional) are still in absolute numbers so they need to be standardised such that their magnitude is not too large compared to the other variables, which would affect the results of the hierarchical clustering. The following code chunk creates a new dataset cluster_vars in the format needed to create the proximity matrix for hierarchical clustering and standardises functional and nonfunctional using min-max normalisation.\n\ncluster_vars <- joinvars %>%\n  mutate(functional = normalize(functional),\n         nonfunctional = normalize(nonfunctional))\n\nrow.names(cluster_vars) <- cluster_vars$\"shapeID\"\n\ncluster_vars <- cluster_vars %>%\n  select(!1)\n\nBefore proceeding with the clustering, we need to check for multicollinearity among the variables of interest.\n\ncluster_vars.cor = cor(joinvars[,2:8])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe correlation coefficient for handpump proportion and proportio of low capacity waterpoints is 0.82, indicating that there is multicollinearity. The higher the proportion of handpumps, the higher the proportion of low capacity waterpoints. I will drop the handpump portion variable and keep the capacity variable.\n\ncluster_vars <- cluster_vars %>%\n  select(!5)\n\n\n\n\nThe dist() function is used to create the proximity matrix.\n\nproxmat <- dist(cluster_vars, method=\"euclidean\")\n\nThe following code chunk tests the different agglomerative clustering algorithm to determine the best method. Values closer to 1 indicate a stronger clustering structure.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(cluster_vars, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.9115986 0.8239627 0.9415135 0.9888309 \n\n\nThe ward method is the optimum method.\nNext, we need to determine the optimum number of clusters. The following code chunk recommends the optimum number of clusters using the gap statistic method.\nThe gap statistic compares the total within cluster variation for different values of k with their expected values under null reference distribution (distribution with no obvious clustering) of the data. The estimated optimal clusters (k) will be value that maximises the gap statistic, indicating that there is greatest difference between the clustering of the data and the clustering of a random dataset at that number of k.\n\nset.seed(12345)\ngap_stat <- clusGap(cluster_vars, \n                    FUN = hcut, \n                    K.max = 10, \n                    B = 50)\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nNow that we have determined that we should use the Ward method to join clusters and that the optimum number of clusters is 4, we can try aspatial hierarchical clustering. Note that the “ward” method in the agnes() function is called “ward.D2” in the hclust() function.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D2')\n\n\ngroups <- as.factor(cutree(hclust_ward, k=4))\nadm_wp_cluster <- cbind(adm_wp, as.matrix(groups)) %>%\n  rename(`HCLUSTER`=`as.matrix.groups.`)\n\nggparcoord(data= adm_wp_cluster,\n           columns=c(6:9, 11:12),\n           mapping = aes(color = as.factor(`HCLUSTER`)),\n           alphaLines = 0.3,\n           scale=\"uniminmax\",\n           boxplot=TRUE) +\n  labs(title = \"Parallel Coordinates Plots of Waterpoint Availability by Hierarchical Clusters (k=4)\",\n       subtitle = \"Standardised using Min-Max Normalisation\",\n       xlab = \"Cluster Variables\") +\n  scale_colour_brewer(name=\"Cluster\",\n                      labels = levels(adm_wp_cluster$`HCLUSTER`),\n                      palette = \"Set3\") +\n  theme(axis.text.x = element_text(angle = 45, size=8),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(~ HCLUSTER)\n\n\n\n\nWe can attempt to characterise the 4 clusters from the parallel coordinates plots:\n\nGreen cluster 1 (mix of urban and rural, average condition): Mid prop functional and non-functional, low-mid prop low capacity, low-mid prop rural\nYellow cluster 2 (mostly rural, poor condition): Low-mid prop non-functional, high prop rural\nPurple cluster 3 (mix of urban and rural, better condition): High prop functional, low prop non-functional, low-mid prop rural\nRed cluster 4 (few waterpoints): Low absolute functional and non-functional\n\nHowever, the clusters do not appear to be very distinct. Although the algorithm has recommended 4 as the optimum number of clusters, the results may not be easy to interpret because there is overlap in the distribution of the variables for each cluster.\nThe final cluster assignment should be informed by whether it can adequately address the research question (recommending areas to improve water supply/maintenance in this case) and intepretability. While increasing the number of clusters improves the within cluster cohesion, having too many clusters also makes interpretation difficult.\nNonetheless, since we are more interested in regionalisation than pure hierarchical clustering, we proceed to plot the 4 clusters spatially first. We can keep in mind that k=7 is the next best number of clusters when checking the spatial clustering results.\n\nqtm(adm_wp_cluster, \"HCLUSTER\")\n\n\n\n\nAs expected, the clusters are fragmented spatially.\n\n\n\nFor spatially constrained clustering, I will use the ClustGeo method. It mixes 2 distance matrices, one in terms of attribute space and the other in terms of geographical distance, to conduct clustering that considers both spatial structure and attribute similarity/dissimilarity.\nThis is chosen over the SKATER method where the neighbourhood structure is rigidly defined so clusters can only contain neighbours. The ClustGeo method will allow more flexibility in the spatial structure to consider cohesion within clusters and separation between clsuters in terms of attributes.\n\n\nIn order to conduct spatially constrained clustering, we need to define the spatial structure in the form of a distance matrix for the ClustGeo method.\nThe st_distance() computes pair-wise distance between observations of 2 geospatial datasets. Since I want pair-wise distances between each administration region, I apply st_distance on itself. We then need to convert it to a dist object.\n\ndist <- st_distance(adm_wp, adm_wp)\ndistmat <- as.dist(dist)\n\n\n\n\nchoicealpha() helps to identify the optimum mix of the two distance matrices based on homogenity within clusters in each of the dimensions of attribute space (black line) and geographic space (red line). The optimum mixing parameter achieves minimum compromise in the cohesion of clusters in terms of attribute space and geographical space.\n\nchoicealpha(proxmat, \n            distmat, \n            range.alpha = seq(0, 1, 0.1), \n            K=4, \n            graph = TRUE)\n\n\n\n\n\n\n\n$Q\n                   Q0          Q1\nalpha=0   0.517161360 0.003495416\nalpha=0.1 0.519842962 0.004787772\nalpha=0.2 0.501618820 0.032982608\nalpha=0.3 0.439522230 0.326534122\nalpha=0.4 0.354092532 0.420469977\nalpha=0.5 0.183885221 0.617781433\nalpha=0.6 0.174948153 0.648905612\nalpha=0.7 0.006702762 0.752189196\nalpha=0.8 0.005280607 0.792751369\nalpha=0.9 0.004321980 0.796393894\nalpha=1   0.001908642 0.771955198\n\n$Qnorm\n               Q0norm      Q1norm\nalpha=0   1.000000000 0.004528003\nalpha=0.1 1.005185233 0.006202137\nalpha=0.2 0.969946441 0.042726066\nalpha=0.3 0.849874457 0.422996208\nalpha=0.4 0.684684820 0.544681839\nalpha=0.5 0.355566435 0.800281460\nalpha=0.6 0.338285430 0.840600094\nalpha=0.7 0.012960678 0.974394884\nalpha=0.8 0.010210754 1.026939608\nalpha=0.9 0.008357120 1.031658180\nalpha=1   0.003690612 1.000000000\n\n$range.alpha\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n$K\n[1] 4\n\nattr(,\"class\")\n[1] \"choicealpha\"\n\n\nThe optimum value of alpha is between 0.4 - 0.5. Let’s set it at 0.45.\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.45)\ngroups <- as.factor(cutree(clustG, k=4))\nadm_wp_cluster <-cbind(adm_wp_cluster, as.matrix(groups)) %>%\n  rename(`GCLUSTER4` = `as.matrix.groups.`)\n\nLet’s examine the spatial distribution of clusters and the distribution of the cluster variables within each cluster.\n\ngclust4.map <- qtm(adm_wp_cluster, \"GCLUSTER4\")\ngclust4.map\n\n\n\n\n\nggparcoord(data= adm_wp_cluster,\n           columns=c(6:9, 11:12),\n           mapping = aes(color = as.factor(`GCLUSTER4`)),\n           alphaLines = 0.3,\n           scale=\"uniminmax\",\n           boxplot=TRUE) +\n  labs(title = \"Parallel Coordinates Plots of Waterpoint Availability by Spatial Clusters (k=4)\",\n       subtitle = \"Standardised using Min-Max Normalisation\",\n       xlab = \"Cluster Variables\") +\n  scale_colour_brewer(name=\"Cluster\",\n                      labels = levels(adm_wp_cluster$`GCLUSTER4`),\n                      palette = \"Set3\") +\n  theme(axis.text.x = element_text(angle = 45, size=8),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(~ GCLUSTER4)\n\n\n\n\nWe can attempt to characterise the clusters:\n\nGreen cluster 1 (mostly rural, low capacity, average condition): mid prop functional and non-functional, low-mid prop capacity, mid-high prop rural\nYellow cluster 2 (mix rural and urban, poor condition, south): low-mid prop functional and non-functional, low-mid prop low capacity, low-mid prop rural, south\nPurple cluster 3 (mix rural and urban, low supply, low capacity, poor condition): Low absolute functional and non-functional, mid prop functional and non-functional, low-mid prop rural\nRed cluster 4 (mostly rural, high supply, low capacity, good condition, north): Mid-high absolute functional, high prop functional, low prop non-functional, high prop low capacity, high prop rural, north\n\nFrom the above cluster characterisations, we can deduce that cluster 2 and 3 (yellow and purple) are of higher concern because the waterpoints are mostly low capacity and many are non-functional. These areas should be prioritised for maintenance. In addition, cluster 3 (purple) has a low absolute supply of waterpoints so efforts to increase waterpoint supply may be beneficial.\nCluster 1 (green) is mid-priority because the proportion of non-functional waterpoints is not as high.\nCluster 4 areas are the lowest priority as they generally have more waterpoints and high proportion that are in working condition.\nInterestingly, the cluster results when considering the geospatial dimension are actually easier to intepret although there is still a lot of overlap between clusters 1-3. There is clearer distinction of a cluster which should be considered high priority or low priority for maintenance.\nWe should also check whether any clusters are significantly larger than others.\n\ntable(adm_wp_cluster$GCLUSTER4)\n\n\n  1   2   3   4 \n128 283  86 264 \n\n\nNot all the clusters are distinct. From the parallel coordinates plot, there still appears to be quite a lot of overlap between the distribution of attributes between clusters (mostly clusters 1-3). Increasing the number of clusters could produce a better result. We can try the next best number of clusters (k=7).\n\n\n\nLet’s try the next best number of clusters (k=7) according to the gap statistic graph in section 4.\n\nchoicealpha(proxmat, \n            distmat, \n            range.alpha = seq(0, 1, 0.1), \n            K=7, \n            graph = TRUE)\n\n\n\n\n\n\n\n$Q\n                  Q0          Q1\nalpha=0   0.63093662 0.004447545\nalpha=0.1 0.62033286 0.013241083\nalpha=0.2 0.59062097 0.217145030\nalpha=0.3 0.57981802 0.351221231\nalpha=0.4 0.47126680 0.534967151\nalpha=0.5 0.33963418 0.692726843\nalpha=0.6 0.30790259 0.731005906\nalpha=0.7 0.15156730 0.819693878\nalpha=0.8 0.01149031 0.898919073\nalpha=0.9 0.01144768 0.903395165\nalpha=1   0.00312245 0.913346910\n\n$Qnorm\n               Q0norm      Q1norm\nalpha=0   1.000000000 0.004869502\nalpha=0.1 0.983193619 0.014497321\nalpha=0.2 0.936101903 0.237746499\nalpha=0.3 0.918979806 0.384543077\nalpha=0.4 0.746932080 0.585721751\nalpha=0.5 0.538301584 0.758448773\nalpha=0.6 0.488008740 0.800359533\nalpha=0.7 0.240225873 0.897461708\nalpha=0.8 0.018211512 0.984203334\nalpha=0.9 0.018143951 0.989104091\nalpha=1   0.004948912 1.000000000\n\n$range.alpha\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n$K\n[1] 7\n\nattr(,\"class\")\n[1] \"choicealpha\"\n\n\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.45)\ngroups <- as.factor(cutree(clustG, k=7))\nadm_wp_cluster <-cbind(adm_wp_cluster, as.matrix(groups)) %>%\n  rename(`GCLUSTER7` = `as.matrix.groups.`)\n\n\ngclust7.map <- qtm(adm_wp_cluster, \"GCLUSTER7\")\n\ntmap_arrange(gclust4.map, gclust7.map, asp=1, ncol=2)\n\n\n\n\n\ntable(adm_wp_cluster$GCLUSTER7)\n\n\n  1   2   3   4   5   6   7 \n 98 194  86  89 176  88  30 \n\n\nIncreasing the number of clusters to 7 has split up clusters 1 (green) and 4 (red) in the left map.\nThe large low-priority red cluster in the north (left map) split into clusters 4-6 (right map). Green cluster 1 in the left map split into clusters 1 and 7 in the right map, with the new cluster 1 in the south and the new cluster 7 in the north. To determine if this splitting improved the recommendations with respect to the research question, we need to plot the distribution of attributes:\n\nggparcoord(data= adm_wp_cluster,\n           columns=c(6:9, 11:12),\n           mapping = aes(color = as.factor(`GCLUSTER7`)),\n           alphaLines = 0.3,\n           scale=\"uniminmax\",\n           boxplot=TRUE) +\n  labs(title = \"Parallel Coordinates Plots of Waterpoint Availability by Spatial Clusters (k=7)\",\n       subtitle = \"Standardised using Min-Max Normalisation\",\n       xlab = \"Cluster Variables\") +\n  scale_colour_brewer(name=\"Cluster\",\n                      labels = levels(adm_wp_cluster$`GCLUSTER7`),\n                      palette = \"Set3\") +\n  theme(axis.text.x = element_text(angle = 45, size=8),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(~ GCLUSTER7)\n\n\n\n\nSince clusters 2-3 are still the same, we need not characterise them again. From the coordinates plot, we can see that the new clusters 4-6 still generally have high propotion of functional waterpoints and are hence lower priority for maintenance. The new cluster 7 has similar characteristics with clusters 4-6 (high proportion of functional, high proportion of low capacity and high proportion rural). Clusters 4-7 can collectively be assigned low priority.\nWith the regions in better condition split off from cluster 1, cluster 1 now has lower proportions of functional waterpoints and lower proportions of low capacity. Nonetheless, it is still a mid priority cluster.\nThere is no significant change in the recommendation for prioritisation of provision of waterpoints or maintenance so we can retain the clustering result of k=4.\n\n\n\n\nThrough this exercise, I identified a cluster of regions that should be prioritised for increasing supply and improving maintenance by considering both attributes and geospatial location. The spatially constrained clustering produced a better result than aspatial clustering.\nSpatially constrained clustering can also reveal underlying properties about the land. Regions in the north of Nigeria tend to have more small capacity waterpoints but have a higher proportion of functional waterpoints. This could be due to climate factors where the North is more arid and there could be higher reliance on waterpoints.\nThe recommendations on prioritisation of maintenance or increasing provision of waterpoints are based only on the data in the given dataset. Information on water demand (eg. population, population density) and other supplies of water (e.g. rainfall, water bodies) should also be considered to a more holistic understanding of how to meet water needs in Nigeria."
  },
  {
    "objectID": "Hands-on_EX04/Hands-on_EX04.html",
    "href": "Hands-on_EX04/Hands-on_EX04.html",
    "title": "Hands-on Exercise 04",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (aka dependent variable).\nThis exercise will create a hedonic pricing model to explain the effect of locational factors on condominium prices in Singapore in 2015. A number of independent variables on about the property (e.g. size, type of property) and its surroundings (e.g. proximity to amenities) will be used."
  },
  {
    "objectID": "Hands-on_EX04/Hands-on_EX04.html#setting-up",
    "href": "Hands-on_EX04/Hands-on_EX04.html#setting-up",
    "title": "Hands-on Exercise 04",
    "section": "1. Setting Up",
    "text": "1. Setting Up\n\nLoading Packages\n\nsf and spdep: spatial data handling and spatial weights\ntidyverse: manipulation of attribute data and plotting visualisations (aspatial)\ntmap: creating map visualisations\ncorrplot and ggpubr: multivariate data analysis and visualisation\noslrr: building OLS and performing diagnostics tests\nGWmodel: calibrating geographical weighted family of models\ngtsummary: create publication-ready analytical and summary tables\n\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, \n               GWmodel, tmap, tidyverse, gtsummary, kableExtra)\n\n\n\nLoading Data\nThe geospatial dataset that will be used is the Singapore Masterplan 2014 subzone planning boundaries.\n\nmpsz <- st_read(dsn=\"data/geospatial\",\n                layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX04\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWhen importing geospatial files, we should check the projection:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the projection is correct, the EPSG code is incorrect. st_set_crs edits crs information but does not reproject the dataset.\n\nmpsz_svy21 <-st_transform(mpsz, 3414)\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWe can view the geographical extent of the dataset:\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nNow let’s load the aspatial dataset:\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nThe condo dataset contains transactions by condominium blocks. It can be transformed into a geospatial dataset using the latitude and longitude data:\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords=c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\nWe can plot the two geospatial datasets:\n\ntm_shape(mpsz_svy21) +\n  tm_polygons() +\ntm_shape(condo_resale.sf) +\n  tm_dots()"
  },
  {
    "objectID": "Hands-on_EX04/Hands-on_EX04.html#exploratory-data-analysis",
    "href": "Hands-on_EX04/Hands-on_EX04.html#exploratory-data-analysis",
    "title": "Hands-on Exercise 04",
    "section": "2. Exploratory Data Analysis",
    "text": "2. Exploratory Data Analysis\nBefore building a model, we should examine the distribution of the variables in the data. The code below plots histograms for the numeric variables in the dataset.\n\nautoplot <- function(x){\n  ggplot(data=condo_resale.sf, aes(x= get(x))) + \n    geom_histogram(bins=20, color=\"black\", fill=\"light blue\")+\n    labs(x=x)\n}\n\nnumdists <- map(names(condo_resale[4:20]), ~autoplot(.x))\nggarrange(plotlist=numdists, ncol=3, nrow=6)\n\n\n\n\nLinear regression does not require independent variables to be normally distributed, but we should note if there are outliers. The dependent variables should also be linearly correlated with the indepdent variable.\nWe should also check for multicollienarity:\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\nLEASEHOLD_99YEAR has a strong negative correlation with FREEHOLD, so one of them should be excluded in the model. I will exclude LEASEHOLD_99YEAR in the subsequent model building.\nBy setting tmap_mode to view, we get an interactive map. We can also use plot the values of a variable spatially by varying the colour of each point. tm_dots() is used so that the size scales with the zoom.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nSet the plot mode back to plot.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_EX04/Hands-on_EX04.html#regression-models",
    "href": "Hands-on_EX04/Hands-on_EX04.html#regression-models",
    "title": "Hands-on Exercise 04",
    "section": "3. Regression Models",
    "text": "3. Regression Models\n\nSimple Linear Regression\nThe following code creates a simple linear regression (only one explanatory variable). It models the relationship between selling price and size.\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nThe adjusted R-squared value of 0.4515 means that the model can explain about 45% of the variation of the selling price. The p-value of the model is also low (<0.001) so we can reject the null hypothesis that mean selling price is a good estimator of selling price and accept the alternative hypothesis that the model is a better estimator of selling price.\nSince we are only using 2 variables, we can easily plot the relationship:\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWhile the results of the simple linear regression show that size can be used to estimate selling price, we may be able to estimate selling price better by including more explanatory variables.\n\n\nMultiple Linear Regression\nThe following code chunk uses all the available independent variables:\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\nThe tbl_regression() function can create publication-ready summary tables for regression models. The following code chunk produces a clean coefficient table and the summary statistics of the model.\n\ntbl_regression(condo.mlr, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n481,728\n243,505, 719,952\n<0.001\n    AREA_SQM\n12,708\n11,983, 13,433\n<0.001\n    AGE\n-24,441\n-29,861, -19,020\n<0.001\n    PROX_CBD\n-78,670\n-91,948, -65,391\n<0.001\n    PROX_CHILDCARE\n-351,618\n-566,353, -136,883\n0.001\n    PROX_ELDERLYCARE\n171,029\n88,424, 253,635\n<0.001\n    PROX_URA_GROWTH_AREA\n38,475\n13,908, 63,041\n0.002\n    PROX_HAWKER_MARKET\n23,746\n-33,729, 81,222\n0.4\n    PROX_KINDERGARTEN\n147,469\n-14,698, 309,636\n0.075\n    PROX_MRT\n-314,600\n-428,272, -200,928\n<0.001\n    PROX_PARK\n563,280\n432,730, 693,831\n<0.001\n    PROX_PRIMARY_SCH\n180,186\n52,213, 308,159\n0.006\n    PROX_TOP_PRIMARY_SCH\n2,280\n-37,758, 42,318\n>0.9\n    PROX_SHOPPING_MALL\n-206,604\n-290,642, -122,566\n<0.001\n    PROX_SUPERMARKET\n-44,992\n-196,200, 106,217\n0.6\n    PROX_BUS_STOP\n683,121\n411,722, 954,521\n<0.001\n    NO_Of_UNITS\n-231\n-406, -57\n0.010\n    FAMILY_FRIENDLY\n140,341\n48,103, 232,578\n0.003\n    FREEHOLD\n359,913\n263,361, 456,465\n<0.001\n  \n  \n    \n      R² = 0.652; Adjusted R² = 0.647; AIC = 42,970; Statistic = 147; p-value = <0.001; σ = 755,816\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nThe adjusted R-squared value of 0.647 means that the model can explain about 65% of the variation in selling price. This indicates that overall, this multiple linear regression model is a better estimator of the selling price than the simple linear regression model in the previous section.\nHowever, we can also see that not all the variables used were statistically significant (let’s set alpha at 0.05), meaning that we cannot reject the null hypothesis that the coefficient for that variable is 0. Removal of these variables may improve fit.\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\n                   PROX_CHILDCARE + PROX_ELDERLYCARE +PROX_URA_GROWTH_AREA +\n                   PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH +\n                   PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS +\n                   FAMILY_FRIENDLY + FREEHOLD, \n                 data=condo_resale.sf)\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\nCheck Regression Assumptions\nThere are a few main assumptions or requirements in linear regression:\n\nNo multicollinearity between explanatory variables\nLinear relationship between independent and dependent variables\nIndependence of errors\nNormality of errors\nEqual variance of errors\n\nThe linearity assumption and independence of errors can be checked using the following code chunk. The points are approximately randomly scattered around the 0 line, indicating a linear relationship\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nVIFs (variance inflation factor) can be used to check for multicollinearity. A VIF value >10 usually indicates that there is multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nThe following code chunk tests for unequal variance of errors (aka heteroskedasticity). With a low p-value, we reject the null hypothesis and conclude that the variance of errors is not constant.\n\nols_test_breusch_pagan(condo.mlr1)\n\n\n Breusch Pagan Test for Heteroskedasticity\n -----------------------------------------\n Ho: the variance is constant            \n Ha: the variance is not constant        \n\n                  Data                    \n -----------------------------------------\n Response : SELLING_PRICE \n Variables: fitted values of SELLING_PRICE \n\n        Test Summary         \n ----------------------------\n DF            =    1 \n Chi2          =    4573.0707 \n Prob > Chi2   =    0.0000 \n\n\nNormality of errors can be tested by plotting the distribution of errors or using a statistical test. The low p-values mean that we reject the null hypothesis that the data (residuals) follow a normal distribution. In other words, the assumption for normality of residuals does not hold.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------"
  },
  {
    "objectID": "Hands-on_EX04/Hands-on_EX04.html#spatial-autocorrelation",
    "href": "Hands-on_EX04/Hands-on_EX04.html#spatial-autocorrelation",
    "title": "Hands-on Exercise 04",
    "section": "4. Spatial Autocorrelation",
    "text": "4. Spatial Autocorrelation\nGeographically weighted regression estimates a dependent variable that varies across space. First we must test if the dependent variable does indeed exhibit systematic spatial variation, which is also know as spatial autocorrelation.\nFirst, we need to convert the residuals from the multiple linear regression model from sf data frame into a spatial points data frame. The following code chunk extracts the residuals and appends it to the geosptial dataset.\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                             condo.mlr1$residuals) %>%\n  rename(`MLR_RES` = `condo.mlr1.residuals`)\n\nThis code chunk converts it to a spatial points data frame object which is required by the GWmodel functions as input.\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\n\nWe can view the residuals on the map to visually look for spatial autocorrelation.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nThere appears to be spatial autocorrelation. we can see that there are locations with clustering of observations with high residuals.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nFor a more conclusive test, we can use the Moran’s I test to check if residuals are randomly distributed across space.\nFirst, we need to define the neighbourhood. Since we are using point data, we will use a distance-based weight matrix. The following code chunk creates the list of neighbours of each point up to 1.5km away.\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nThen we convert it to a spatial weight matrix using nb2listw(). We are using a row-standardised weight matrix.\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran's I test for residual spatial autocorrelation.\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe p-value of the Moran’s I test is less than the alpha value of 0.05. We can reject the null hypothesis and conclude that residuals are not randomly distributed. Since the observed Moran’s I statistic is 0.14 which is >0, we can infer that there is clustering."
  },
  {
    "objectID": "Hands-on_EX04/Hands-on_EX04.html#building-the-gwr-model",
    "href": "Hands-on_EX04/Hands-on_EX04.html#building-the-gwr-model",
    "title": "Hands-on Exercise 04",
    "section": "5. Building the GWR Model",
    "text": "5. Building the GWR Model\n\nFixed Bandwith\nThe following code chunk is used to determine the optimal fixed bandwidth to use in the model. If we want to use adaptive distance (fixed number of neighbours), we would change the adaptive=FALSE argument to adaptive=TRUE. The approach argument sets the stopping rule to determine the maximum threshold distance.\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe recommended bandwidth is 971.3405m.\nThe following code chunk performs the geographically weighted regression using the fixed bandwidth found in the previous step.\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA +\n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nLet’s check the output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-09 22:21:50 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2022-12-09 22:21:51 \n\n\nThe adjusted R-squared of the model is 0.8430417 which is higher than the R-square of the multiple linear regression model’s R-square of 0.647. This means that the geographically weighted model is able to explain more of the variation in selling price than the multiple linear regression model.\n\n\nAdaptive Bandwidth\nThe following code chunk uses adaptive bandwidth instead. It recommends the number of points that should be considered as neighbours.\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe algorithm recommends 30 as the optimal number of neighbours.\nNow, we can conduct the geographically weighted regression.\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, \n                          bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-09 22:22:00 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2022-12-09 22:22:01 \n\n\nThe R-square of the GWR model using adaptive distance is 0.856 which is also better than that of the MLR model (0.647). It is also slightly better than the GWR model using fixed distance.\n\n\nVisualising GWR Output\nOn top of the printed output shown in the previous sections, the gwr.basic() function also outputs some other diagnostics saved as a spatial points data frame named SDF.\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted y (yhat): these are the estimated (or fitted) y values computed by GWR.\nResiduals: Residuals are the difference between observed y values and the fitted y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nTo visualise the results of the GWR model, we extract it and convert it to an sf object.\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 52\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM                <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE                     <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD                <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE          <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE        <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA    <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT                <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK               <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH        <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL      <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP           <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS             <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY         <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD                <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\nThe following code chunk produces a summary of the predicted y values.\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\nThe following code chunk visualises local R-square\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nWe can see that the GWR model is better at predicting selling prices in some areas than others. Specifically, the model is not as accurate at predicting prices near the centre of Singapore. There could be a variable that is not included in the model that could explain this\nWe can take a close look by restricting the planning areas. These values are specifically in the Bishan, Toa Payoh, Novena and Kallang. Note that there are still points outside these regions as we did not filter the results for the condo_resale.sf.adaptive dataset. It would need to be related to the subzone data to conduct the filtering.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz_svy21[mpsz_svy21$PLN_AREA_C %in% c(\"BS\", \"TP\", \"NV\", \"KL\"), ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  }
]