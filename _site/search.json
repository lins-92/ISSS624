[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to my ISSS6224 Geospatial Analytics webpage! :)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_EX01.html",
    "href": "Hands-on_EX01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The purpose of this exercise is to practice the basics of using geospatial data in R.\n\n\nsf is used to manipulate geospatial data and tidyverse for aspatial data. kableExtra makes tables with nicer formating.\n\n\n\n\n\nLet’s load the geospatial data.\n\nmpsz = st_read(dsn = \"Hands-on_EX01/data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath = st_read(dsn = \"Hands-on_EX01/data/geospatial\", \n                      layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool = st_read(\"Hands-on_EX01/data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that each file has a different geometry type to represent different types of features.\nWe can also see that mpsz and cyclingpath both have the same projected CRS of SVY21 but preschools has a geodetic CRS of WGS 84. These refer to the coordinate systems to model geographic location and how to represent this information on a flat surface. Here is a detailed explanation on why coordinate systems are needed and the difference between a geodetic CRS (GCS) and projected CRS (PCS).\n\n\n\nThe st_geometry command displays the geometry information of a spatial dataset.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nWe can use glimpse to get an overview of the different variables in the dataset and head to view the first few entries.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    OBJECTID \n    SUBZONE_NO \n    SUBZONE_N \n    SUBZONE_C \n    CA_IND \n    PLN_AREA_N \n    PLN_AREA_C \n    REGION_N \n    REGION_C \n    INC_CRC \n    FMEL_UPD_D \n    X_ADDR \n    Y_ADDR \n    SHAPE_Leng \n    SHAPE_Area \n    geometry \n  \n \n\n  \n    1 \n    1 \n    MARINA SOUTH \n    MSSZ01 \n    Y \n    MARINA SOUTH \n    MS \n    CENTRAL REGION \n    CR \n    5ED7EB253F99252E \n    2014-12-05 \n    31595.84 \n    29220.19 \n    5267.381 \n    1630379.3 \n    MULTIPOLYGON (((31495.56 30... \n  \n  \n    2 \n    1 \n    PEARL'S HILL \n    OTSZ01 \n    Y \n    OUTRAM \n    OT \n    CENTRAL REGION \n    CR \n    8C7149B9EB32EEFC \n    2014-12-05 \n    28679.06 \n    29782.05 \n    3506.107 \n    559816.2 \n    MULTIPOLYGON (((29092.28 30... \n  \n  \n    3 \n    3 \n    BOAT QUAY \n    SRSZ03 \n    Y \n    SINGAPORE RIVER \n    SR \n    CENTRAL REGION \n    CR \n    C35FEFF02B13E0E5 \n    2014-12-05 \n    29654.96 \n    29974.66 \n    1740.926 \n    160807.5 \n    MULTIPOLYGON (((29932.33 29... \n  \n  \n    4 \n    8 \n    HENDERSON HILL \n    BMSZ08 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    3775D82C5DDBEFBD \n    2014-12-05 \n    26782.83 \n    29933.77 \n    3313.625 \n    595428.9 \n    MULTIPOLYGON (((27131.28 30... \n  \n  \n    5 \n    3 \n    REDHILL \n    BMSZ03 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    85D9ABEF0A40678F \n    2014-12-05 \n    26201.96 \n    30005.70 \n    2825.594 \n    387429.4 \n    MULTIPOLYGON (((26451.03 30... \n  \n\n\n\n\n\nWe can also create simple plots of spatial data using the base R plot function. We can use indexing to indicate the variable to group by.\n\nplot(mpsz[\"CA_IND\"])\n\n\n\n\n\n\n\nThe st_crs displays the details of a spatial dataset’s projection. In this example, the EPSG code has been wrongly specified and needs to be corrected. The st_set_crs command only changes the code but does not actually change the coordinate system. It is only used to correcting wrongly specified projection information.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo change the coordinate system (called transformation or projection), we use the the st_transform function. We will use this function to transform the preschool dataset to the same projection system as the other 2 layers (SVY21).\n\npreschool <- st_transform(preschool,\n                          crs=3414)\n\n\n\n\nSometimes we have datasets that have spatial information (e.g. latitude and longitude) that are not already in geospatal file formats (shp, gpkg, kml). We will need to import them as aspatial data first then specify which variables contain the geometries and how to represent these data spatially (ie. the coordinate system).\n\nlistings <- read_csv(\"Hands-on_EX01/data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(listings)\n\nRows: 4,252\nColumns: 16\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.34531, 1.2…\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596, 103.9610,…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n\n\nFrom the glimpse, we can see that the latitude and longitude variables contain the spatial information we need. The units used are decimal degrees.\nNow let’s use the st_as_sf function to transform the listings dataset into geospatial data. Use the coords argument to specify the x and y coordinates (longitude then latitude) respectively. We assume that the original coordinate system was WGS84 (EPSG 4326) and reproject it to SVY21 (EPSG 3414).\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %>%\n  st_transform(crs=3414)\n\n\n\n\n\n\n\nBuffers create a zone around a feature. It is used in geospatial analyses in conjunction with other functions to measure access to amenities (e.g. how many households are within 500m proximity to an MRT station?). The function is st_buffer.\nIn this example, we want to calculate the area of land that needs to be set aside for to 5m wide cycling paths.. The original cycling path layer is a polyline dataset which has no width so we need to use create a buffer first then calculate area using the st_area function.\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                            dist=5, nQuadSegs = 30)\n\nbuffer_cycling$area = st_area(buffer_cycling)\n\nsum(buffer_cycling$area)\n\n773143.9 [m^2]\n\n\n\n\n\nCounting the number of points (features) in a polygon is another common geoprocessing tool. We use the st_intersects function to relate the point and polygon layers spatially. It will output a list of points located within each polygon (by their respective indices). The lengths function from base R is used to find the number of elements (ie pre-schools) in each polygon.\nIn this example, we will count the number of pre-schools in each subzone.\n\nmpsz <- mpsz %>%\n  mutate(preschools = lengths(st_intersects(x=mpsz,y=preschool)))\n\nplot(mpsz[\"preschools\"])"
  },
  {
    "objectID": "Hands-on_EX01.html#importing-and-preparing-data-1",
    "href": "Hands-on_EX01.html#importing-and-preparing-data-1",
    "title": "Hands-on Exercise 1",
    "section": "Importing and Preparing Data",
    "text": "Importing and Preparing Data\n\nLoading and Manipulating Data\nThis exercise uses the mpsz dataset from Part 1 and a new attribute dataset containing population data by subzone.\n\npopdata <- read_csv(\"Hands-on_EX01/data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   <chr> \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   <chr> \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   <chr> \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  <chr> \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  <chr> \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  <dbl> 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\nhead(popdata, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    PA \n    SZ \n    AG \n    Sex \n    TOD \n    Pop \n    Time \n  \n \n\n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 1- and 2-Room Flats \n    0 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 3-Room Flats \n    10 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 4-Room Flats \n    30 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 5-Room and Executive Flats \n    50 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HUDC Flats (excluding those privatised) \n    0 \n    2011 \n  \n\n\n\n\n\nFor this exercise, we will only be using the 2020 data. We need to relate the attribute data to the mpsz dataset. First, we need to manipulate the attribute data to create the following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMYACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npop2020 <- popdata %>%\n  filter(Time==2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(POP = sum(Pop)) %>%\n  ungroup() %>%\n  pivot_wider(names_from = AG, \n              values_from = POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])+ rowSums(.[12])) %>%\n  mutate(ECONOMYACTIVE = rowSums(.[7:11]) + rowSums(.[13:15])) %>%\n  mutate(AGED=rowSums(.[16:21])) %>%\n  mutate(TOTAL=rowSums(.[3:21])) %>%  \n  mutate(DEPENDENCY = (YOUNG + AGED)/ ECONOMYACTIVE) %>%\n  select(PA, SZ, YOUNG, ECONOMYACTIVE, AGED, TOTAL, DEPENDENCY) %>%\n  mutate(across(PA:SZ, toupper))\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nJoin the attribute data to the mpsz data by SZ. In the previous step, we manipulated this variable to be uppercase to match with the mpsz file.\n\nmpsz_pop2020 <- left_join(x=mpsz,\n                          y=pop2020,\n                          by= c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_EX01.html#choropleth-maps",
    "href": "Hands-on_EX01.html#choropleth-maps",
    "title": "Hands-on Exercise 1",
    "section": "Choropleth Maps",
    "text": "Choropleth Maps\n\nBasic Map\nA basic choropleth map with no customisations can be created using the qtm function. It uses a number of defaults which may not always be useful depending on the dataset. In the example below, the pretty breaks result in a map which is not informative because of the distribution of dependency ratio.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nMore Customisations\ntmap also allows us to customise each aspect of the map more finely. The code chunk below uses the same dependency ratio data as the above map but splits by quantiles instead to show the distribution more clearly. Other customisations create map elements like title, map scale, map grid and compass.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_EX01/Hands-on_EX01.html",
    "href": "Hands-on_EX01/Hands-on_EX01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The purpose of this exercise is to practice the basics of using geospatial data in R.\n\n\nsf is used to manipulate geospatial data and tidyverse for aspatial data. kableExtra makes tables with nicer formating.\n\n\n\n\n\nLet’s load the geospatial data.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                      layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX01\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that each file has a different geometry type to represent different types of features.\nWe can also see that mpsz and cyclingpath both have the same projected CRS of SVY21 but preschools has a geodetic CRS of WGS 84. These refer to the coordinate systems to model geographic location and how to represent this information on a flat surface. Here is a detailed explanation on why coordinate systems are needed and the difference between a geodetic CRS (GCS) and projected CRS (PCS).\n\n\n\nThe st_geometry command displays the geometry information of a spatial dataset.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nWe can use glimpse to get an overview of the different variables in the dataset and head to view the first few entries.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    OBJECTID \n    SUBZONE_NO \n    SUBZONE_N \n    SUBZONE_C \n    CA_IND \n    PLN_AREA_N \n    PLN_AREA_C \n    REGION_N \n    REGION_C \n    INC_CRC \n    FMEL_UPD_D \n    X_ADDR \n    Y_ADDR \n    SHAPE_Leng \n    SHAPE_Area \n    geometry \n  \n \n\n  \n    1 \n    1 \n    MARINA SOUTH \n    MSSZ01 \n    Y \n    MARINA SOUTH \n    MS \n    CENTRAL REGION \n    CR \n    5ED7EB253F99252E \n    2014-12-05 \n    31595.84 \n    29220.19 \n    5267.381 \n    1630379.3 \n    MULTIPOLYGON (((31495.56 30... \n  \n  \n    2 \n    1 \n    PEARL'S HILL \n    OTSZ01 \n    Y \n    OUTRAM \n    OT \n    CENTRAL REGION \n    CR \n    8C7149B9EB32EEFC \n    2014-12-05 \n    28679.06 \n    29782.05 \n    3506.107 \n    559816.2 \n    MULTIPOLYGON (((29092.28 30... \n  \n  \n    3 \n    3 \n    BOAT QUAY \n    SRSZ03 \n    Y \n    SINGAPORE RIVER \n    SR \n    CENTRAL REGION \n    CR \n    C35FEFF02B13E0E5 \n    2014-12-05 \n    29654.96 \n    29974.66 \n    1740.926 \n    160807.5 \n    MULTIPOLYGON (((29932.33 29... \n  \n  \n    4 \n    8 \n    HENDERSON HILL \n    BMSZ08 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    3775D82C5DDBEFBD \n    2014-12-05 \n    26782.83 \n    29933.77 \n    3313.625 \n    595428.9 \n    MULTIPOLYGON (((27131.28 30... \n  \n  \n    5 \n    3 \n    REDHILL \n    BMSZ03 \n    N \n    BUKIT MERAH \n    BM \n    CENTRAL REGION \n    CR \n    85D9ABEF0A40678F \n    2014-12-05 \n    26201.96 \n    30005.70 \n    2825.594 \n    387429.4 \n    MULTIPOLYGON (((26451.03 30... \n  \n\n\n\n\n\nWe can also create simple plots of spatial data using the base R plot function. We can use indexing to indicate the variable to group by.\n\nplot(mpsz[\"CA_IND\"])\n\n\n\n\n\n\n\nThe st_crs displays the details of a spatial dataset’s projection. In this example, the EPSG code has been wrongly specified and needs to be corrected. The st_set_crs command only changes the code but does not actually change the coordinate system. It is only used to correcting wrongly specified projection information.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo change the coordinate system (called transformation or projection), we use the the st_transform function. We will use this function to transform the preschool dataset to the same projection system as the other 2 layers (SVY21).\n\npreschool <- st_transform(preschool,\n                          crs=3414)\n\n\n\n\nSometimes we have datasets that have spatial information (e.g. latitude and longitude) that are not already in geospatal file formats (shp, gpkg, kml). We will need to import them as aspatial data first then specify which variables contain the geometries and how to represent these data spatially (ie. the coordinate system).\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(listings)\n\nRows: 4,252\nColumns: 16\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.34531, 1.2…\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596, 103.9610,…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n\n\nFrom the glimpse, we can see that the latitude and longitude variables contain the spatial information we need. The units used are decimal degrees.\nNow let’s use the st_as_sf function to transform the listings dataset into geospatial data. Use the coords argument to specify the x and y coordinates (longitude then latitude) respectively. We assume that the original coordinate system was WGS84 (EPSG 4326) and reproject it to SVY21 (EPSG 3414).\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %>%\n  st_transform(crs=3414)\n\n\n\n\n\n\n\nBuffers create a zone around a feature. It is used in geospatial analyses in conjunction with other functions to measure access to amenities (e.g. how many households are within 500m proximity to an MRT station?). The function is st_buffer.\nIn this example, we want to calculate the area of land that needs to be set aside for to 5m wide cycling paths.. The original cycling path layer is a polyline dataset which has no width so we need to use create a buffer first then calculate area using the st_area function.\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                            dist=5, nQuadSegs = 30)\n\nbuffer_cycling$area = st_area(buffer_cycling)\n\nsum(buffer_cycling$area)\n\n773143.9 [m^2]\n\n\n\n\n\nCounting the number of points (features) in a polygon is another common geoprocessing tool. We use the st_intersects function to relate the point and polygon layers spatially. It will output a list of points located within each polygon (by their respective indices). The lengths function from base R is used to find the number of elements (ie pre-schools) in each polygon.\nIn this example, we will count the number of pre-schools in each subzone.\n\nmpsz <- mpsz %>%\n  mutate(preschools = lengths(st_intersects(x=mpsz,y=preschool)))\n\nplot(mpsz[\"preschools\"])"
  },
  {
    "objectID": "Hands-on_EX01/Hands-on_EX01.html#importing-and-preparing-data-1",
    "href": "Hands-on_EX01/Hands-on_EX01.html#importing-and-preparing-data-1",
    "title": "Hands-on Exercise 1",
    "section": "Importing and Preparing Data",
    "text": "Importing and Preparing Data\n\nLoading and Manipulating Data\nThis exercise uses the mpsz dataset from Part 1 and a new attribute dataset containing population data by subzone.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   <chr> \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   <chr> \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   <chr> \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  <chr> \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  <chr> \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  <dbl> 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\nhead(popdata, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    PA \n    SZ \n    AG \n    Sex \n    TOD \n    Pop \n    Time \n  \n \n\n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 1- and 2-Room Flats \n    0 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 3-Room Flats \n    10 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 4-Room Flats \n    30 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HDB 5-Room and Executive Flats \n    50 \n    2011 \n  \n  \n    Ang Mo Kio \n    Ang Mo Kio Town Centre \n    0_to_4 \n    Males \n    HUDC Flats (excluding those privatised) \n    0 \n    2011 \n  \n\n\n\n\n\nFor this exercise, we will only be using the 2020 data. We need to relate the attribute data to the mpsz dataset. First, we need to manipulate the attribute data to create the following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMYACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npop2020 <- popdata %>%\n  filter(Time==2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(POP = sum(Pop)) %>%\n  ungroup() %>%\n  pivot_wider(names_from = AG, \n              values_from = POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])+ rowSums(.[12])) %>%\n  mutate(ECONOMYACTIVE = rowSums(.[7:11]) + rowSums(.[13:15])) %>%\n  mutate(AGED=rowSums(.[16:21])) %>%\n  mutate(TOTAL=rowSums(.[3:21])) %>%  \n  mutate(DEPENDENCY = (YOUNG + AGED)/ ECONOMYACTIVE) %>%\n  select(PA, SZ, YOUNG, ECONOMYACTIVE, AGED, TOTAL, DEPENDENCY) %>%\n  mutate(across(PA:SZ, toupper))\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nJoin the attribute data to the mpsz data by SZ. In the previous step, we manipulated this variable to be uppercase to match with the mpsz file.\n\nmpsz_pop2020 <- left_join(x=mpsz,\n                          y=pop2020,\n                          by= c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_EX01/Hands-on_EX01.html#choropleth-maps",
    "href": "Hands-on_EX01/Hands-on_EX01.html#choropleth-maps",
    "title": "Hands-on Exercise 1",
    "section": "Choropleth Maps",
    "text": "Choropleth Maps\n\nBasic Map\nA basic choropleth map with no customisations can be created using the qtm function. It uses a number of defaults which may not always be useful depending on the dataset. In the example below, the pretty breaks result in a map which is not informative because of the outlier.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nMore Customisations\ntmap also allows us to customise each aspect of the map more finely. The code chunk below uses the same dependency ratio data as the above map but splits by quantiles instead to show the distribution more clearly. Other customisations create map elements like title, map scale, map grid and compass.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThere are also other styles to create breaks. The map below uses the hclust method to create breaks and the number of breaks is increased to 10. Although the number of breaks is increased, the map is not necessarily more informative than the previous map using 5 quantile breaks.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          n=10,\n          style = \"hclust\", \n          palette = \"Reds\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In-class_EX01/In-class_EX01.html",
    "href": "In-class_EX01/In-class_EX01.html",
    "title": "In-Class Exercise 01",
    "section": "",
    "text": "We will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\n\nThis dataset contains the administrative boundaries of the Hunan province in China.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\lins-92\\ISSS624\\In-class_EX01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNext, we import the aspatial data containing some economic indicators of the counties within Hunan.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLastly, we join the aspatial data to the spatial data.\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\nJoining, by = \"County\"\n\n\nWe can now visual GDP per capita for each county.\n\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nThe poly2nb() function of the spdep package cna be used to compute contiguity weight matrices.\n\n\nBy setting queen=TRUE, the poly2nb() function will output the matrix using the queen method.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nWe can view the complete weight matrix using str(). It displays the indices of neighbours.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\nIf we want to retrieve the GDP per capita of all neighbours of polygon 1, we can use the following code chunk. The first line store the indices of all neighbours of 1 by retrieving it from the nested list. The next line uses these indices to retrieve the values from the Hunan GDPPC variable by index.\n\nnb1 <- wm_q[[1]]\nhunan$GDPPC[nb1]\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\nBy changing queen=FALSE, the rook method will be used.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nCompared to the queen method, the rook method produces fewer nonzero links because the rook method is more restrictive than queen method.\n\n\n\nRow standardisation is applied to adjust the weights of each neighbour by the size of the neighbourhood. There are a few ways to perform row standardisation (see below). In the code chunk below, we use “W” where each neighbour is assigned the weight of 1/(#no of neighbours).\nThe function used is the nb2listw(). The options for style are :\n\n“W” row standardised (each row sums to 1)\n“B” binary\n“C” globally standardised (weight = total no of areas/total links)\n“U” unequal (all weights sum to 1)\n“minmax” standardised by minimum and maximum of row\n\n“S” variance standardised\n\nrswm_q <- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\nSpatial weights can be visualised using connectivity graphs. Since the Hunan dataset is in polygons, we need to extract their centroids to do visualisation.\nThe following code chunk uses st_centroid() to generate the latitude and longitude of each polygon centroid and store in vectors. Lastly, the vectors are combined into a single object.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude, latitude)\n\nNow we can plot the connectivity graph. The first line plots the polygons and the second line plots the connectivity matrix by from the connections in weight matrix and the location of the points in coords.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\ntitle(main=\"Connectivity Graph (Queen)\")\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\ntitle(main=\"Connectivity Graph (Rook)\")\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\ntitle(main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\ntitle(main=\"Rook Contiguity\")\n\n\n\n\n\n\n\n\nFor distance weight matrices, the dnearneigh() function of the spdep package is used.\nThe function identifies neighbours of points by Euclidean distance within a specified distance band.\n\n\nA fixed distance weight matrix considers any points within a certain fixed distance as a neighbour. To find this, we first need to set the upper limit for the distance band. We do this using the knearneigh() function by setting k=1 to generate a knn object. It is passed to the knn2nb() function to create a list of indices of the nearest neighbour to each centroid. We then use the nbdists() to compute the distance between each centroid and nearest neighbour.\n\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the summary, we see that the maximum distance between a centroid and its nearest neighbour centroid is 61.79km. If we set the maximum distance at 62km, all centroids will have at least one neighbour. The code chunk below creates a spatial matrix using 62km as the maximum distance.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAt maximum distance of 62km, the average number of neighbours is 3.68.\nNow we can plot the connectivty graph:\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\ntitle(main=\"1st nearest neighbours\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\ntitle(main=\"Distance link (62km)\")\n\n\n\n\n\n\n\nThe adaptive distance weight matrix is another way to build a distance weight matrix. Instead of using a fixed distance to find neighbours, it uses a fixed number of neighbours.\nWe use the knearneigh() function again but set the value of k at a larger number.\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe do not need the additional step of find the distance between neighbours since we have already fixed the number of neighbours. Nonetheless, we can use the following code to understand how the distance considered has changed between methods. Because some areas are more sparse or polygons are larger, the distance considered has naturally increased. The maximum distance considered is now 125km compared to 62km in the fixed distance method.\n\nk6dists <- unlist(nbdists(knn6, coords, longlat = TRUE))\nsummary(k6dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   45.30   57.56   57.89   67.73  124.88 \n\n\nWe can plot the adaptive distance weight matrix connectivity graph:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\ntitle(main=\"Adaptive distnace (k=6)\")\n\n\n\n\n\n\n\nThe inverse distance matrix uses actual distance not just binary weights. It is inversed because weightage should decrease with distance.\nWe can compute distance between points using the nbdists() function. Note that we use the queen contiguity matrix here. Although distance is considered, the neighbourhood is still based on queen contiguity.\n\ndist <- nbdists(wm_q, coords, longlat = TRUE)\nids <- lapply(dist, function(x) 1/(x))\nhead(ids, 5)\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n\n\n\n\nWe can also apply row standardisation to the inverse distance weight matrix.\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nThe code below displays the weights that will be applied to the neighbours of polygon 1.\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n\n\n\n\n\nSpatial weight matrices are typically used in computing spatially lagged values. Spatially lagged values can be used in spatial lag regression as an independent variable to account for the effect of a location’s neighbours.\nIn the following code chunk, we use the row-standardised queen contiguity matrix to compute the average GDP per capita for each polygon’s neighbours.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nhead(GDPPC.lag,5)\n\n[1] 24847.20 22724.80 24143.25 27737.50 27270.25\n\n\nWe join the spatially lagged mean GDP per capita values to the Hunan dataset below:\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nNow we can plot the lagged GDP per capita.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nThe spatially lagged sum is just the sum of the neighbours values. This means that each neighbour has a weight of 1.\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWe can then add compute the spatially lagged sum and join it to the Hunan dataset for plotting.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"NAME_3\"\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nThe spatial window average and sum basically include the area itself, not only its neighbours. To do that, we need to change the diagonal values of the matrix to 1 using the include_self() function.\n\nwm_q1 <- nb2listw(include.self(wm_q))\nwm_q1\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\n\nlag_w_avg_gpdpc <- lag.listw(wm_q1, \n                             hunan$GDPPC)\nhead(lag_w_avg_gpdpc)\n\n[1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17\n\n\nJoin the spatial window mean to the Hunan dataset and plot it.\n\nlag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan <- left_join(hunan, lag_wm_q1.res)\n\nJoining, by = \"NAME_3\"\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\nWe can repeat the process to get spatial window sum.\n\nb_weights <- lapply(include.self(wm_q), \n                    function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nb_weights2 <- nb2listw(include.self(wm_q), \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"NAME_3\"\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_EX02/Hands-on_EX02.html",
    "href": "Hands-on_EX02/Hands-on_EX02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Spatial autocorrelation measures the degree to which one object is similar to other nearby objects. Spatial autocorrelation is an important consideration in geospatial analysis because it means that observations are not independent of each other.\nOne of the common measures of spatial autocorrelation is Moran’s I. It takes a value between -1 and 1. The closer the value is to 1, the more clustered the dependent variable is spatially; the closer the value is to 01, the more dispersed the dependent variable is.\n\n\n\nAdapted from https://www.statology.org/morans-i/\n\n\nThis exercise is to practice how to computing spatiial autocorrelation.\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\n\n\n\n\nThis dataset contains the administrative boundaries of the Hunan province in China.\n\nhunan <- st_read(dsn=\"data/geospatial\",\n                 layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\lins-92\\ISSS624\\Hands-on_EX02\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(hunan)\n\nRows: 88\nColumns: 8\n$ NAME_2     <chr> \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       <int> 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     <chr> \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  <chr> \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng <dbl> 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area <dbl> 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     <chr> \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   <POLYGON [°]> POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\nhead(hunan, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    NAME_2 \n    ID_3 \n    NAME_3 \n    ENGTYPE_3 \n    Shape_Leng \n    Shape_Area \n    County \n    geometry \n  \n \n\n  \n    Changde \n    21098 \n    Anxiang \n    County \n    1.869074 \n    0.1005619 \n    Anxiang \n    POLYGON ((112.0625 29.75523... \n  \n  \n    Changde \n    21100 \n    Hanshou \n    County \n    2.360691 \n    0.1997875 \n    Hanshou \n    POLYGON ((112.2288 29.11684... \n  \n  \n    Changde \n    21101 \n    Jinshi \n    County City \n    1.425620 \n    0.0530241 \n    Jinshi \n    POLYGON ((111.8927 29.6013,... \n  \n  \n    Changde \n    21102 \n    Li \n    County \n    3.474324 \n    0.1890812 \n    Li \n    POLYGON ((111.3731 29.94649... \n  \n  \n    Changde \n    21103 \n    Linli \n    County \n    2.289506 \n    0.1145036 \n    Linli \n    POLYGON ((111.6324 29.76288... \n  \n\n\n\n\n\n\ntm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"County\", size=0.5)\n\n\n\n\nNow let’s load the attribute data. This dataset contains some economic indicators of counties in the Hunan province.\n\necon <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(econ)\n\nRows: 88\nColumns: 29\n$ County      <chr> \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        <chr> \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    <dbl> 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    <dbl> 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         <dbl> 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     <dbl> 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     <dbl> 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         <dbl> 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       <dbl> 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         <dbl> 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        <dbl> 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       <dbl> 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         <dbl> 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         <dbl> 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        <dbl> 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       <dbl> 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     <dbl> 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     <dbl> 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   <dbl> 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R <dbl> 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        <dbl> 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       <dbl> 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        <dbl> 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       <dbl> 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        <dbl> 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     <dbl> 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    <dbl> 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        <dbl> 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      <dbl> 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\nhead(econ, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    County \n    City \n    avg_wage \n    deposite \n    FAI \n    Gov_Rev \n    Gov_Exp \n    GDP \n    GDPPC \n    GIO \n    Loan \n    NIPCR \n    Bed \n    Emp \n    EmpR \n    EmpRT \n    Pri_Stu \n    Sec_Stu \n    Household \n    Household_R \n    NOIP \n    Pop_R \n    RSCG \n    Pop_T \n    Agri \n    Service \n    Disp_Inc \n    RORP \n    ROREmp \n  \n \n\n  \n    Anhua \n    Yiyang \n    30544 \n    10967.0 \n    6831.7 \n    456.72 \n    2703.0 \n    13225.0 \n    14567 \n    9276.9 \n    3954.9 \n    3528.3 \n    2718 \n    494.31 \n    441.4 \n    338.0 \n    54.175 \n    32.830 \n    290.4 \n    234.5 \n    101 \n    670.3 \n    5760.60 \n    910.8 \n    4942.253 \n    5414.5 \n    12373 \n    0.7359464 \n    0.8929619 \n  \n  \n    Anren \n    Chenzhou \n    28058 \n    4598.9 \n    6386.1 \n    220.57 \n    1454.7 \n    4941.2 \n    12761 \n    4189.2 \n    2555.3 \n    3271.8 \n    970 \n    290.82 \n    255.4 \n    99.4 \n    33.171 \n    17.505 \n    104.6 \n    121.9 \n    34 \n    243.2 \n    2386.40 \n    388.7 \n    2357.764 \n    3814.1 \n    16072 \n    0.6256753 \n    0.8782065 \n  \n  \n    Anxiang \n    Changde \n    31935 \n    5517.2 \n    3541.0 \n    243.64 \n    1779.5 \n    12482.0 \n    23667 \n    5108.9 \n    2806.9 \n    7693.7 \n    1931 \n    336.39 \n    270.5 \n    205.9 \n    19.584 \n    17.819 \n    148.1 \n    135.4 \n    53 \n    346.0 \n    3957.90 \n    528.3 \n    4524.410 \n    14100.0 \n    16610 \n    0.6549309 \n    0.8041262 \n  \n  \n    Baojing \n    Hunan West \n    30843 \n    2250.0 \n    1005.4 \n    192.59 \n    1379.1 \n    4087.9 \n    14563 \n    3623.5 \n    1253.7 \n    4191.3 \n    927 \n    195.17 \n    145.6 \n    116.4 \n    19.249 \n    11.831 \n    73.2 \n    69.9 \n    18 \n    184.1 \n    768.04 \n    281.3 \n    1118.561 \n    541.8 \n    13455 \n    0.6544614 \n    0.7460163 \n  \n  \n    Chaling \n    Zhuzhou \n    31251 \n    8241.4 \n    6508.4 \n    620.19 \n    1947.0 \n    11585.0 \n    20078 \n    9157.7 \n    4287.4 \n    3887.7 \n    1449 \n    330.29 \n    299.0 \n    154.0 \n    33.906 \n    20.548 \n    148.7 \n    139.4 \n    106 \n    301.6 \n    4009.50 \n    578.4 \n    3793.550 \n    5444.0 \n    20461 \n    0.5214385 \n    0.9052651 \n  \n\n\n\n\n\nJoin the attribute data to the geospatial data using left_join.\n\nhunan <- left_join(x=hunan,\n                   y=econ,\n                   by=\"County\")\n\n\n\n\nFirst, let’s visualise GDP per capita of the different counties in Hunan province using a choropleth map.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n=5,\n          style=\"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n=5,\n          style=\"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Quantile\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\nTo compute global spatial autocorrelation, we first need to compute a spatial weight matrix. The poly2nb() function from the spdep package is used to compute a contiguity matrix using the queen’s method. This gives a basic weight matrix to indicate if areas are contiguous with each other.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nContiguity matrices are typically not used in raw form. The matrix is often row standardised by dividing each value by the sum of neighbours in a row such that each neighbour of an area applies an equal weightage. Each row will sum up to 1 (all rows are equal).\nThe function used is the nb2listw(). The options for style are :\n\n“W” row standardised (each row sums to 1)\n“B” binary\n“C” globally standardised (weight = total no of areas/total links)\n“U” unequal (all weights sum to 1)\n“minmax” standardised by minimum and maximum of row\n“S” variance standardised\n\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nNow we can finally conduct the Moran’s I test with the moran.test() function from spdep.\n\nmoran.test(hunan$GDPPC,\n           rswm_q,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThe null hypothesis of the Moran’s I test is that the data is randomly distributed (ie Moran’s I=0). In the above example, the null hypothesis is that the data is clustered (ie Moran’s I>0). At 5% significance level, we reject the null hypothesis and accept the alternative hypothesis that there is spatial clustering of GDP per capita. The computed Moran’s I is 0.3, indicating that there is some degree of spatially clustering.\n\n\n\nThe Moran’s I test assumes that the variable follows a normal distribution and is a random sample. When we are unsure of the underlying assumption of the variable, we can use Monte Carlo Moran’s I test instead. This test involves repeated random sampling from the dataset to estimate the distribution of Moran’s I if the variable were a random distributed across space, then compares the computed Moran’s I from the full dataset to this distribution.\n\nset.seed=1234\n\nbperm <- moran.mc(hunan$GDPPC,\n                  rswm_q,\n                  nsim=999,\n                  zero.policy=TRUE,\n                  na.action=na.omit)\n\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe null hypothesis of the Moran’s I test is that the data is randomly distributed or perfectly dispersed (ie Moran’s I<=0). In the above example, the null hypothesis is that the data is clustered (ie Moran’s I>0). At 5% significance level, we reject the null hypothesis and accept the alternative hypothesis that there is spatial clustering of GDP per capita. The computed Moran’s I is 0.3, indicating that there is some degree of spatially clustering.\nWe can use the simulated data to plot the probability distribution of Moran’s I.\n\nmcdata <- as_tibble(bperm$res)\n\nggplot(data=mcdata) +\n  geom_histogram(aes(x=value), \n                 colour=\"black\",\n                 fill=\"light blue\", bins=30) +\n  geom_vline(xintercept=0,\n             colour=\"black\",\n             linetype=\"dashed\") +\n  geom_vline(xintercept=mean(mcdata$value),\n             colour=\"red\") +\n  annotate(geom = \"text\",\n           label=paste0(\"mean =\\n\",\n                        signif(mean(mcdata$value), 3)),\n           x=-0.043,\n           y=139) +\n  ylim(0, 150) +\n  labs(title=\"Simulated Moran's I\",\n       x=\"Simulated Moran's I\", \n       y=\"Frequency\") +\n  theme_bw()\n\n\n\n\nThis is the sampling distribution of Moran’s I, which is approximately a normal distribution. The null hypothesis is the Moran’s I <=0 (although the sample mean is actually slightly less than 0). If the null hypothesis is true, it is unlikely to get values more than 0. From the distribution, we can see that it is unlikely to get the computed Moran’s I of 0.3 if the null hypothesis hold true. As such, we can reject the null hypothesis and conclude that there is clustering observed in the GDP per capita in Hunan.\n\n\n\nGeary’s C test is another method to measure spatial autocorrelation. The geary.test() function from the spdep package is used to perform this test. The Geary C test statistic lies between 0 and 3 with 0 meaning perfect clustering, 1 meaning random distribution and 3 meaning perfect dispersion.\n\ngeary.test(hunan$GDPPC, \n           listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nThe null hypothesis is that Geary’s C >=1 (randomly distributed or perfected dispersed). At 5% significance level, we can reject the null hypothesis and conclude that C <1. The value of 0.69 indicates that GDP per capita is spatially clustered.\n\n\n\nA spatial correlogram can be used to visualise patterns of spatial autocorrelation with increasing lags (distance). Logically, correlation should decrease with more lags. Increasing lags means that we are testing if further locations are correlated with an area. The y-axis is usually Moran’s I or Geary’s C.\nThe code chunk below generates a spatial correlogram using Moran’s I. As the order of contiguity increases, GDP per capita is less correlated, which is to be expected.\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nWe can also view the detail test statistics to check significance of results.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe code chunk below generates a spatial correlogram using Geary’s C. As the order of contiguity increases, GDP per capita is less correlated.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nLocal indicators spatial autocorrelation (LISA) are used to evaluate the existence of clusters and outliers in the spatial arrangement of a variable. The difference between global and local indicators of spatial autocorrelation is that local indicators are computed for each observation. Each value measures the extent of significant spatial clustering of similar values around that observation.\n\n\nLocal Moran’s I can be computed using the localmoran() function. The first line of the code creates a list of the indices by alphabetical order of county name. It will be used later to order the local Moran’s I test output.\n\nfips <- order(hunan$County)\n\nlocalMI <- localmoran(hunan$GDPPC,\n                      rswm_q)\n\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() outputs the following:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local Moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local Moran statistic under the randomisation hypothesis\nZ.Ii: the standard deviation of local Moran statistic\nPr(): the p-value of local Moran statistic\n\nIn this case, the null hypotheses are that GDP per capita are randomly distributed around each area. The default is the two-sided test shown, but this can be adjusted in the arguments of the localmoran() function.\nThe following code chunk prints all the local Moran’s I statistics:\n\nprintCoefmat(data.frame(localMI[fips,], \n                        row.names=hunan$County[fips]), \n             check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n\nTo map the local Moran’s I, first we need to join it to the spatial data.\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nNow, we can create the map.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style=\"pretty\",\n          palette =\"RdBu\",\n          title=\"Local Moran Statistics\") +\n  tm_borders(alpha=0.5)\n\nlocalMI.map\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nThe map seems to indicate that there is a high degree of clustering in some of the north-eastern counties. Some counties have low local Moran’s I, indicating that GDP per capita in surrounding counties are dispersed.\nHowever, this map alone is not enough to conclude if there is not is no clustering of values. We need the p-values as well to evaluate whether the local Moran’s I statistic for each area is significant.\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette =\"-Blues\",\n          title=\"Local Moran's I p-values\") +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(localMI.map, pvalue.map,\n             asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nUsing these 2 maps, we can conclude that there is indeed clustering in some of the north eastern counties. However, the Moran’s I statistic of counties with high degree dispersion indicated in the first map were not significant and hence we cannot reject the null hypothesis that values were randomly.\n\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations. We can plot this using the moran.plot() function.\n\nmoran.plot(hunan$GDPPC,\n           rswm_q,\n           labels=as.character(hunan$County),\n           xlab=\"GDP per capita\",\n           ylab=\"Spatially lagged GDP per capita\")\n\n\n\n\nThe scatterplot is split into 4 quadrants. The x-axis is the actual GDP per capita and the y-axis is the spatially lagged GDP per capita. A higher spatially lagged GDP per capita means the surrounding neighbours have high GDP per capita.\nUpper right: Contains observations with high spatially lagged and actual GDP per capita, indicating positive autocorrelation and clustering of high values.\nLower left: Contains low spatially lagged and actual GDP per capita, indicating positive autocorrelation and clustering of low values.\nUpper left: High spatially lagged GDP per capita and low actual GDP per capita, indicating negative autocorrelation. These observations are outliers with low GDP per capita among neighbours with high GDP per capita.\nLower right: Low spatially lagged GDP per capita and high actual GDP per capita, indicating negative autocorrelation. These observations are outliers with high GDP per capita among neighbours with low GDP per capita.\n This scatterplot still does not take into account whether the values are statistically significant so we still need to refine this further.\n\n\n\nFirst, we center GDP per capita and local Moran’s I around their means. We can then assign each observation to a quadrant depending on whether it is above or below mean GDP per capita and above or below the mean Moran’s I. We also create a quadrant 0 for observations that are not statistically significant. Note that the logical statement for quadrant 0 must be the first as we want it to be prioritised over the other criteria.\n\nhunan.localMI <- hunan.localMI %>%\n  mutate(C_mI = Ii - mean(Ii)) %>%\n  mutate(DV = GDPPC- mean(GDPPC)) %>%\n  mutate(quadrant = case_when(\n    Pr.Ii >0.05 ~0,\n    DV>0 & C_mI>0 ~4, #high-high cluster\n    DV<0 & C_mI<0 ~2, #low-high outlier\n    DV<0 & C_mI>0 ~1, #low-low cluster\n    DV>0 & C_mI<0 ~3)) #high-low outlier\n\nWe can now build the LISA map:\n\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col=\"quadrant\",\n          style=\"cat\",\n          palette = colors,\n          label = clusters,\n          popup.vars=c(\"\")) +\n  tm_view(set.zoom.limits=c(11,17))+\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = \"LISA Clustering\")\n\nLISAmap\n\n\n\n\nFor proper analysis, we should actual GDp per capita next to the LISA map.\n\ntmap_arrange(quantile, LISAmap,\n             asp=1, ncol=2)\n\n\n\n\nFrom the maps, we can see that there is a cluster of high GDP per capita counties in the northeast. There are 2 outlier counties in the with low GDP per capita near this the high cluster. In the southeast, there is a cluster of low GDP per capita.\n\n\n\nLocal spatial statistics can also be used to detect hot spots and cold spots. One such measure is Getis and Ord’s G-statistics. It examines neighbours within a defined proximity to identify where either high or low values clutser spatially.\nInstead of contiguous neighbours, it uses neighbours with a specified distance. As such, we need to find the centroids of each county to develop a distance spatial weight matrix. The following code chunk creates an object with longitude and latitudes extracted using the st_centroid() function.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude, latitude)\n\nNext, we need to determine the maximum distance to consider counties as neighbours in the spatial matrix. The following code chunk uses knearneigh() to find the k nearest neighbours to each centroid (k=1 by default) and stores the indices of the nearest neighbours as list k1. The second line of code uses nbdists() to find the distance between each pair of neighbours . unlist() is needed to extract the distances from the list object. Lastly, we get some summary statistics on distance to nearest neighbours.\n\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe furtherest nearest neighbour is 61.79km away, so using this as the maximum distance will ensure that each county will have at least one neighbour.\nThe following code chunk creates a distance weight matrix (list of the the indices of neighbours within 62km radius of each centroid).\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThen, we convert the matrix to binary format with the nb2listw() function.\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nThe localG() function is used to compute the G statistic of each county with respect to GDP per capita.\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nIt outputs a list of the G statistic for each county (in terms of a z-value). High positive values indicate the posibility of a local cluster of high values of the variable being analysed, very low relative values a similar cluster of low values.\nWe then join the G statistics to the base dataset.\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nWe can see that there is a hotspot of high GDP per capita in the northeast of Hunan province.\n\n\n\nThe previous section computed Gi using a fixed weighting scheme where the distance is fixed and the number of neighbours considered depends on density of neighbours. Another method to compute Gi is to use an adaptive weighting scheme that considers a fixed number of nearest neighbours. The size of the neighbourhood considered will depend on the density of points.\n\nk8 <- knn2nb(knearneigh(coords,\n                        k=8))\nk8\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nk8_lw <- nb2listw(k8, style = 'B')\nsummary(k8_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\nNow to recompute Gi using the new weights matrix and generate the new map.\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, k8_lw)\n\nhunan.gi <- cbind(hunan.gi, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap1 <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi (Fixed)\") + \n  tm_borders(alpha = 0.5)\n\nGimap2 <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi (Adaptive)\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap1,\n             Gimap2,\n             asp=1, \n             ncol=3)\n\nSome legend labels were too wide. These labels have been resized to 0.47, 0.47, 0.47, 0.43. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nUnder the adaptive weightage scheme, there are more non-zero links. We can infer that in general a larger neighbourhood is considered for each county. This is likely especially so for counties on the border. This could explain the additional hotspot on the northeastern border. There are also fewer coldspots compared to the fixed scheme.\n\n\n\n\nhttps://gisgeography.com/spatial-autocorrelation-moran-i-gis/\nhttps://medium.com/locale-ai/spatial-autocorrelation-how-spatial-objects-affect-other-nearby-spatial-objects-e05fa7d43de8\nhttps://www.statology.org/morans-i/\nhttps://storymaps.arcgis.com/stories/5b26f25bb81a437b89003423505e2f71"
  },
  {
    "objectID": "Take-home_EX01/Take-home_EX01.html",
    "href": "Take-home_EX01/Take-home_EX01.html",
    "title": "Take-Home Exercise 01",
    "section": "",
    "text": "The purpose of this study is to understand the spatial patterns of functional and non-functional water points in Nigeria.\n\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\nfunModeling: quick exploratory data analysis\n\n\npackages = c('sf', 'tidyverse', 'spdep', 'tmap', 'funModeling', 'kableExtra')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p,character.only = T)\n}\n\n\n\n\nThe water point data is collected by the Water Point Data Exchange (WPdx) whose goal is to improve water access to rural communities by providing data to enable data-driven decision making. The dataset can be found here and the data dictionary here. The data is in csv format with latitude and longitude information.\n\nwp <- read_csv(\"data/WPdx_plus_Nigeria.csv\")\n\nRows: 95008 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): #status_clean\ndbl (2): #lat_deg, #lon_deg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nDue to the size of the dataset, it has already been pre-processed to keep only entries in Nigeria and some unused variables have been removed. The following code was used to pre-process the raw data file “WPdx_plus_full.csv” from the website but is not run on this page (raw data file is also not found on GitHub).\n\nwp <- read_csv(\"data/WPdx_plus_full.csv\") %>%\n  filter(`#clean_country_name`==\"Nigeria\") %>%\n  select(c(3:4, 22)) %>%\n  write_csv(\"data/WPdx_plus_Nigeria.csv\")\n\n\nglimpse(wp)\n\nRows: 95,008\nColumns: 3\n$ `#lat_deg`      <dbl> 7.980000, 6.964532, 6.486940, 6.727570, 6.779900, 6.95…\n$ `#lon_deg`      <dbl> 5.120000, 3.597668, 7.929720, 7.648670, 7.664850, 7.77…\n$ `#status_clean` <chr> NA, \"Functional\", NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nWe can see that the variable names have some special characters which is not ideal. There are also a lot of NA values in the variable of interest (#status_clean). The following code chunk cleans the variable names and replaces the NA values with “Unknown”.\n\nwp <- wp %>%\n  rename_with(~str_replace(.x, \"#\", \"\")) %>%\n  mutate(status_clean=replace_na(status_clean, \"Unknown\"))\n\nLet’s check the values of status_clean.\n\nwp %>%\n  group_by(status_clean) %>%\n  summarise(n=n()) %>%\n  ungroup() %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    status_clean \n    n \n  \n \n\n  \n    Abandoned \n    175 \n  \n  \n    Abandoned/Decommissioned \n    234 \n  \n  \n    Functional \n    45883 \n  \n  \n    Functional but needs repair \n    4579 \n  \n  \n    Functional but not in use \n    1686 \n  \n  \n    Non-Functional \n    29385 \n  \n  \n    Non-Functional due to dry season \n    2403 \n  \n  \n    Non functional due to dry season \n    7 \n  \n  \n    Unknown \n    10656 \n  \n\n\n\n\n\nThe categories are more detailed than we need to study the proportion of functional and non-functional waterpoints. The following code chunk collapses the categories into 3 categories: “Functional”, “Nonfunctional” and “Unknown”.\n\nwp <- wp %>%\n  mutate(status = case_when(\n    status_clean %in% c(\"Abandoned/Decommissioned\", \n                        \"Abandoned\",\n                        \"Non-Functional\",\n                        \"Non functional due to dry season\",\n                        \"Non-Functional due to dry season\") ~ \"Nonfunctional\",\n    status_clean == \"Unknown\" ~ \"Unknown\",\n    status_clean %in% c(\"Functional\", \n                        \"Functional but not in use\",\n                        \"Functional but needs repair\") ~ \"Functional\"\n  ))\n\nLet’s visualise the proportions of functionality of the waterpoints. On the whole, only 55% of waterpoints are functional.\n\nfreq(wp, input=\"status\")\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n         status frequency percentage cumulative_perc\n1    Functional     52148      54.89           54.89\n2 Nonfunctional     32204      33.90           88.79\n3       Unknown     10656      11.22          100.00\n\n\nNow, I convert the aspatial data into geospatial point data from the latitude and longitude variables using the st_as_sf() function. The GCS of the data is WGS1984 (EPSG:4326) as stated in the data dictionary.\n\nwp_sf <- st_as_sf(wp, \n                  coords = c(\"lon_deg\", \"lat_deg\"),\n                  crs=4326) \n\n\n\n\nI will also use the Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon dataset from geoBoundaries.\n\nadm_bound <- st_read(dsn=\"data\",\n               layer=\"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\lins-92\\ISSS624\\Take-home_EX01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(adm_bound)\n\nRows: 774\nColumns: 6\n$ shapeName  <chr> \"Aba North\", \"Aba South\", \"Abadam\", \"Abaji\", \"Abak\", \"Abaka…\n$ Level      <chr> \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"AD…\n$ shapeID    <chr> \"NGA-ADM2-72505758B79815894\", \"NGA-ADM2-72505758B67905963\",…\n$ shapeGroup <chr> \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NG…\n$ shapeType  <chr> \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"AD…\n$ geometry   <MULTIPOLYGON [°]> MULTIPOLYGON (((7.401109 5...., MULTIPOLYGON (…\n\n\nLet’s check what the Nigeria Level-2 Administrative Boundary and water points data looks like.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(adm_bound) +\n  tm_polygons() +\n  tm_text(\"shapeName\", size=0.2) +\ntm_shape(wp_sf) +\n  tm_symbols(size=0.1)\n\n\n\n\n\n\n\n\nNow I have 2 geospatial datasets: a point dataset with waterpoint locations and a polygon data with administrative boundaries. I still need to count the number of points by status for each administrative area.\nI will use the st_join() function to do a spatial join to relate the polygon IDs to each waterpoint by its location (note that the shapeName variable contains duplicates and should not be used for this step). The join=st_intersects() argument tells R the type of spatial join to use. Note that both datasets must have the same projection (WGS1984), which is why we have not transformed either dataset yet.\n\nwp_named <- st_join(x = wp_sf,\n                    y = adm_bound,\n                    join = st_intersects,\n                    left = TRUE)\n\nNext, we need check if there are any missing values.\n\nsum(is.na(wp_named$shapeID))\n\n[1] 29\n\n\nWe can plot the points to visually check why these points are missing polygon IDs. Most likely it is because they fall outside any administrative area. If so, we can safely ignore these points.\nSetting tmap_mode(\"view\") creates an interactive plot so we can zoom in to check the points. In addition, tm_dots() is used instead of tm_shape() this time so that the size of each point scales dynamically when zooming in on the interactive map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(adm_bound) +\n  tm_polygons() +\ntm_shape(filter(wp_named, is.na(shapeID))) +\n  tm_dots(size=0.1,\n          col=\"red\")\n\n\n\n\n\n\nWe can see that these 29 points fall outside the boundary of Nigeria so we can exclude them.\nNow let’s extract the number of waterpoints by status in each administrative boundary and join it to the administrative boundary polygon layer. First, I need to remove the geometry data using the st_drop_geometry() function to manipulate it like a regular dataframe using tidyr and dplyr functions.\nThe next step is to group by administrative area name and status to generate the count. Lastly, we pivot from long to wide format for joining with the administrative boundary dataset such. The values_fill=0 argument replaces any na values in the values_from variable with 0.\n\nprop <- wp_named %>%\n  st_drop_geometry() %>%\n  group_by(shapeID, status) %>%\n  summarise(n=n()) %>%\n  ungroup() %>%\n  pivot_wider(id_cols=shapeID,\n              names_from=status,\n              values_from=n, \n              values_fill=0)\n\n`summarise()` has grouped output by 'shapeID'. You can override using the\n`.groups` argument.\n\nhead(prop, n=5) %>%\n  kable() %>%\n  kable_styling()\n\n\n\n \n  \n    shapeID \n    Functional \n    Nonfunctional \n    Unknown \n  \n \n\n  \n    NGA-ADM2-72505758B10049836 \n    31 \n    39 \n    0 \n  \n  \n    NGA-ADM2-72505758B10063467 \n    50 \n    38 \n    30 \n  \n  \n    NGA-ADM2-72505758B10065661 \n    104 \n    51 \n    23 \n  \n  \n    NGA-ADM2-72505758B10302610 \n    64 \n    53 \n    84 \n  \n  \n    NGA-ADM2-72505758B11317593 \n    51 \n    49 \n    0 \n  \n\n\n\n\n\nNow, we use left_join() to join the counts to the administrative boundary geospatial data. As this is the final dataset we will be working on, we can transform the projection to EPSG:26391. We also need to replace any na counts with 0. There are still na counts in this step because some polygons may not have any waterpoints and would not have been addressed in the previous step. Lastly, we add a new variable for total number of waterpoints.\n\nadm_wp <- left_join(x=adm_bound,\n                    y=prop,\n                    by=\"shapeID\") %>%\n  mutate(across(c(6:8), ~replace_na(.x, 0))) %>%\n  mutate(Total = Functional + Nonfunctional + Unknown) %>%\n  st_transform(crs = 26391)\n\n\n\nFinally, we can plot the number of waterpoints by status in each administrative area.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntotal <- qtm(adm_wp, \"Total\")\nfunc <- qtm(adm_wp, \"Functional\")\nnonfunc <- qtm(adm_wp, \"Nonfunctional\")\nunknown <- qtm(adm_wp, \"Unknown\")\n\ntmap_arrange(total, func, nonfunc, unknown,\n             asp=1, ncol=2, nrow=2)\n\n\n\n\nThe distribution of waterpoints across Nigeria does not appear to be evenly distributed. There are some small administrative areas with many waterpoints in the central north. Based on the distribution of waterpoints of unknown status, we can infer that the north of Nigeria is likely more developed because there are fewer waterpoints of unknown status; likewise, central Nigeria may not be as developed because there is a higher number of waterpoints of unknown or non-functional status.\nThe next 3 code chunks plot waterpoints using quantile breaks. We can also add a histogram to view the distribution of total waterpoints.\n\ntm_shape(adm_wp)+\n  tm_polygons(\"Total\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              legend.hist=TRUE) +\n  tm_layout(main.title=\"Total Waterpoints in Nigeria\",\n            main.title.size=1.1,\n            title.snap.to.legend=FALSE,\n            legend.outside=TRUE,\n            legend.hist.width = 1.1)\n\n\n\n\nFrom this map, we can see that the north-east and south of Nigeria tend to have fewer waterpoints. More than 60% of administrative areas have less than 200 waterpoints. As we do not know the population or water demand of each administrative area, it is difficult to say which areas are water stressed or need additional water infrastructure.\n\ntm_shape(adm_wp)+\n  tm_polygons(\"Functional\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              legend.hist=TRUE) +\n  tm_layout(main.title=\"Functional Waterpoints in Nigeria\",\n            main.title.size=1.1,\n            title.snap.to.legend=FALSE,\n            legend.outside=TRUE,\n            legend.hist.width = 1.1)\n\n\n\n\n\ntm_shape(adm_wp)+\n  tm_polygons(\"Nonfunctional\",\n              style=\"quantile\",\n              palette=\"-RdBu\",\n              legend.hist=TRUE) +\n  tm_layout(main.title=\"Non-Functional Waterpoints in Nigeria\",\n            main.title.size=1.1,\n            title.snap.to.legend=FALSE,\n            legend.outside=TRUE,\n            legend.hist.width = 1.1)\n\n\n\n\nFrom the maps above, it would seem that areas with many waterpoints tend to have many functional and non-functional waterpoints as well. As such, to assess the state of maintenance of waterpoints in each administrative area, it would be better to map the proportion of functional and non-functional waterpoints out of the total number of waterpoints.\n\n\n\nFirst, we need to generate new variables for proportions. There are some administrative areas without any waterpoints which will result is na values for the proportions. We do not replace these na values with 0 because it will affect the subsequent analysis. We will need to be careful to exclude na values in the subsequent steps. We also should not remove these values because it will affect the neighbourhood structure when conducting spatial analysis.\nThere are 2 problems with replacing them with 0:\n\n0 values represent a low proportion of functional/non-functional waterpoints. This is inaccurate since there were no waterpoints at all. Using 0 may skew the spatial distribution and clustering analysis.\nThese areas will appear to have low proportions for both functional and non-functional waterpoints. The relationship between should be negative.\n\n\nadm_wp <-adm_wp %>%\n  mutate(pFunctional = Functional/Total,\n         pNonfunctional = Nonfunctional/Total,\n         pUnknown = Unknown/Total) \n\nThe following plot shows the number of non-functional waterpoints out of total waterpoints by administrative area. It is sorted by descending order of proportion of non-functional waterpoints using the reorder() function.\nWe can see that there are some administrative areas on the left side of the plot with some few waterpoints and most of them are non-functional. Repairs should be focused on such areas with fewer waterpoints and high percentage that are non-functional.\n\nggplot(adm_wp) +\n  geom_bar(aes(x=reorder(shapeID, pNonfunctional, decreasing=TRUE), \n               y=Total,\n               fill=\"Total\"),\n           stat=\"identity\") +\n    geom_bar(aes(x=reorder(shapeID, pNonfunctional, decreasing=TRUE), \n               y=Nonfunctional,\n               fill=\"Non-functional\"),\n           stat=\"identity\",\n           alpha=0.8) +\n  scale_fill_manual(name=\"\",\n                    values=c(\"red\", \"gray30\")) +\n  labs(title=\"Number of Water by Administrative Area\",\n       subtitle=\"(sorted by proportion of non-functional)\",\n       y=\"Number of waterpoints\",\n       x=\"Administrative Areas\")+\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        axis.line.y=element_line(colour=\"grey50\"))\n\n\n\n\nNow let’s plot the proportions spatially.\n\ntotal <- tm_shape(adm_wp)+\n  tm_polygons(\"Total\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Total waterpoints\")\n\nfunc <- tm_shape(adm_wp)+\n  tm_polygons(\"pFunctional\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Proportion functional\")\n\nnonfunc <- tm_shape(adm_wp)+\n  tm_polygons(\"pNonfunctional\",\n              style=\"quantile\",\n              palette=\"-RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Proportion non-functional\")\n\nunknown <- tm_shape(adm_wp)+\n  tm_polygons(\"pUnknown\",\n              style=\"quantile\",\n              palette=\"RdBu\",\n              title=\"\")+\n  tm_layout(main.title=\"Proportion unknown\")\n\ntmap_arrange(total, func, nonfunc, unknown,\n             asp=1, ncol=2, nrow=2)\n\n\n\n\nWe can see that many administrative areas in the north have more waterpoints and a higher proportion of functional waterpoints. Many states in the south part of Nigeria have few waterpoints a high proportion of non-functional waterpoints.\nThe spatial distribution of waterpoints could be influenced by climate and population distribution (see maps below). The south of Nigeria has a tropical climate (and thus higher rainfall) which could mean less reliance on man-made waterpoints and thus there are fewer waterpoints. On the other hand, many regions in the north of Nigeria have a high proportion of functional waterpoints, possibly because of the high reliance on them due to the arid climate.\nAreas with higher population also tend to have more waterpoints.\n\n\n\n\n\n\nKoppen-Geiger climate classification map for Nigeria. Source: Beck, H. E., et al. (2018)\n\n\n\n\n\n\n\nPopulation density in Nigeria. Source: Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFrom plotting the total number of waterpoints and the proportion of functional waterpoints, we can visually see that waterpoints may not be evenly distributed across space in Nigeria. To confirm our intuition from visual inspection, we can test it statistically using global and local spatial autocorrelation statistics.\n\n\nFirst, we must define the neighbourhood to be considered for each administrative area. There are a number of methods to do this (see In-Class Exercise 1). Contiguity matrices only consider polygons that are immediately adjacent while distance matrices use distance to determine the neighbour. The choice of weight matrix can affect the results of the analysis. For this exercise, I will try 2 methods: inverse-distance contiguity weight matrix and adaptive distance weight matrix.\nContiguity Weight Matrix\nFirst, I create an nb object listing the neighbours of each administrative area. Queen method will be used to identify the adjacent neighbours. From the summary below, we can see that on average each administrative area is contiguous with about 6 other polygons. However, there is 1 administrative area which does not have any contiguous neighbours. It is likely an island. This means that a contiguity matrix is not suitable for this analysis.\n\nwm_q <- poly2nb(adm_wp, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 4440 \nPercentage nonzero weights: 0.7411414 \nAverage number of links: 5.736434 \n1 region with no links:\n86\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  14 \n  1   2  14  57 125 182 140 122  72  41  12   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nAdaptive Distance Weight Matrix\nAn adaptive distance weight matrix sets the fixed number of neighbours for each study area. It is usually used if there is large variation in polygon sizes but we need to set a consistent scale of analysis by considering the same number of neighbours for each area.\nFirst, we need to find the centroids of each polygon. These will be used to determine the distances between polygons to set the neighbourhood.\n\nlongitude <- map_dbl(adm_wp$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(adm_wp$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude/1000, latitude/1000)\n\nIn this exercise, I will fix the number of neighbours at 8 [1]. The knearneigh() function takes the coordinates and finds the 8 nearest neighbours of each polygon. We then convert it to an nb object using knn2nb() function. lastly, nb2listw() generates the spatial weight matrix from the nb object.\n\nk8 <- knn2nb(knearneigh(coords, k=8))\nk8\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 6192 \nPercentage nonzero weights: 1.033592 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nk8_lw <- nb2listw(k8, style=\"B\",\n                  zero.policy=TRUE)\n\n\n\n\nThe global Moran’s I test is intended to test if the independent variable (total waterpoints, proportion of functional and non-functional waterpoints) is evenly distributed, randomly distributed or clustered. Since we do not know the underlying distribution of waterpoints, we use Monte Carlo simulations (n=1000) to simulate randomly distribution of proportions spatially.\nNote that that we must set na.action=na.exclude because there are na values in pFunctional and pNonfunctional. Because we omit these values, some areas may have less than 8 neighbours.\n\nset.seed=123\n\nmoran.mc(adm_wp$Total, \n         listw=k8_lw, \n         nsim=999,\n         zero.policy = TRUE, \n         na.action=na.exclude)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  adm_wp$Total \nweights: k8_lw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.49306, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe above test shows that there is spatial clustering of waterpoints in Nigeria. The Moran’s I statistic of 0.49 is significant at the 5% significance level. We can reject the null hypothesis (that total waterpoints is randomly distributed spatially) and conclude that there isspatial clustering of waterpoints in Nigeria.\n\nset.seed=123\n\nmoran.mc(adm_wp$pFunctional, \n         listw=k8_lw, \n         nsim=999,\n         zero.policy = TRUE, \n         na.action=na.exclude)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  adm_wp$pFunctional \nweights: k8_lw \nomitted: 3, 86, 241, 250, 252, 261, 400, 406, 447, 473, 492, 507, 526 \nnumber of simulations + 1: 1000 \n\nstatistic = 0.52454, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nset.seed=123\n\nmoran.mc(adm_wp$pNonfunctional, \n         listw=k8_lw, \n         nsim=999,\n         zero.policy = TRUE, \n         na.action=na.exclude)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  adm_wp$pNonfunctional \nweights: k8_lw \nomitted: 3, 86, 241, 250, 252, 261, 400, 406, 447, 473, 492, 507, 526 \nnumber of simulations + 1: 1000 \n\nstatistic = 0.44023, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe computed Moran’s I of 0.52 (p-value=0.001) and 0.44 (p-value=0.001) for the proportions of functional and non-functional waterpoints respectively are significant at the 5% significance level. This indicates that there is some degree of clustering of proportions of functional and non-functional waterpoints.\n\n\n\n\nHotspots and coldspots can be detected using the local Moran’s I statistics. Unlike the global Moran’s I test, the local Moran’s I test calculates the test statistics for each observation. Each value measures the extent of significant spatial clustering of similar values around that observation.\nThe following code chunk conducts the local MI test and saves the result to a dataframe for both proportion of functional and non-functional waterpoints. The Moran’s I statistics and p-values are then joined to the polygon data to plot in a map.\n\nlocalMI.func <- localmoran(adm_wp$pFunctional,\n                           k8_lw, \n                           na.action=na.exclude,\n                           zero.policy=TRUE)\nlocalMI.func <- data.frame(localMI.func)%>%\n  select(c(1,5)) %>%\n  rename(func.Ii = Ii,\n         func.Pr = Pr.z....E.Ii..)\n\nlocalMI.nonfunc <- localmoran(adm_wp$pNonfunctional,\n                              k8_lw,\n                              na.action=na.exclude,\n                              zero.policy=TRUE)\nlocalMI.nonfunc <- data.frame(localMI.nonfunc)%>%\n  select(c(1,5)) %>%\n  rename(nonfunc.Ii = Ii,\n         nonfunc.Pr = Pr.z....E.Ii..)\n\nadm_wp.localMI <- cbind(adm_wp, localMI.func, localMI.nonfunc) \n\nThe local Moran’s score alone is not enough to show spatial clustering because it does not tell us whether the value of the variable being tested (proportion of functional/non-functional waterpoints) is high or low and whether the test result was significant. As such, we assign each observation to a quadrant depending on the value of the variable on the y-axis (centred around the mean) and Moran’s I on the x-axis. Quadrant 1 contains coldspots and quadrant contains hotspots. The following table explains the the quadrants:\n\nThe following code create 2 new variables each for proportion of functional and non-functional waterpoints. One for the centered proportion (around the mean) and the quadrant that the observation belong to. Note that we must include the na.rm=TRUE argument when computing mean because our data has na values. We also create a quadrant zero if the test statistic is not significant and the null hypothesis of random distribution cannot be rejected.\n\nadm_wp.localMI <- adm_wp.localMI %>%\n  mutate(DV.func = pFunctional- mean(pFunctional, na.rm=TRUE)) %>%\n  mutate(func.quadrant = case_when(\n    func.Pr >0.05 ~0,\n    DV.func<0 & func.Ii>0 ~1, \n    DV.func<0 & func.Ii<0 ~2,\n    DV.func>0 & func.Ii<0 ~3,\n    DV.func>0 & func.Ii>0 ~4)) %>% \n  mutate(DV.nonfunc = pNonfunctional- mean(pNonfunctional, na.rm=TRUE)) %>%\n  mutate(nonfunc.quadrant = case_when(\n    nonfunc.Pr >0.05 ~0,\n    DV.nonfunc<0 & nonfunc.Ii>0 ~1, \n    DV.nonfunc<0 & nonfunc.Ii<0 ~2, \n    DV.nonfunc>0 & nonfunc.Ii<0 ~3,\n    DV.nonfunc>0 & nonfunc.Ii>0 ~4)) \n\nPlot LISA cluster map:\n\npfunc.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"pFunctional\", \n          style=\"quantile\",\n          title=\"Proportion\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"Proportion Functional\")\n\npnonfunc.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"pNonfunctional\", \n          style=\"quantile\",\n          title=\"Proportion\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"Proportion Non-functional\")\n\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nlocalMI.func.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"func.quadrant\", \n          style=\"cat\",\n          palette =colors,\n          label=clusters,\n          title=\"Quadrant\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"LISA Cluster (Functional)\")\n\nlocalMI.nonfunc.map <- tm_shape(adm_wp.localMI) +\n  tm_fill(col = \"nonfunc.quadrant\", \n          style=\"cat\",\n          palette =colors,\n          label=clusters,\n          title=\"Quadrant\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title=\"LISA Cluster (Non-Functional)\")\n\ntmap_arrange(pfunc.map, localMI.func.map, \n             pnonfunc.map, localMI.nonfunc.map,\n             asp=1, ncol=2, nrow=2)\n\n\n\n\nThe LISA cluster maps clearly show that there is clustering in the proportion of functional/non-functional waterpoints. There is a hotspot for functional waterpoints in the central north of Nigeria. There is also a coldspot in the southeast where a custer of regions have low proportion of functional waterpints. This area is an area of concern for maintenance efforts. There are not many outliers.\nThere is a coldspot of non-functional waterpoints in the central north of Nigeria that overlaps with the hotspot of functional waterpoints. This is logical as the proportions have an negative relationship. If the proportion of functional waterpoints is high, the proportion of non-functional waterpoints should be low.\nHowever, we see a different story in the south where there is a hotspot of non-functional waterpoint areas and no corresponding hotspot for functional waterpoint. This could be due to a difference in the centring of the proportions. From the code chunk below, we see that the mean proportion of non-functioning waterpoints is much lower than that of functional waterpoints (because there are unknowns as well). The threshold to be classified as a high non-functional area is lower than the threshold to be classified as a low functional area.\n\nmean(adm_wp$pFunctional, na.rm=TRUE)\n\n[1] 0.5069513\n\nmean(adm_wp$pNonfunctional, na.rm=TRUE)\n\n[1] 0.3653858\n\n\nThe 3 hotspot of high proportion of non-functional waterpoints in the south and west of Nigeria are a cause for concern for maintenance efforts.\n\n\n\nThe analysis showed there is clearly uneven distribution of waterpoints in Nigeria, and there is uneven distribution of available (functional) waterpoints. There were significant hotspots with high proportion of non-functional waterpoints which could be indicative of underlying problems in the maintenance regimes. Nonetheless, further analysis should be conducted considering population or water demand to determine water stress and decide on high priority areas to add waterpoints or step up maintenance.\n\n\n\n[1] https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/generate-spatial-weights-matrix.htm"
  },
  {
    "objectID": "In-class_EX02/In-class_EX02.html",
    "href": "In-class_EX02/In-class_EX02.html",
    "title": "In-Class Exercise 2",
    "section": "",
    "text": "This exercise is to prepare the datasets for take-home exercise 1 on analysing availability of waterpoints in Nigeria. The details of the exercise can be found here.\n\n\n\n\nWe will use the following packages:\n\nsf: import geospatial datasets\ntidyverse: manipulate aspatial data\nspdep: compute spatial weights and autocorrelation\ntmap: plot maps\nfunModeling: quick EDA\n\n\npacman::p_load(sf, tidyverse, tmap, spdep, funModeling)\n\n\n\n\nThe waterpoint dataset is downloaded from here and the data dictionary here. The file has been saved as “Wdx_plus_full.csv”. In this exercise, I will use the csv format. Although the shp file format would be preferable, I was unable to complete the download without the file getting corrupted. Nonetheless, we can simply use the longitude and latitude data provided to convert it to an sf object.\nThe following code imports the waterpoint dataset and keeps only the datapoints from Nigeria.\n\nwp_csv <- read_csv(\"data/WPdx_plus_full.csv\") %>%\n  filter(`#clean_country_name`==\"Nigeria\")\n\n\nglimpse(wp_csv)\n\nWe can see that we do not need most of the variables to analyse the status of waterpoints. The following code chunk keeps only the relevant variables and removes the special characters from the variable names.\n\nwp_csv <- wp_csv %>%\n  select(c(3:4, 22))%>%\n  rename_with(~str_replace(.x, \"#\", \"\"))\n\nNow we can convert it to sf format. From the data dictionary, we know that the original GCS of the data is WGS1984 (EPSG:4326) from the data dictionary. We need to project it to the EPSG:26391 CRS later. However, as we will be using the st_intersects() function later, we will keep retain the EPSG:4326 GCS first.\n\nwp <- st_as_sf(wp_csv, \n               coords = c(\"lon_deg\", \"lat_deg\"),\n               crs=4326)\n\nNow we save the smaller version of the file.\n\nwrite_rds(wp, \"data/wp_nga.rds\")\n\n\n\n\nThis exercise also usess the Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon dataset from geoBoundaries.\n\nnga <- st_read(dsn = \"data\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\lins-92\\ISSS624\\In-class_EX02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\nThe following code chunk imports the reduced waterpoint data file which was saved with geometries. We perform some further cleaning by replacing the na values in the status_clean variable as “Unknown”.\n\nwp_nga <- read_rds(\"data/wp_nga.rds\") %>%\n  mutate(status_clean = replace_na(status_clean, \"Unknown\"))\n\nWe can use the freq() function of the funModeling package to plot the distribution of status of waterpoints.\n\nfreq(data=wp_nga, \n     input = 'status_clean')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                          Unknown     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nThere are types of status but we only really need to know whether the water point is functional or not. Those that were na values will continue to be categorised as unknown status.\n\n\n\nwpt_functional <- wp_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\", \n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nfreq(data=wpt_functional, \n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\n\n\n\nwpt_nonfunctional <- wp_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\n\nfreq(data=wpt_nonfunctional, \n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00\n\n\n\n\n\n\nwpt_unknown <- wp_nga %>%\n  filter(status_clean == \"Unknown\")\n\n\n\n\nThe following code chunk counts the number of points (functional, non-functional and unknown separately) in each polygon of the administrative boundary data and saves type each as a variable in the administrative data attribute table.\n\nnga_wp <- nga %>% \n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown)))\n\nNext, we compute the proportions of functional and non-functional waterpoints for each area. We can also perform the transformation now since we have done the st_intersects() already. Save the file.\n\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%\n  st_transform(crs = 26391) %>%\n  write_rds(\"data/nga_wp.rds\")\n\n\n\n\n\n\nnga_wp <- read_rds(\"data/nga_wp.rds\")\ntotal <- qtm(nga_wp, \"total wpt\")\nwp_functional <- qtm(nga_wp, \"wpt functional\")\nwp_nonfunctional <- qtm(nga_wp, \"wpt non-functional\")\nunknown <- qtm(nga_wp, \"wpt unknown\")\n\ntmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1, ncol=2)"
  }
]